{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data assimilation (DA) & the ensemble Kalman filter (EnKF)\n",
    "*Copyright (c) 2016, Patrick N. Raanes, NERSC*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebooks\n",
    "These tutorials are made in \"Jupyter notebooks\" which conveniently combine Python (code) with text (markdown). Notebooks live in the web browser because that's what the developers found most convenient. A notebook consists of \"cells\", which you can work with using your mouse, or more efficiently, your keyboard:\n",
    "\n",
    "\n",
    "| Navigate                      | Edit              | Exit           | Run                              |\n",
    "| -------------                 | : ------------- : | -------------  | : ------------- :                |\n",
    "| <kbd>↓</kbd> and <kbd>↑</kbd> | <kbd>Enter</kbd>  | <kbd>Esc</kbd> | <kbd>Ctrl</kbd>+<kbd>Enter</kbd> |\n",
    "\n",
    "\n",
    "When you open a notebook it starts a session of Python in the background. All of the Python code cells (in a given notebook) are connected -- they use the same Python session and thus share variables, functions, and classes. Thus, the order in which you run the cells matters. For example, the uppermost code cell in each of these tutorials will be the following, which you must run before any other code cells:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell now.\n",
    "from resources.workspace import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond the above table, there's a bunch of other things you can do with the notebooks. The most important one is to restart the Python session, which clears all of your variables, functions, etc, so that you can start over. Test this now by going through the top menu bar: `Kernel` → `Restart & Clear Output`. But rembember to run the above cell again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data assimilation (DA) is:\n",
    "<figure style=\"float:right;width:350px;\">\n",
    "    <img src=\"./resources/DA_bridges.jpg\" alt='DA \"bridges\" data and models.'/>\n",
    "    <figcaption>Data assimilation \"bridges\" data and models.<br>Attribution: Data Assimilation Research Team, <a href=\"http://www.aics.riken.jp\">www.aics.riken.jp</a>.</figcaption>\n",
    "</figure>\n",
    " * the calibration of big models with big data;\n",
    " * the fusion of forecasts with observations.\n",
    " \n",
    "The problem of ***DA*** fits well within the math/stats theory of ***state estimation*** and ***sequential inference***. A concise theoretical overview of DA is given by Wikle and Berliner: [A Bayesian tutorial for data assimilation](http://web-static-aws.seas.harvard.edu/climate/pdf/2007/Wikle_Berliner_InPress.pdf)\n",
    "\n",
    "Modern DA builds on state estimation techniques such as the ***Kalman filter (KF)***, which is an algorithm that recursively performs a form of least-squares regression. It was developed to steer the Apollo mission rockets to the moon, but also has applications outside of control systems, such as speech recognition, video tracking, and finance. An [introduction by pictures](http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/) is provided by Tim Babb. An [interactive tutorial](https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python) has been made by Roger Labbe.\n",
    "\n",
    "When it was first proposed to apply the KF to DA (specifically, weather forecasting), the idea sounded ludicrous because of some severe challenges:\n",
    "\n",
    "#### Technical challenges in DA (vs. \"classic\" state estimation):\n",
    " * size of data and models;\n",
    " * nonlinearity of models;\n",
    " * sparsity and inhomogeneous-ness of data.\n",
    "\n",
    "Some of these challenges may be recognized in the video below.\n",
    "\n",
    "*Execute/run the cell below to bring up the video*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "envisat_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The EnKF is\n",
    "an ensemble (Monte-Carlo) formulation of the KF\n",
    "that manages (fairly well) to deal with the above challenges in DA.\n",
    "\n",
    "For those familiar with the method of 4D-Var, **further advantages of the EnKF** include it being:\n",
    " * Non-invasive: the models are treated as black boxes, and no explicit jacobian is required.\n",
    " * Bayesian: \n",
    "   * provides ensemble of possible realities;\n",
    "       - arguably the most practical form of \"uncertainty quanitification\";\n",
    "       - ideal way to initialize \"ensemble forecasts\";\n",
    "   * uses \"flow-dependent\" background covariances in the analysis.\n",
    " * Highly parallellizable:\n",
    "   * distributed accross realizations for model forecasting;\n",
    "   * distributed accross local domains for observation analysis.\n",
    "   \n",
    "The rest of this tutorial provides an EnKF-centric presentation of DA; it also has a [theoretical companion](./resources/DA_intro.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAPPER example\n",
    "This tutorial builds on the underlying package, DAPPER, made for academic reserach in DA and its dissemination. For example, the code below is taken from  `DAPPER/example_1.py`. It illustrates DA on a small toy problem.\n",
    "\n",
    "Run the cells in order and try to interpret the output. Don't worry if you can't understand what's going on -- we will discuss it later throughout the tutorials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mods.Lorenz63.sak12 import setup\n",
    "setup.t.T = 30\n",
    "# print(setup)\n",
    "xx,yy = simulate(setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = EnKF_N(N=4, store_intermediate=True)\n",
    "stats = config.assimilate(setup,xx,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_3D_trajectory(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_time_series(stats,T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avrgs = stats.average_in_time()\n",
    "#print(avrgs)\n",
    "print_averages(config,avrgs,[],['rmse_a','rmv_a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_rank_histogram(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Exercises marked with a star (*) are optional.\n",
    "\n",
    "**Exc 1.2:** Word association.\n",
    "Fill in the `X`'s in the table to group the words according to meaning.\n",
    "\n",
    "`Filtering, Sample, Random, Measurements, Kalman filter (KF), Monte-Carlo, Observations, Set of draws, State estimation, Data fusion`\n",
    "\n",
    "---\n",
    "`Data Assimilation (DA)     Ensemble      Stochastic     Data        \n",
    "X                          X             X              X           \n",
    "X                          X             X              X           \n",
    "X                          \n",
    "X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show_answer('thesaurus 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"The answer\" is given from the perspective of DA. Do you agree with it?\n",
    "* Can you describe the (important!) nuances between the similar words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Exc 1.3*:** Word association (advanced).\n",
    "Group these words:\n",
    "\n",
    "`Inverse problems, Sample point, Probability, Particle, Sequential, Inversion, Realization, Relative frequency, Iterative, Estimation, Single draw, Serial, Approximation, Regression, Fitting`\n",
    "\n",
    "---\n",
    "\n",
    "`Statistical inference    Ensemble member     Quantitative belief    Recursive \n",
    "X                        X                   X                      X         \n",
    "X                        X                   X                      X         \n",
    "X                        X                                          X         \n",
    "X                        X\n",
    "X                        \n",
    "X                        \n",
    "`\n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show_answer('thesaurus 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next: [Bayesian inference](T2 - Bayesian inference.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
