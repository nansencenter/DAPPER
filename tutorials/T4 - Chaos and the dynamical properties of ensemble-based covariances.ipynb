{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from resources.workspace import *\n",
    "from IPython.display import display\n",
    "from scipy.integrate import odeint\n",
    "import copy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaos and the dynamical properties of ensemble-based covariances\n",
    "\n",
    "Chaos is commonly understood by the <b>butterfly effect</b>; \"A buttefly that flaps its wings in Brazil can \"cause\" a hurricane in Texas\". As opposed to the opinions of Descartes/Newton/Laplace, chaos effectively means that even in a deterministic (non-stochastic) universe, we can only predict \"so far\" into the future.  We will introduce two very typical \"toy\" models that exhibit these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of models chaotic systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"Lorenz-95\" model\n",
    "\n",
    "The [Lorenz 95/ 96 system](http://eaps4.mit.edu/research/Lorenz/Predicability_a_Problem_2006.pdf) is a one dimensional model, designed to simulate atmospheric convection.  Each variable <span style='font-size:1.25em'>$x^j$ </span> can be considered some atmospheric quantity in one of $m$ sectors along a single lattitude.  The differential equation for <span style='font-size:1.25em'>$x^j$ </span> reads,\n",
    "<h3>$$\n",
    "\\frac{{\\rm d} x^j}{{\\rm d} t} \\triangleq -x^{j-1} x^{j-2} + x^{j-1}x^{j+1} - x^j + F,\n",
    "$$</h3>\n",
    "where all indices $j$ are taken modulo $m$. \n",
    "\n",
    "There are **no accurate physics** represented in this model.  Rather, the model only seeks to capture qualitative features of the atmosphere, in that:\n",
    "<ul>\n",
    "    <li> there is external forcing, determined by a parameter $F$;</li>\n",
    "    <li> there is internal dissipation, simulated by linear terms;</li>\n",
    "    <li> there is advection, simulated by quadratic terms.</li>\n",
    "</ul>\n",
    "\n",
    "The number of sectors $m$ is assumed to be at least $m=4$ but typically it is taken that $m=40$. See the following link for\n",
    "[further description](resources/DA_intro.pdf#page=23)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exc 4.2**: The system above has an easy to find fixed point, i.e., a point <span style='font-size:1.25em'>$\\mathbf{x}_0$</span> such that\n",
    "<h3>$$ \\frac{{\\rm d}}{{\\rm d} t} \\mathbf{x}_0 \\equiv 0$$ </h3>\n",
    "\n",
    "Can you identify one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example solution\n",
    "\n",
    "# show_answer('fixed_point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fixed point is **stable** if for any perturbations sufficiently small, a trajectory evolved from this perturbation must be attracted to the fixed point.  That means, all nearby solutions will settle to a solution that doesn't change in time.  A classification of various fixed point dynamics is illustrated in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:900px'>\n",
    "<img src=\"./resources/Stability_Diagram.png\">\n",
    "</div>\n",
    "\n",
    "**By Freesodas (Gimp) [<a href=\"http://www.gnu.org/copyleft/fdl.html\">GFDL</a> or <a href=\"https://creativecommons.org/licenses/by-sa/4.0\">CC BY-SA 4.0</a>], <a href=\"https://commons.wikimedia.org/wiki/File:Stability_Diagram.png\">via Wikimedia Commons</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Lorenz-95 model, different values for $F$ will produce different behaviors in the model.  For some values of $F$, the fixed point from **Exc 4.2** is stable.  For some values of $F$, perturbations won't be drawn to the fixed point, but will settle to another kind of **steady behavior**.  For some values of $F$, small perturbations will behave wildy, with growth and decay that is difficult to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.4**: Run the code below to interactively plot the behavior of the Lorenz-95 sytem.  The figure on the left hand side below plots a time lapse of the values of <span style='font-size:1.25em'>$x^j$</span> on the $y$-axis, while the $x$-axis varies each sector $j$, modulo $m=10$.  The time variable is given by \"T\" below. \n",
    "\n",
    "The figure on the right hand side below plots the time series of the total engergy of the system, defined by\n",
    "<h3>$$\\begin{align}\n",
    "\\mathbf{E}(\\mathbf{x}) &= \\frac{1}{2} \\sum_{j=1}^m \\left(\\mathbf{x}^j\\right)^2.\n",
    "\\end{align}$$\n",
    "</h3>\n",
    "Note that for $T>30$, we only plot the time series in the interval $[T-30, T]$.\n",
    "\n",
    "For each value of $F$, we initialize the model with a small perturbation of size \"eps=0.5\" to the fixed point found in **Exc 4.2**.  Answer the following questions:\n",
    "<ol>\n",
    "   <li> For what values of $F$ does it look like the fixed point is stable?  How is this reflected in the energy in the system?</li>\n",
    "   <li> For what values of $F$ does it look like the system settles to periodic motion? How is this reflected in the energy in the system?</li>\n",
    "   <li> For what values of $F$ does the evolution become \"chaotic\"? How is this reflected in the energy in the system?\n",
    "   <li> The classical choice for $F$ is $F=8$.  What kind of behavior is exhibited?\n",
    "<ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For all i, any n: s(x,n) := x[i+n], circularly.\n",
    "def s(x,n):\n",
    "    return np.roll(x,-n)\n",
    "\n",
    "def animate_lorenz_95(F=0.8,T=0):\n",
    "    # Initial conditions: perturbations\n",
    "    eps=.5\n",
    "    m=10\n",
    "    x0 = ones(m)\n",
    "    x0 = x0 * F\n",
    "    x0[0] += eps\n",
    "    \n",
    "    def dxdt(x,t):\n",
    "        return (s(x,1)-s(x,-2))*s(x,-1) - x + F\n",
    "    \n",
    "    tt = linspace(0, T, int(T/.1) + 1)\n",
    "    xx = odeint(lambda x,t: dxdt(x,t), x0, tt)\n",
    "    energy =  .5 * np.sum(xx*2, axis=1)\n",
    "    xx = np.concatenate([xx,\n",
    "                         np.reshape(xx[:,0], [len(xx[:,0]), 1])],axis=1)\n",
    "    \n",
    "\n",
    "    # Plot multiple\n",
    "    fig = plt.figure(figsize=(16,6))\n",
    "    ax1 = fig.add_axes([.08, .095,  .4, .89])\n",
    "    ax2 = fig.add_axes([.525, .095, .4, .89])\n",
    "\n",
    "    Lag = 4\n",
    "    colors = plt.cm.cubehelix(0.1+0.6*linspace(0,1,Lag))\n",
    "    for k in range(Lag,0,-1):\n",
    "        ax1.plot(xx[max(0,len(xx)-k)],c=colors[Lag-k])\n",
    "\n",
    "    ax1.set_ylim(-10,20)\n",
    "    ax1.set_xlabel(r'Sector $j$', size=30)\n",
    "    ax1.set_xticks(range(0,12,2))\n",
    "    ax1.set_ylabel(r'$x^j$', size=30)\n",
    "    ax1.tick_params(\n",
    "        labelsize=20)\n",
    "    ax2.plot(tt[-300:], energy[-300:])\n",
    "    ax2.set_xlabel('Time T',size=30)\n",
    "    ax2.yaxis.set_label_position(\"right\")\n",
    "    ax2.set_ylabel('Total Energy',size=30, rotation=270)\n",
    "    ax2.yaxis.set_label_coords(1.175,.5)\n",
    "    ax2.tick_params(\n",
    "        axis='x',\n",
    "        labelsize=20)\n",
    "    ax2.tick_params(\n",
    "        axis='y',\n",
    "        labelsize=20,\n",
    "        right=True,\n",
    "        labelright=True,\n",
    "        left=False,\n",
    "        labelleft=False\n",
    "    )\n",
    "    tics = [np.round(i,decimals=1) for i in linspace(np.min(energy[-300:]) - 1, np.max(energy[-300:]) + 1, 5)]\n",
    "    ax2.set_yticks(tics)\n",
    "    ax2.set_yticklabels([str(i).zfill(2) for i in tics])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "interact(animate_lorenz_95,T=(0.2,60.2,0.1),F=(0,12,.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Lorenz (1963) system\n",
    "\n",
    "The <b>[Lorenz-63 system](https://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281963%29020%3C0130%3ADNF%3E2.0.CO%3B2)</b>, commonly known as the \"butterfly attractor\", is a simplified mathematical model for atmospheric convection respresenting real physics.  The Lorenz equations are derived from the Oberbeck-Boussinesq approximation to the equations describing fluid circulation in a shallow layer of fluid, heated uniformly from below and cooled uniformly from above - this describes Rayleigh-BÃ©nard convection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lorenz-63 system is given by the 3 coupled ordinary differential equations (ODE):\n",
    "<h3>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dot{x} & = \\sigma(y-x) \\\\\n",
    "\\dot{y} & = \\rho x - y - xz \\\\\n",
    "\\dot{z} & = -\\beta z + xy\n",
    "\\end{aligned}\n",
    "$$\n",
    "</h3>\n",
    "where \n",
    "<h3>$$\\dot{\\ast} \\triangleq \\frac{{\\rm d} }{{\\rm d} t}.$$</h3>\n",
    "See the following link for [further description](resources/DA_intro.pdf#page=22). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a test case for DA, the state vector is <span style='font-size:1.25em'>$\\mathbf{x} = (x,y,z)$</span>, and the parameters are typically set to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIGMA = 10.0\n",
    "BETA  = 8/3\n",
    "RHO   = 28.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equations relate the properties of a two-dimensional fluid layer uniformly warmed from below and cooled from above. In particular, the equations describe the rate of change of three quantities with respect to time: x is proportional to the rate of convection, y to the horizontal temperature variation, and z to the vertical temperature variation.  \n",
    "\n",
    "The dynamics can be written as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dxdt(xyz, t0, sigma=SIGMA, beta=BETA, rho=RHO):\n",
    "    \"\"\"Compute the time-derivative of the Lorenz-63 system.\"\"\"\n",
    "    x, y, z = xyz\n",
    "    return array([\n",
    "        sigma * (y - x),\n",
    "        x * (rho - z) - y,\n",
    "        x * y - beta * z\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical computation of trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is code to numerically integrate the differential equations and plot the solutions. This function has arguments that control the parameters of the differential equation <span style='font-size:1.25em'>$(\\sigma,\\beta,\\rho)$</span>.  In the following we will study how small perturbations of a \"control\" trajectory change over time.\n",
    "\n",
    "Additional parameters in the code inlcude:\n",
    "<ul>\n",
    "    <li> \"N\", defining the number of perturbations;</li>\n",
    "    <li> \"eps\", defining the size of perturbations;</li>\n",
    "    <li> \"T\", defining the length of the forward evolution.  **Note**: we will only plot the trajectory along times $[T-10, T]$ for $T>10$</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.6**: Use the code below to investigate sensititivy to initial conditions.  Answer the following questions:\n",
    "<ol>\n",
    "    <li> For small pertubations, eps=0.01, how long does it take to see the nearby initial conditions lose track of the control trajectory?\n",
    "    <li> Does it appear that there are parameter configurations where there are **stable** fixed points? </li>\n",
    "    <li> Does it appear that there are parameter configurations where there are **stable** periodic behaviors?  **Hint**: what pattern emerges with $\\rho = 350$?  What about $\\rho=100.5$?</li>\n",
    "    <li>When all trajectories are drawn to a limiting behavior, we call this behavior **globally stable**.  Do the periodic solutions appear to be globally or locally stable?  Try multiple values of epsilon, and consider what happens when there is more than one periodic behavior.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def animate_lorenz(sigma=SIGMA, beta=BETA, rho=RHO, N=2, eps=0.01, T=0.1):    \n",
    "    \n",
    "    # Initial conditions: perturbations around some \"proto\" state\n",
    "    seed(1)\n",
    "    x0_proto = array([-6.1, 1.2, 32.5])\n",
    "    x0 = x0_proto + eps*randn((N, 3))\n",
    "\n",
    "    # Compute trajectories\n",
    "    tt = linspace(0, T, int(T/.01)+1)               # Time instances for trajectory\n",
    "    d2 = lambda x,t: dxdt(x,t, sigma,beta,rho)      # Define dxdt(x,t) with fixed params.\n",
    "    xx = array([odeint(d2, x0i, tt) for x0i in x0]) # Integrate\n",
    "    \n",
    "    \n",
    "    # PLOTTING\n",
    "    ax = plt.figure(figsize=(16,8)).add_subplot(111, projection='3d')\n",
    "    \n",
    "    colors = plt.cm.jet(linspace(0,1,N))\n",
    "    for i in range(N):\n",
    "        # plot each ensemble member, but only the last 1000 steps of the trajectory\n",
    "        ax.plot(*(xx[i,-1000:,:].T),'-'  ,c=colors[i])\n",
    "        ax.scatter3D(*xx[i,-1,:],s=40,c=colors[i])\n",
    "\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "w = interactive(animate_lorenz, sigma=(0.,50), rho=(0.,350, .5), beta=(0.,5),\n",
    "                N=(1,10), eps=(0.01,10.01, .1),T=(0.1,100))\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the standard configuration of the Lorenz-63 model we see that small perturbations quickly diverge from control trajectories.  But even with perfect knowledge of the state of the atmosphere, our numerical approximations of its evolution would quickly degrade the forecast skill to zero.  As a proof of concept, suppose the \"<b>true</b>\" atmosphere is equal to the Lorenz-63 system, evolved via the simple <b>[forward Euler method](https://en.wikipedia.org/wiki/Euler_method)</b>, with a time step of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_true = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are given the <b>exact</b> state of the atmosphere, defined as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xyz_exact = array([-6.1, 1.2, 32.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we must use the <b>[Order 4.0 Runge-Kutta](https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods#The_Runge%E2%80%93Kutta_method)</b> scheme,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l63_rk4_step(xyz, h):\n",
    "    \"\"\" calculate the evolution of Lorenz-63 one step forward via RK-4\"\"\"\n",
    "    \n",
    "    k_xyz_1 = dxdt(xyz, h, sigma=SIGMA, beta=BETA, rho=RHO)\n",
    "    k_xyz_2 = dxdt(xyz + k_xyz_1 * (h / 2.0), h, sigma=SIGMA, beta=BETA, rho=RHO)\n",
    "    k_xyz_3 = dxdt(xyz + k_xyz_2 * (h / 2.0), h, sigma=SIGMA, beta=BETA, rho=RHO)\n",
    "    k_xyz_4 = dxdt(xyz + k_xyz_3 * h, h, sigma=SIGMA, beta=BETA, rho=RHO)\n",
    "\n",
    "    xyz_step = xyz + (h / 6.0) * (k_xyz_1 + 2 * k_xyz_2 + 2 * k_xyz_3 + k_xyz_4)\n",
    "\n",
    "    return xyz_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with a time step of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_approximate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to derive an <b>approximate forecast</b>, due to computational constraints.  Note that the discretization error of <b>both</b> the forward Euler (with time step h_true=0.0001) and the Order 4.0 Runge-Kutta (with time step h_approximate=0.1) is on the order $\\mathcal{O}\\left(10^{-4}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.8**: Use the function \"<b>dxdt</b>\" defined above to code the forward Euler method.  Fill in the missing line in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l63_forward_euler_step(xyz, h):\n",
    "    \"\"\"x_step is the one-step-forward state, derived from the initial condition xyz\"\"\"\n",
    "    \n",
    "    ### Fill in missing line here ###\n",
    "    \n",
    "    return xyz_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Example solution\n",
    "\n",
    "# show_answer('forward_euler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.10**: Verify that your solution to Exc 4.6 works, using the GUI slider below.  The following code will generate the two paths from the **same** initial condition:\n",
    "<ol>\n",
    "    <li>the \"true\" atmosphere, generated by the forward Euler scheme and time step of 0.0001;</li>\n",
    "    <li>the approximate atmospher, generated by the Runge-Kutta scheme with a time step of 0.1;</li>\n",
    "</ol>\n",
    "where the discretization error of each scheme is on the order of $\\mathcal{O}\\left(10^{-4}\\right)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def animate_approximation_divergence(T=0.1):    \n",
    "    \n",
    "    ## Compute trajectories\n",
    "    xyz_approx_step = copy.copy(xyz_exact)\n",
    "    xyz_true_step = copy.copy(xyz_exact)\n",
    "    \n",
    "    # define the number of integration steps\n",
    "    true_steps = int(T / h_true)\n",
    "    approx_steps = int(T / h_approximate)\n",
    "    \n",
    "    # define storage for the approximate trajectory\n",
    "    xyz_approx = zeros([approx_steps + 1, 3])\n",
    "    \n",
    "    # define storage for the true trajectory, but where we only store the same time steps as the approximate one\n",
    "    xyz_true = zeros([approx_steps + 1, 3])\n",
    "    \n",
    "    for i in range(approx_steps + 1):\n",
    "        # store the value for each the true and approximate trajectory\n",
    "        xyz_true[i, :] = xyz_true_step\n",
    "        xyz_approx[i, :] = xyz_approx_step\n",
    "            \n",
    "        # forward propagate the approximate trajectory only at increments of 0.1\n",
    "        xyz_approx_step = l63_rk4_step(xyz_approx_step, h_approximate)\n",
    "        \n",
    "        for j in range(1000):\n",
    "            # forward propagate the true trajectory at every step of 0.0001\n",
    "            xyz_true_step = l63_forward_euler_step(xyz_true_step, h_true)\n",
    "        \n",
    "            \n",
    "            \n",
    "    # PLOTTING\n",
    "    ax = plt.figure(figsize=(10,5)).add_subplot(111, projection='3d')\n",
    "    xx = np.dstack([xyz_true, xyz_approx])\n",
    "    \n",
    "    colors = plt.cm.jet(linspace(0,1,2))\n",
    "    for i in range(2):\n",
    "        # plot each of the trajectories, integrated with separate rules\n",
    "        ax.plot(*(xx[-4:,:,i].T),'-'  ,c=colors[i])\n",
    "        ax.scatter3D(*xx[-1,:,i], s=40, c=colors[i])\n",
    "\n",
    "    ax.set_xlim((-15, 15))\n",
    "    ax.set_ylim((-25, 25))\n",
    "    ax.set_zlim((15, 40))\n",
    "    ax.view_init(30, 120)\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "w = interactive(animate_approximation_divergence, T=(0.4,4))\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exc 4.12**: What do you notice about this plot?  What does this say about small simulation errors in chaotic systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics of perturbations\n",
    "\n",
    "In the following, we will neglect the important issues of model deficiencies and the inherent stochasticity of certain dynamics.  Instead, we will focus on the simplified scenario where we assume:\n",
    "<ul>\n",
    "    <li> we can perfectly model and compute the purely deterministic dynamics; and</li>\n",
    "    <li> prediction error originates soley from the uncertainty in initial conditions.</li>\n",
    "</ul>\n",
    "\n",
    "Understanding that perturbations rapidly diverge even in a chaotic system as described above, this led to the transition from single-trajectory forecasts to ensemble-based forecasts.   Ensembles are used to \"average out\" our initialization errors, and to understand the variability and uncertainty in forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantages of ensemble based forecasts over single trajectory forecasts historically led to a search for perturbations that are most representative of the error growth in operational forecasts.  Prediction centers have sought to initialize ensemble-based forecasts in a way to best capture the variability induced by the dynamical chaos.  Two major techniques emerged,\n",
    "<ol>\n",
    "   <li> \"<b>[bred vectors](https://journals.ametsoc.org/doi/abs/10.1175/1520-0477%281993%29074%3C2317%3AEFANTG%3E2.0.CO%3B2)</b>\", and </li>\n",
    "   <li> \"<b>[forcing singular vectors](https://onlinelibrary.wiley.com/doi/abs/10.1034/j.1600-0870.1993.t01-4-00005.x)</b>\". </li>\n",
    "</ol>\n",
    "   \n",
    "\n",
    "These lead to different formulations of the classical \"<b>[Lyapunov vectors](http://www.lmd.ens.fr/legras/publis/liapunov.pdf)</b>\".  We do not stress here what a \"Lyapunov vector\" is, rather we will discover their nature experimentally in the following work.  This will lead to a formal definition of <em>one type</em> of Lyapunov vectors by the end of the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Breeding\" growing modes\n",
    "\n",
    "Suppose we have a smooth, nonlinear dynamical system,\n",
    "<h3>\n",
    "$$\n",
    "\\begin{align}\n",
    "\\dot{\\mathbf{x}} = f(\\mathbf{x}) & & \\mathbf{x} \\in \\mathbb{R}^n,\n",
    "\\end{align}\n",
    "$$\n",
    "</h3>\n",
    "and a precise estimate of an initial condition <span style='font-size:1.25em'>$\\mathbf{x}^c_0$</span>, from which we want to make a forecast.  Suppose, also, that there are future observations that we will assimilate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was suggested by Toth and Kalnay to use the evolution of the initial estimate <span style='font-size:1.25em'>$\\mathbf{x}^c_0$</span> as a control trajectory, while introducing small perturbations to generate an ensemble,\n",
    "<h3>\n",
    "$$\\begin{align}\n",
    "\\mathbf{x}^i_0 = \\mathbf{x}^c_0 + \\boldsymbol{\\delta}^i_0 \n",
    "\\end{align}$$\n",
    "</h3>\n",
    "where <span style='font-size:1.25em'>$\\left \\rvert \\boldsymbol{\\delta}^i \\right \\rvert  = \\epsilon \\ll 1$</span>.\n",
    "\n",
    "The ensemble is evolved in parallel to the control trajectory.  Between times $t_{k-1}$ and $t_k$, this takes the form\n",
    "<h3>\n",
    "$$\\begin{align}\n",
    "\\widehat{\\mathbf{x}}^c_k &= \\mathbf{x}_{k-1}^c + \\int_{t_{k-1}}^{t_k} f(x) {\\rm d}t \\\\\n",
    "\\widehat{\\mathbf{x}}^i_k &= \\mathbf{x}_{k-1}^i + \\int_{t_{k-1}}^{t_k} f(x) {\\rm d}t.\n",
    "\\end{align}\n",
    "$$\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the point of analyzing new observations we form a new estimate for the control trajectory, taking <span style='font-size:1.25em'>$\\widehat{\\mathbf{x}}_k^c$</span> to <span style='font-size:1.25em'>$\\mathbf{x}_k^c$</span>. the perturbations are rescaled back to their original small size while maintaining their <em>directions</em>.  That is to say,\n",
    "<h3>\n",
    "$$\n",
    "\\begin{align}\n",
    "\\widehat{\\boldsymbol{\\delta}}_k^i \\triangleq \\mathbf{x}_k^c - \\widehat{\\mathbf{x}}_k^i, & &\n",
    "\\boldsymbol{\\delta}_k^i \\triangleq \\frac{\\epsilon}{\\left\\rvert \\widehat{\\boldsymbol{\\delta}}^i_k\\right\\rvert} \\widehat{\\boldsymbol{\\delta}}^i_k.\n",
    "\\end{align}\n",
    "$$\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='breeding'>\"Breeding growing modes\"</a> is designed to simulate how the modes of fast growing error are maintained and propagated through the successive use of short range forecasts.  The resulting perturbations are thus meant to represent a perturbation field of the \"errors of the day\", i.e., uncertainties in the initial condition at the present time that result from the repeated cycle of forecasts and analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.14**: Run the code below and use the sliders to examine behavior of successive \"breeding\" of growing modes. The parameter **B** stands for the number of breeding cycles.  The parameter **eps** stands for the re-scaling parameter <span style='font-size:1.25em'>$\\epsilon$</span> defined above.  The parameter **N** is the number of perturbations.  \n",
    "\n",
    "The the plots on the left hand side show the evolution of the control trajectory and the perturbed trajectories along each breeding cycle.  The right hand side plots $\\pm 1$ times the normalized perturbations,\n",
    "<h3>\n",
    "$$\n",
    " \\frac{ \\pm\\widehat{\\boldsymbol{\\delta}}_k^i}{\\left\\rvert \\widehat{\\boldsymbol{\\delta}}^i_k\\right\\rvert},\n",
    "$$\n",
    "</h3>\n",
    "giving the **directions** of the perturbations, plotted as lines through the unit sphere. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the following questions**:\n",
    "<ol>\n",
    "    <li> For small values of <span style='font-size:1.25em'>$\\epsilon$</span>, what is significant about the long term behavior of the directions of the perturbations? </li>\n",
    "    <li> Does this behavior change with large <b>N</b>, i.e., more directions for the pertubations? </li>\n",
    "    <li> How does this behavior change when <span style='font-size:1.25em'>$\\epsilon$</span> is increased?  Do the directions of the perturbations depend on **N** for large <span style='font-size:1.25em'>$\\epsilon$</span>?\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def animate_bred_vectors(B=0, eps=0.01, N=10):    \n",
    "    \n",
    "    # Initial conditions: perturbations around some \"proto\" state\n",
    "    sigma=SIGMA \n",
    "    beta=BETA \n",
    "    rho=RHO\n",
    "    T=0.05\n",
    "    \n",
    "    seed(1)\n",
    "    x_0 = array([-6.1, 1.2, 32.5])               # define the control\n",
    "    \n",
    "    # define the perturbations, randomly generated but of fixed norm epsilon\n",
    "    perts = randn([N,3])\n",
    "    perts = array([eps * perts[i] / sqrt(perts[i] @ perts[i]) for i in range(N)])\n",
    "    delta_x = x_0 + perts\n",
    "                  \n",
    "    tt = linspace(0, T, 10)           # Time instances for trajectory\n",
    "    d2 = lambda x,t: dxdt(x,t, sigma,beta,rho)  # Define dxdt(x,t) with fixed params.    \n",
    "    \n",
    "    # for each breeding cycle\n",
    "    for kk in range(B):\n",
    "        # Compute trajectories\n",
    "        x_traj = array([odeint(d2, x_0, tt)])        # integrate the control trajectory\n",
    "        x_0 = np.squeeze(x_traj[:, -1, :])\n",
    "        \n",
    "        delta_x_traj = array([odeint(d2, delta_xi, tt) for delta_xi in delta_x]) # Integrate the perturbations\n",
    "        perts = delta_x_traj[:, -1, :] - x_0                                     # redefine the perts\n",
    "        perts = array([eps * perts[i] / sqrt(perts[i] @ perts[i]) for i in range(N)])\n",
    "        delta_x = x_0 + perts # redefine the initialization of the perturbed trajectories\n",
    "    \n",
    "    # PLOTTING\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax1 = plt.subplot(121, projection='3d')\n",
    "    ax2 = plt.subplot(122, projection='3d')\n",
    "    \n",
    "    if B==0:\n",
    "        ax1.scatter3D(*x_0, s=40, c='k')\n",
    "\n",
    "    else:\n",
    "        ax1.plot(*x_traj[0,:,:].T, '-', c='k')\n",
    "        ax1.scatter3D(*x_traj[0,-1,:].T, '-', s=40, c='k')\n",
    "            \n",
    "    colors = plt.cm.jet(linspace(0,1,N))\n",
    "    for i in range(N):\n",
    "        # for each breeding cycle\n",
    "        if B==0:\n",
    "            # if just the initial conditions, we plot these\n",
    "            ax1.scatter3D(*delta_x[i,:],s=40,c=colors[i])\n",
    "            \n",
    "        else:\n",
    "            # otherwise, plot the trajectories over a breeding cycle\n",
    "            ax1.plot(*(delta_x_traj[i,:,:].T),'-'  ,c=colors[i])\n",
    "            ax1.scatter3D(*delta_x_traj[i,-1,:],s=40,c=colors[i])\n",
    "                          \n",
    "        # we plot the normalized perturbations on the unit sphere\n",
    "        tmp = perts[i,:]/sqrt(perts[i,:] @ perts[i, :])\n",
    "        p_vect = np.concatenate([np.reshape([0,0,0],[1,3]), np.reshape(tmp,[1,3])], axis=0)\n",
    "        \n",
    "        # delta * +1\n",
    "        ax2.plot(p_vect[:,0], p_vect[:,1], p_vect[:,2],'-'  ,c=colors[i])\n",
    "        ax2.scatter3D(*tmp[:],s=40,c=colors[i], marker='o')\n",
    "\n",
    "        # delta * -1\n",
    "        ax2.plot(-1*p_vect[:,0], -1*p_vect[:,1], -1*p_vect[:,2],'-'  ,c=colors[i])\n",
    "        ax2.scatter3D(*tmp[:]*(-1),s=40,c=colors[i], marker='o')\n",
    "\n",
    "    ax1.axis('off')\n",
    "    ax2.set_xlim((-.9, .9))\n",
    "    ax2.set_ylim((-.9, .9))\n",
    "    ax2.set_zlim((-.9, .9))\n",
    "    plt.show()\n",
    "    \n",
    "w = interactive(animate_bred_vectors,B=(0,175,25), eps=(0.01,1.61, .2), N=(1, 161, 20))\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.16**: If the \"breeding\" of perturbations is meant to represent the unstable growth of initial perturbations, what can we learn from their growth rates?  In the following code, fill in the missing lines to define a function that will compute the log-growth rate of the perturbation <span style='font-size:1.25em'>$\\boldsymbol{\\delta^i}_k$</span>, i.e., the log growth relative to the length of time in the breeding interval.  This function should return\n",
    "<h3>\n",
    "$$\\begin{align}\n",
    "\\frac{1}{T}\\log \\left( \\frac{\\left\\rvert \\widehat{\\boldsymbol{\\delta}}^i_k\\right \\rvert}{\\left\\rvert \\boldsymbol{\\delta}_{k-1}^i \\right\\rvert}\\right) \\equiv \\frac{1}{T}\\log \\left( \\frac{\\left\\rvert \\widehat{\\boldsymbol{\\delta}}^i_k\\right \\rvert}{\\epsilon}\\right),\n",
    "\\end{align}$$\n",
    "</h3>\n",
    "for a single perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_growth(x_control_k, x_pert_k, T, eps):\n",
    "    \"\"\"function returns array of the log growth values for a single perturbation\"\"\"\n",
    "    \n",
    "    \n",
    "    ### Fill in missing line(s) here ###\n",
    "    \n",
    "    return log_growth_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Example solution\n",
    "\n",
    "# show_answer('log_growth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.18**: Test your answer to **Exc 4.16**.  Using the code and slider below, investigate the distributions of the log-growth rates of the bred vectors as a function of the number of breeding cycles.  Answer the following questions:\n",
    "<ol>\n",
    "    <li> What is the long term behaviour of this distribution?</li>\n",
    "    <li> The leading Lyapunov exponent of the Lorenz-63 system is $\\approx 0.9050$, what do you notice about the mean of the log-growth rates over a long number of breeding cycles?</li>\n",
    "    <li> Consider the behavior of small perturbations from **Exc 4.14**. Can you conjecture what the perturbations are converging to?</li>\n",
    "    <li> What does this suggest about the \"representative perturbations\" for the error growth in chaotic systems?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def animate_bred_growth_rates(B=1000):    \n",
    "    \n",
    "    # Initial conditions: perturbations around some \"proto\" state\n",
    "    sigma=SIGMA \n",
    "    beta=BETA \n",
    "    rho=RHO\n",
    "    eps=0.01\n",
    "    N=1\n",
    "    T=0.01\n",
    "    \n",
    "    seed(1)\n",
    "    x_0 = array([-6.1, 1.2, 32.5])               # define the control\n",
    "    \n",
    "    # define the perturbation, randomly generated but of fixed norm epsilon\n",
    "    perts = randn(3)\n",
    "    perts = eps * perts / sqrt(perts @ perts)\n",
    "    delta_x = x_0 + perts\n",
    "                  \n",
    "    tt = linspace(0, T, 20)           # Time instances for trajectory\n",
    "    d2 = lambda x,t: dxdt(x,t, sigma,beta,rho)  # Define dxdt(x,t) with fixed params.    \n",
    "    grwt = np.zeros(B)\n",
    "    \n",
    "    \n",
    "    # for each breeding cycle\n",
    "    for kk in range(B):\n",
    "        # Compute trajectories\n",
    "        x_traj = array([odeint(d2, x_0, tt)])        # integrate the control trajectory\n",
    "        x_0 = np.squeeze(x_traj[:, -1, :])\n",
    "        \n",
    "        delta_x_traj = array([odeint(d2, delta_x, tt)]) # Integrate the perturbation\n",
    "        \n",
    "        # compute the log growth from the code defined earlier\n",
    "        grwt[kk] = log_growth(x_0, delta_x_traj[0, -1, :], T, eps)\n",
    "        \n",
    "        # redefine perts\n",
    "        perts = delta_x_traj[0, -1, :] - x_0\n",
    "        perts = eps * perts / sqrt(perts @ perts.T) \n",
    "        delta_x = x_0 + perts\n",
    "    \n",
    "    # PLOTTING\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.hist(grwt, bins=linspace(-20,20,4001), normed=True)\n",
    "    ax.set_xlim((-12, 12))\n",
    "    ax.set_ylim((0, 0.8))\n",
    "    ax.text(4, 0.6, 'Mean log-growth rate=' + str(np.round(mean(grwt),decimals=4)).zfill(4), size=20)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "w = interactive(animate_bred_growth_rates,B=(1000,30000, 5800))\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lyapunov exponents and eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Lypunov exponent** can be understood loosely as a kind of generalized eigenvalue for time-depenent linear transformations, or for the linearization of a nonlinear evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do eigenvalues tell us about a matrix and why might the above results seem intuitive? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the <a id='perturbation_equation'>equation for the <em>evolution</em> of the pertubation <span style='font-size:1.25em'>$\\boldsymbol{\\delta}^i_k$</span></a>.  We can write,\n",
    "<h3>\n",
    "$$\\begin{align}\n",
    "& \\boldsymbol{\\delta}_k^i = \\mathbf{x}_k^c - \\mathbf{x}_k^i \\\\\n",
    "\\Rightarrow & \\dot{\\boldsymbol{\\delta}}_k^i = f(\\mathbf{x}_k^c) - f(\\mathbf{x}_k^i).\n",
    "\\end{align}$$\n",
    "</h3>\n",
    "But for small perturbations, we can reasonably make an approximation with a Taylor expansion,\n",
    "<h3>\n",
    "$$\\begin{align}\n",
    " f(\\mathbf{x}_k^c) - f(\\mathbf{x}_k^i) \\approx \\nabla f\\rvert_{\\mathbf{x}c}  \\boldsymbol{\\delta}^i_k, & &   \n",
    "\\end{align}$$\n",
    "</h3> \n",
    "where the term, \n",
    "<h2>\n",
    "$$f\\rvert_{\\mathbf{x}c}$$\n",
    "</h2>\n",
    "is the gradient with respect to the state variables, i.e., the **[Jacobian matrix](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant)**, evaluated at the control trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that for small perturbations, the evolution is well approximated by the linear Jacobian equations, and we can think of these linear equations having some kind of generalized eigenvalues, describing the invariant (exponential) growth and decay rates for the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The power method\n",
    "\n",
    "The method of breeding errors above is conceptually very similar to the classical [power method](https://en.wikipedia.org/wiki/Power_iteration) for finding the leading eigenvalue of a diagonalizable matrix:\n",
    "\n",
    "* Suppose <span style='font-size:1.25em'>$\\mathbf{M}\\in\\mathbb{R}^{n\\times n}$</span> is a diagonalizable matrix, with eigenvalues,\n",
    "<h3>\n",
    "$$\n",
    "\\rvert \\mu_1 \\rvert > \\rvert\\mu_2\\rvert \\geq \\cdots \\geq \\rvert\\mu_n\\rvert,\n",
    "$$\n",
    "</h3>\n",
    "i.e., <span style='font-size:1.25em'>$\\mathbf{M}$</span> has a single eigenvalue of magnitude greather than all its others.   \n",
    "\n",
    "* Let <span style='font-size:1.25em'>$\\mathbf{v}_0 \\in \\mathbb{R}^n$</span> be a randomly selected vector, with respect to the Gaussian distribution on <span style='font-size:1.25em'>$\\mathbb{R}^n$</span>. \n",
    "\n",
    "* We define the algorithm,\n",
    "<h3>\n",
    "$$\\begin{align}\n",
    "\\mathbf{v}_{k+1} \\triangleq \\frac{\\mathbf{M} \\mathbf{v}_k}{ \\left\\rvert \\mathbf{M} \\mathbf{v}_k\\right\\rvert} & &\n",
    "\\widehat{\\mu}_{k+1} \\triangleq \\mathbf{v}_{k+1}^{\\rm T} \\mathbf{M} \\mathbf{v}_{k+1} \n",
    "\\end{align}$$\n",
    "</h3>\n",
    "as the power method.  \n",
    "\n",
    "It is easy to verify that with probability one, the sequence <span style='font-size:1.25em'>$\\widehat{\\mu}_k$</span> converges to the dominant eigenvalue, <span style='font-size:1.25em'>$\\mu_1$</span>, and <span style='font-size:1.25em'>$\\mathbf{v}_k$</span> converges to an eigenvector for the dominant eigenvalue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.20**: Fill in the code below to write an algorithm for the power method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def power_method(M, v, number_iterations):\n",
    "    \"\"\"takes a diagonalizable matrix M and returns approximations for the leading eigenvector/eigenvalue\"\"\"\n",
    "    \n",
    "    for i in range(number_iterations):\n",
    "        ### fill in missing lines here\n",
    "       \n",
    "    return v, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example solution\n",
    "\n",
    "# show_answer('power_method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.22**: Test your solution to **Exc 4.20**.  Use the code and slider below to study the rate of convergence.  In this case, the matrix will have eigenvalues \n",
    "<h3>$$\\begin{align}\n",
    "\\left\\{r^i : \\hspace{2mm} i =0, 1, 2, \\hspace{2mm} \\text{and} \\hspace{2mm} r\\in(1,2]\\right\\}\n",
    "\\end{align}$$</h3>\n",
    "The parameter <span style='font-size:1.25em'>$k$</span> defines how many iterations of the power method are computed.  How does the value <span style='font-size:1.25em'>$r$</span> affect the number of iterations necessary to reach convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def animate_power_convergence_rate(k=1, r=1.5):    \n",
    "    \n",
    "    # We define a well conditioned matrix M, depending on the ratio of the eigenvalues\n",
    "    M = array([r ** i for i in range(3)])\n",
    "    M = np.diag(M)\n",
    "    e_3 = array([0, 0, 1])\n",
    "\n",
    "    # define a random initial condition\n",
    "    np.random.seed(0)\n",
    "    v = randn(3)\n",
    "    v = v / sqrt(v.T @ v)\n",
    "    \n",
    "    # and storage for the series of approximations\n",
    "    v_hist = zeros(k+1)\n",
    "    v_hist[0] = e_3.T @ v \n",
    "    \n",
    "    mu_hist = zeros(k+1)\n",
    "    mu_hist[0] = v.T @ M @ v\n",
    "    \n",
    "    # for the number of iterations k, return the power method approximation\n",
    "    for it in range(1,k+1):\n",
    "        np.random.seed(0)\n",
    "        v, mu = power_method(M, v, it)\n",
    "        v_hist[it] = np.arccos(e_3.T @ v)\n",
    "        mu_hist[it] = mu\n",
    "     \n",
    "    # PLOTTING\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax2 = plt.subplot(122)\n",
    "    ax1.plot(range(0,k+1), v_hist)\n",
    "    ax2.plot(range(0,k+1), mu_hist)\n",
    "    ax1.set_ybound([0,1.05])\n",
    "    ax2.set_ybound([.9,4])\n",
    "    \n",
    "    t_scl = np.floor_divide(k+1, 10)\n",
    "    \n",
    "    ax1.set_xticks(range(0, k+1, t_scl + 1))\n",
    "    ax2.set_xticks(range(0, k+1, t_scl + 1))\n",
    "    \n",
    "    ax1.text(0, 1.07, r'Angle between $\\mathbf{v}_k$ and eigenvector', size=20)\n",
    "    ax2.text(0, 4.05, r'Value of $\\mu_k$', size=20)\n",
    "    ax1.tick_params(\n",
    "        labelsize=20)\n",
    "    ax2.tick_params(\n",
    "        labelsize=20)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "w = interactive(animate_power_convergence_rate, k=(1,15), r=(1.05,2, .05))\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.24.a **: Suppose the power method is performed on a generic diagonalizable matrix <span style='font-size:1.25em'>$\\mathbf{M}\\in\\mathbb{R}^{n\\times n}$</span>, with eigenvalues\n",
    "<h3>$$\\begin{align}\n",
    "\\rvert \\mu_1 \\rvert > \\rvert\\mu_2 \\rvert\\geq \\cdots \\geq \\rvert\\mu_n \\rvert,\n",
    "\\end{align}$$</h3>\n",
    "with a randomly selected initial vector <span style='font-size:1.25em'>$\\mathbf{v}_0$</span>, with respect to the Gaussian distribution on <span style='font-size:1.25em'>$\\mathbb{R}^n$</span>.\n",
    "\n",
    "Can you conjecture what is the order of convegence for the sequences <span style='font-size:1.25em'>$\\mathbf{v}_k$</span> and <span style='font-size:1.25em'>$\\widehat{\\mu}_k$</span>? \n",
    "\n",
    "**Hint**: the rate depends on the eigenvalues.\n",
    "\n",
    "**Exc 4.42.b***: Prove the rate of convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "# show_answer('power_method_convergence_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exc 4.28* **: We have brushed over why the algorithm described above converges with *probability one*, can you prove why this is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "# show_answer('probability_one')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exc 4.30.a **: Let <span style='font-size:1.25em'>$\\widehat{\\mu}_k$</span> be defined as in **Exc 4.24**.  Suppose we define a sequence of values,\n",
    "<h3>$$\\begin{align}\n",
    "\\widehat{\\lambda}_T = \\frac{1}{T} \\sum_{k=1}^T\\log\\left(\\rvert \\widehat{\\mu}_k\\right \\rvert).\n",
    "\\end{align}$$</h3>\n",
    "Answer the following:\n",
    "<ol>\n",
    "  <li> Can you conjecture what <span style='font-size:1.25em'>$\\widehat{\\lambda}_T$</span> converges to as <span style='font-size:1.25em'>$T \\rightarrow \\infty$</span>?  \n",
    "  \n",
    "  **Hint**: Use the fact that <span style='font-size:1.25em'>$\\widehat{\\mu}_k \\rightarrow \\mu_1$</span> as <span style='font-size:1.25em'>$k \\rightarrow \\infty$</span></li>\n",
    "  \n",
    "  <li> Suppose we define the Lyapunov exponents as the log-average growth rates of the matrix <span style='font-size:1.25em'>$\\mathbf{M}$</span>.  What can you guess about the relationship between the eigenvalues and the Lyapunov exponents of the matrix <span style='font-size:1.25em'>$\\mathbf{M}$</span>?</li>\n",
    "<ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exc 4.30.b* **: Prove that the limit\n",
    "<h3>$$\\begin{align}\n",
    "\\lim_{T \\rightarrow \\infty} \\widehat{\\lambda}_T\n",
    "\\end{align}$$</h3>\n",
    "exists, and what quantity it converges to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answers\n",
    "\n",
    "# show_answer('lyapunov_exp_power_method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The QR algorithm\n",
    "\n",
    "The power method is an intuitive method for finding the dominant eigenvalue for a special class of matrices.  However, we generally want to find directions that may also be growing, though more slowly than the dominant direction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, if we are tracking a control trajectory with data assimilation and we corrected the forecast errors only in the direction of dominant error growth, we may still lose track of the control trajectory, only it would be more slowly than the dominant rate of growth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a simple generalization of the power method for finding higher dimensional subspaces.  We may consider *separating* perturbations into directions that grow at different rates.  One easy way to perform this is to construct a *moving frame* in the span of the perturbations.  If there is only one perturbation, then the power method constructs precisely a 1-dimensional moving frame, with a vector that is always of norm 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are two perturbations we can construct a moving frame in the span of the perturbations with a [Gram-Schmidt](https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process) step.  A visualization of the Gram-Schmidt process for three vectors is picuted in the visualization below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:900px'>\n",
    "<img src=\"./resources/Gram-Schmidt_orthonormalization_process.gif\">\n",
    "</div>\n",
    "\n",
    "**By Lucas V. Barbosa [Public domain], <a href=\"https://commons.wikimedia.org/wiki/File:Gram-Schmidt_orthonormalization_process.gif\">from Wikimedia Commons</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, suppose we have two initial, orthogonal vectors\n",
    "<h3>$$\n",
    "\\mathbf{x}_0^1, \\mathbf{x}_0^2\n",
    "$$</h3>\n",
    "which we will propagate forward.  We define for each $j=1,2$,\n",
    "<h3>$$\n",
    "\\widehat{\\mathbf{x}}^j_1 \\triangleq \\mathbf{M} \\mathbf{x}^j_0.\n",
    "$$</h3>\n",
    "The first vector will follow the usual power method, i.e.,\n",
    "<h3>$$\n",
    "\\mathbf{x}^1_1 \\triangleq \\frac{\\widehat{\\mathbf{x}}_1^1}{\\left\\rvert \\widehat{\\mathbf{x}}_1^1\\right\\rvert},\n",
    "$$</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we want to separate the second vector <span style='font-size:1.25em'>$\\widehat{\\mathbf{x}}_1^2$</span> so the new perturbations don't align.  We thus remove the components in the direction of <span style='font-size:1.25em'>$\\mathbf{x}_1^1$</span>, before we normalize <span style='font-size:1.25em'>$\\widehat{\\mathbf{x}}_1^2$</span>.  \n",
    "<h3>$$\\begin{align}\n",
    "\\mathbf{y}^2_1 &\\triangleq \\widehat{\\mathbf{x}}_1^2- \\langle \\mathbf{x}_1^1,  \\widehat{\\mathbf{x}}^2_1\\rangle \\mathbf{x}_1^1 \\\\\n",
    "\\mathbf{x}^2_1 & \\triangleq \\frac{\\mathbf{y}_1^2}{\\left\\rvert \\mathbf{y}_1^2 \\right\\rvert}\n",
    "\\end{align}$$</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to see by definition that <span style='font-size:1.25em'>$\\mathbf{x}_1^1, \\mathbf{x}_1^2$</span> are orthogonal, but we can also show an important dynamical property with this transformation.  Define the following coefficients,\n",
    "<h3>$$\n",
    "\\begin{align}\n",
    "U^{11}_1 &=\\left\\rvert \\widehat{\\mathbf{x}}_1^1\\right\\rvert \\\\\n",
    "U^{22}_1 &=\\left\\rvert \\mathbf{y}_1^2 \\right\\rvert \\\\\n",
    "U^{12}_1 &= \\langle \\mathbf{x}^1_1, \\mathbf{x}_1^2\\rangle \n",
    "\\end{align}\n",
    "$$<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.32**: Can you write the recursion for the vectors <span style='font-size:1.25em'>$\\mathbf{x}_0^1, \\mathbf{x}_0^2$</span> transformed into <span style='font-size:1.25em'>$\\mathbf{x}_1^1,\\mathbf{x}_1^2$</span> with the coefficients <span style='font-size:1.25em'>$U^{ij}_1$</span> defined above in matrix form?  Can you write the recursion for an arbitrary number of steps $k\\in\\{1,2,\\cdots\\}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "# show_answer('gram-schmidt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above procedure defines the *naive* QR algorithm --- one should note that there are more computationally efficient versions of this algorithm utilized in standard linear algebra software libraries.  However, this simple intuition forms the basis for many powerful theoretical results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QR algorithm (in its refined version) is the standard method for computing the <b>[Schur decomposition](https://en.wikipedia.org/wiki/Schur_decomposition)</b> for a matrix, which is used for many purposes as it is a numerically stable alternative to the <b>[Jordan Cannonical Form](https://en.wikipedia.org/wiki/Jordan_normal_form)</b>, pictued below:\n",
    "\n",
    "<div style='width:900px'>\n",
    "<img src=\"./resources/Jordan_blocks.svg\">\n",
    "</div>\n",
    "\n",
    "**By Jakob.scholbach [<a href=\"https://creativecommons.org/licenses/by-sa/3.0\">CC BY-SA 3.0</a> or <a href=\"http://www.gnu.org/copyleft/fdl.html\">GFDL</a>], <a href=\"https://commons.wikimedia.org/wiki/File:Jordan_blocks.svg\">from Wikimedia Commons</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jordan Canonical form is highly appealing as it is the diagonal or \"almost-diagonal\" form of a matrix.  However, this is highly unstable to compute in most applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Schur decomposition relaxes this further, from \"almost-diagonal\" to upper triangular, another useful form for a matrix.  In particular, the Schur decomposition is one approach to find **all eigenvalues** for a matrix, separated into a **chain of descending growth and decay rates**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exc 4.34**: Suppose a matrix <span style='font-size:1.25em'>$\\mathbf{M}$</span> has a Schur decomposition, given as,\n",
    "<h3> $$ \\begin{align}\n",
    "\\mathbf{M} = \\mathbf{Q} \\mathbf{U} \\mathbf{Q}^{\\rm T},\n",
    "\\end{align}$$ </h3>\n",
    "where <span style='font-size:1.25em'>$\\mathbf{U}$</span> is strictly upper triangular, and <span style='font-size:1.25em'>$\\mathbf{Q}$</span> is orthogonal such that <span style='font-size:1.25em'>$\\mathbf{Q}^{\\rm T} = \\mathbf{Q}^{-1}$</span>.  Can you prove that the eigenvalues of <span style='font-size:1.25em'>$\\mathbf{M}$</span> are the diagonal elements of <span style='font-size:1.25em'>$\\mathbf{U}$?</span> \n",
    "\n",
    "If <span style='font-size:1.25em'>$\\mathbf{Q}^j$</span> is the $j$-th column of <span style='font-size:1.25em'>$\\mathbf{Q}^j$</span>, what does the product\n",
    "<h3>$$\\begin{align}\n",
    "\\left(\\mathbf{Q}^j\\right)^{\\rm T} \\mathbf{M} \\mathbf{Q}^j\n",
    "\\end{align}$$</h3>\n",
    "equal in terms of the earlier quantities? ** Hint**: how does this relate to the power method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "# show_answer('schur_decomposition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exc 4.36**: Can you conjecture what the Schur decomposition will take in the case that the matrix <span style='font-size:1.25em'>$\\mathbf{M}$</span> has complex eigenvalues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "# show_answer('real_schur')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A construction for Lyapunov exponents and \"Lyapunov vectors\"\n",
    "\n",
    "We return now to the discussion of perturbations in nonlinear models.  Recall the [equations](#perturbation_equation) for the evolution of perturbations.  We may define *linear* dynamics, generated by the Jacobian equation,\n",
    "<h2>$$\\begin{align}\n",
    "\\frac{{\\rm d} \\mathbf{x}}{{\\rm d} t} = \\nabla f_{\\rvert_{\\mathbf{x}c}},\n",
    "\\end{align}$$</h2>\n",
    "computed along some control trajectory <span style='font-size:1.25em'> $\\mathbf{x}^c(t)$</span>.  This system of equations is known as the <b>[tangent-linear model](http://glossary.ametsoc.org/wiki/Tangent_linear_model)</b>.  The tangent space can be understood as the **space of perturbations** at a point (or along a trajectory).  It can be used to define a vector field on a \"space\" describing the time evolution of trajectories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:900px'>\n",
    "<img src=\"./resources/Tangentialvektor.svg\">\n",
    "</div>\n",
    "\n",
    "**By derivative work: McSush (talk)Tangentialvektor.png: TNThe original uploader was TN at German Wikipedia (Tangentialvektor.png) [Public domain], <a href=\"https://commons.wikimedia.org/wiki/File:Tangentialvektor.svg\">via Wikimedia Commons</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen with the [breeding of errors](#breeding), we can compute the log-average growth rate of the dominant growing mode of the tangent-linear model to approximate the leading Lyapunov exponent.  In a linear system, with fixed matrix <span style='font-size:1.25em'> $\\mathbf{M}$</span> this corresponds exactly to taking the log-average growth rate in the power method.  Recall the generalization of the power method to the QR algorithm.  We might hope to find **all of the log-average growth rates** in the tangent-linear model by computing the log averages of the diagonal elements in the QR factors <span style='font-size:1.25em'> $\\mathbf{U}_k$</span>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the Gram-Schmidt factors form a basis for the tangent linear model where:\n",
    "<ol>\n",
    "    <li> the leading vector aligns with the dominant growth mode;</li>\n",
    "    <li> the subsequent vectors separate out the lower order growth rates.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the tangent-linear model is computed discretely in time, where <span style=font-size:1.25em> $\\textbf{M}_k$</span> takes the perturbations at time <span style=font-size:1.25em>$t_{k-1}$</span> to time <span style=font-size:1.25em>$t_k$</span>.  Suppose that in matrix form, <span style=font-size:1.25em>$\\mathbf{M}_k$</span>, produces the following QR factorization,\n",
    "<h3>$$\\begin{align}\n",
    "\\mathbf{M}_k \\mathbf{E}_{k-1} &= \\mathbf{E}_k \\mathbf{U}_k\n",
    "\\end{align}$$</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 4.36**: Suggest a constructive definition for:\n",
    "<ol>\n",
    "    <li> the Lyapunov exponents of the nonlinear model</li>\n",
    "    <li> the \"Lyapunov vectors\" </li>\n",
    "</ol>\n",
    "**Note:** We will not stress yet what kind of Lyapunov vector we are constructing.  It turns out that Lyapunov exponents are generally **globally defined**, but there are several types of Lyapunov vectors that are locally defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer \n",
    "\n",
    "# show_answer('lyapunov_vs_es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of vector this construction leads to is the **\"backward\" Lyapunov vectors**.  They are denoted \"backward\" because they contain information from the in the past, leading to the current time, i.e., the \"errors of the day\" described by Toth and Kalnay.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, we remark that the forcing singular vectors mentioned above can be shown to converge to the \"forward\" Lyapunov vectors.  These are denoted \"forward\" because they contain information about the future evolution of pertubations, pulled back to the current time.  A third type of Lyapunov vector is also often studied, which are called \"covariant\".  Similar to how eigenvectors always are mapped to a scaled copy of themselves, covariant vectors share an analogous property with respect to time-varying dynamics.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full discussion of the significance of forward, backward, and covariant vectors goes well beyond the scope of this tutorial.  For a comprehensive discussion of Lyapunov theory, aimed at practicioners, it is recommended to read the work of [Legras & Vautard](http://www.lmd.ens.fr/legras/publis/liapunov.pdf) and [Kutpsov & Parlitz](https://arxiv.org/abs/1105.5228)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble based covariances\n",
    "\n",
    "When we restrict the forecasting problem to the situation where we assume:\n",
    "<ul>\n",
    "    <li> we can perfectly model and compute the purely deterministic dynamics; and</li>\n",
    "    <li> prediction error originates soley from the uncertainty in initial conditions,</li>\n",
    "</ul> \n",
    "it is realistic to think of the data assimilation problem as tracking the evolution of perturbations along a control trajectory.  This control trajectory is the \"true\" state of the dynamical system we are studying, which we receive observations of, and try to predict the behavior of at future times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we suppose we have a prior distribution for the state of the dynamical system.  Suppose we sample for an ensemble of \"nearby\" initial conditions.  If the ensemble remains sufficiently close to the control trajectory, and we can use the [approximation for the evolution of perturbations](#perturbation_equation) to accurately model the forecast errors, then the ensemble spread will be characterized by the backward Lyapunov vectors and their growth and decay rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the conceptual image below.  Suppose the initial prior covariance is given by the unit disk, centered on the \"true\" state of a dynamical system.  If the evolution of uncertainty can be well approximated by the tangent linear model along the \"truth\", we will expect the covariance to stretch and deform into an ellipse according to the directions of **growth** and **decay**.\n",
    "<div style='width:800px'>\n",
    "<img src=\"./resources/LyapunovDiagram.svg\">\n",
    "</div>\n",
    "**By Mrocklin (original creation) [<a href=\"https://creativecommons.org/licenses/by-sa/3.0\">CC BY-SA 3.0</a> or <a href=\"http://www.gnu.org/copyleft/fdl.html\">GFDL</a>], <a href=\"https://commons.wikimedia.org/wiki/File:LyapunovDiagram.svg\">via Wikimedia Commons</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will implement a simple, \"square-root\" ensemble Kalman filter in the Lorenz-63 model.  The ensemble Kalman filter will be given **noisy observations** of a control trajectory.   Along the control trajectory, we will compute the **QR factorization** of the tangent-linear model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the **projection coefficient** of the covariance matrix <span style='font-size:1.25em'> $\\mathbf{P}_k$</span> into the $j$-th QR factor to be the quantity,\n",
    "<h3>$$\\begin{align}\n",
    "\\left(\\mathbf{Q}_k^j\\right)^{\\rm T} \\mathbf{P}_k \\mathbf{Q}^j\n",
    "\\end{align}$$</h3>\n",
    "We will compute the projection coefficients of the ensemble based covariance into each of the QR factors, as defined above.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exc 4.38**: Can you conjecture how the projection coefficients will vary in the index $j$? <br>\n",
    "**Hint**: consider **Exc 4.34**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exc 4.40**: Test your conjecture from **Exc 4.40**.  Use the code below to investigate the relationship between the ensemble based covariance and its projeciton into each of the QR factors.  We plot the average projection coefficient for the EnKF covariance into each of the QR factors over the number of analyses.  Similarly, we plot the EnKF mean square error, to vefify that the ensemble mean lies within the variance of the error in these directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: we may consider the QR factorizations to give approximately the \"true\" Lyapunov vectors when the log-average growth rate approaches the Lyapunov exponents for the system.  The Lyapunov exponents are approximately given by,\n",
    "<h3>$$\\begin{align}\n",
    "\\lambda_1 &\\approx 0.905 \\\\\n",
    "\\lambda_2 & = 0 \\\\\n",
    "\\lambda_3 & \\approx -14.571.\n",
    "\\end{align}$$<h3/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma=SIGMA \n",
    "beta=BETA \n",
    "rho=RHO\n",
    "\n",
    "def l63_jac(x):\n",
    "    jac = np.array([\n",
    "        [-sigma,  sigma,     0 ],\n",
    "        [rho - x[2], -1,  -x[0]],\n",
    "        [x[1],      x[0], -beta]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return jac\n",
    "\n",
    "def l63_step_TLM(x, Y, h):\n",
    "    \n",
    "    h_mid = h/2\n",
    "\n",
    "    # calculate the evolution of x to the midpoint\n",
    "    x_mid = l63_rk4_step(x, h_mid)\n",
    "\n",
    "    # calculate x to the next time step\n",
    "    x_next = l63_rk4_step(x_mid, h_mid)\n",
    "\n",
    "    k_y_1 = l63_jac(x).dot(Y)\n",
    "    k_y_2 = l63_jac(x_mid).dot(Y + k_y_1 * (h / 2.0))\n",
    "    k_y_3 = l63_jac(x_mid).dot(Y + k_y_2 * (h / 2.0))\n",
    "    k_y_4 = l63_jac(x_next).dot(Y + k_y_3 * h)\n",
    "\n",
    "    Y_next = Y + (h / 6.0) * (k_y_1 + 2 * k_y_2 + 2 * k_y_3 + k_y_4)\n",
    "\n",
    "    return [x_next, Y_next]\n",
    "\n",
    "def animate_enkf_covariance(nanl=0):    \n",
    "    \n",
    "    # Initial conditions: perturbations around some control state\n",
    "    tanl=0.005\n",
    "    h = 0.001\n",
    "    tl_steps = int(tanl / h)\n",
    "    N = 4\n",
    "    obs_un = 0.25\n",
    "    obs_dim = 3\n",
    "    R = np.eye(obs_dim) * obs_un\n",
    "    H = np.eye(3, M=obs_dim).T\n",
    "    proj_traj = np.zeros([nanl, 3])\n",
    "    err = np.zeros([nanl])\n",
    "    \n",
    "    seed(1)\n",
    "    x_0 = array([-6.1, 1.2, 32.5])               # define the control\n",
    "    \n",
    "    # define the perturbations, randomly generated but of fixed norm epsilon\n",
    "    A_f = randn([3, N])\n",
    "    a_m = np.mean(A_f, axis=1)\n",
    "    A_f = A_f.T - a_m\n",
    "    del a_m\n",
    "    A_f = (x_0 + A_f).T\n",
    "                  \n",
    "    lam = np.zeros(3)\n",
    "    Q = np.eye(3)\n",
    "        \n",
    "    # for each analysis cycle\n",
    "    for kk in range(nanl):\n",
    "        for j in range(tl_steps):\n",
    "            x_0, Q = l63_step_TLM(x_0, Q, h)\n",
    "            for l in range(2):\n",
    "                for j in range(N):\n",
    "                    A_f[:, j] = l63_rk4_step(A_f[:, j], h / 2)\n",
    "            \n",
    "        # perform QR step and find the local Lyapunov exponents\n",
    "        Q, U = np.linalg.qr(Q)\n",
    "        lam += np.log(np.abs(np.diag(U))) / tanl\n",
    "        \n",
    "        # define an observation\n",
    "        y_0 = H @ x_0 + np.random.multivariate_normal(np.zeros([obs_dim]), R)\n",
    "        \n",
    "        # forecast mean, and rmse\n",
    "        x_f = np.mean(A_f, axis=1)\n",
    "        \n",
    "        A_f = (A_f.T - x_f).T\n",
    "        \n",
    "        # forecast covaraince\n",
    "        P_f = (N-1) ** (-1) * A_f @ A_f.T \n",
    "        \n",
    "        # form the Kalman gain    \n",
    "        K = P_f @ H.T @ np.linalg.inv(H @ P_f @ H.T + R) \n",
    "        \n",
    "        # analysis mean\n",
    "        x_a = x_f + K @ (y_0 - H @ x_f)\n",
    "        err[kk] = np.mean((x_a - x_0)**2)\n",
    "        \n",
    "        # analyze the ensemble\n",
    "        T = np.eye(N) - (N-1)**(-1) * (H @ A_f).T @ np.linalg.inv(H @ P_f @ H.T + R) @ (H @ A_f)\n",
    "        U, S, V_h = np.linalg.svd(T)\n",
    "        T = U @ np.diag(np.sqrt(S)) @ U.T\n",
    "        A_f = A_f @ T\n",
    "        \n",
    "        P_a = (N-1)**(-1) * A_f @ A_f.T\n",
    "        # find the forecast projection coefficients\n",
    "        for i in range(3):\n",
    "            proj_traj[kk, i] = Q[:, i].T @ P_a @ Q[:, i]\n",
    "            \n",
    "        A_f = (x_a + A_f.T).T\n",
    "        \n",
    "        \n",
    "    # PLOTTING\n",
    "    avg_proj = np.zeros([nanl, 3])\n",
    "    \n",
    "    # we plot the average projection coefficient into each blv\n",
    "    for i in range(1,nanl):\n",
    "        avg_proj[i, :] = np.mean(proj_traj[:i, :], axis=0)\n",
    "    \n",
    "    lam = lam / nanl\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    for i in range(3):\n",
    "        ax.plot(range(nanl), avg_proj[:, i], label='BLV projection ' + str(i + 1) + ', log-avg growth rate ' + \n",
    "                str(np.round(lam[i],decimals=3)).zfill(3))\n",
    "                \n",
    "    ax.axhline(y=np.mean(err), color='k', label='Mean square error')\n",
    "    plt.legend(fontsize=20)\n",
    "    ax.set_xbound([1, nanl])\n",
    "    ax.set_yscale('log')\n",
    "    ax.tick_params(labelsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "w = interactive(animate_enkf_covariance,nanl=(10,20010,2000))\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exc 4.42**: Answer the following questions.\n",
    "<ol>\n",
    "   <li>How do the projection coefficients relate to the log-average growth rates in each direction? </li> \n",
    "   <li>What is significant about the **effective rank** of the covariance?</li>\n",
    "   <li>Can you conjecture what this means about the necessary number of ensemble members to prevent filter divergence?\n",
    "   <br> **Hint**: the ensemble should capture the effective spread of the uncertainty.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next: [Ensemble [Monte-Carlo] approach](T5 - Ensemble [Monte-Carlo] approach.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
