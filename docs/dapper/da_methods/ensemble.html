<!-- Search file for "CHANGE" for my own changes -->
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>dapper.da_methods.ensemble API documentation</title>
<meta name="description" content="The EnKF and other ensemble-based methods." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<link rel="preconnect" href="https://www.google.com">
<script async src="https://cse.google.com/cse.js?cx=017837193012385208679:pey8ky8gdqw"></script>
<style>
.gsc-control-cse {padding:0 !important;margin-top:1em}
body.gsc-overflow-hidden #sidebar {overflow: visible;}
</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo.png">
<!-- Dont work coz pdoc already defines these:
<title>DAPPER doc</title>
<meta name="description" content="Data Assimilation with Python: a Package for Experimental Research" />
-->
<a href="https://github.com/nansencenter/DAPPER" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dapper.da_methods.ensemble</code></h1>
</header>
<section id="section-intro">
<p>The EnKF and other ensemble-based methods.</p>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L0-L980" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;The EnKF and other ensemble-based methods.&#34;&#34;&#34;

import numpy as np
import numpy.random as rnd
import scipy.linalg as sla
from numpy import diag, eye, sqrt, zeros

import dapper.tools.multiproc as mp
from dapper.stats import center, mean0
from dapper.tools.linalg import mldiv, mrdiv, pad0, svd0, svdi, tinv, tsvd
from dapper.tools.matrices import funm_psd, genOG_1
from dapper.tools.progressbar import progbar

from . import da_method


@da_method
class ens_method:
    &#34;&#34;&#34;Declare default ensemble arguments.&#34;&#34;&#34;

    infl: float        = 1.0
    rot: bool          = False
    fnoise_treatm: str = &#39;Stoch&#39;


@ens_method
class EnKF:
    &#34;&#34;&#34;The ensemble Kalman filter.

    Refs: `bib.evensen2009ensemble`.
    &#34;&#34;&#34;

    upd_a: str
    N: int

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

        # Init
        E = X0.sample(self.N)
        stats.assess(0, E=E)

        # Loop
        for k, kObs, t, dt in progbar(chrono.ticker):
            E = Dyn(E, t-dt, dt)
            E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

            # Analysis update
            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E)
                E = EnKF_analysis(E, Obs(E, t), Obs.noise,
                                  yy[kObs], self.upd_a, stats, kObs)
                E = post_process(E, self.infl, self.rot)

            stats.assess(k, kObs, E=E)


def EnKF_analysis(E, Eo, hnoise, y, upd_a, stats, kObs):
    &#34;&#34;&#34;Perform the EnKF analysis update.

    This implementation includes several flavours and forms,
    specified by `upd_a`.

    Main references: `bib.sakov2008deterministic`,
    `bib.sakov2008implications`, `bib.hoteit2015mitigating`
    &#34;&#34;&#34;
    R     = hnoise.C     # Obs noise cov
    N, Nx = E.shape      # Dimensionality
    N1    = N-1          # Ens size - 1

    mu = np.mean(E, 0)   # Ens mean
    A  = E - mu          # Ens anomalies

    xo = np.mean(Eo, 0)  # Obs ens mean
    Y  = Eo-xo           # Obs ens anomalies
    dy = y - xo          # Mean &#34;innovation&#34;

    if &#39;PertObs&#39; in upd_a:
        # Uses classic, perturbed observations (Burgers&#39;98)
        C  = Y.T @ Y + R.full*N1
        D  = mean0(hnoise.sample(N))
        YC = mrdiv(Y, C)
        KG = A.T @ YC
        HK = Y.T @ YC
        dE = (KG @ (y - D - Eo).T).T
        E  = E + dE

    elif &#39;Sqrt&#39; in upd_a:
        # Uses a symmetric square root (ETKF)
        # to deterministically transform the ensemble.

        # The various versions below differ only numerically.
        # EVD is default, but for large N use SVD version.
        if upd_a == &#39;Sqrt&#39; and N &gt; Nx:
            upd_a = &#39;Sqrt svd&#39;

        if &#39;explicit&#39; in upd_a:
            # Not recommended due to numerical costs and instability.
            # Implementation using inv (in ens space)
            Pw = sla.inv(Y @ R.inv @ Y.T + N1*eye(N))
            T  = sla.sqrtm(Pw) * sqrt(N1)
            HK = R.inv @ Y.T @ Pw @ Y
            # KG = R.inv @ Y.T @ Pw @ A
        elif &#39;svd&#39; in upd_a:
            # Implementation using svd of Y R^{-1/2}.
            V, s, _ = svd0(Y @ R.sym_sqrt_inv.T)
            d       = pad0(s**2, N) + N1
            Pw      = (V * d**(-1.0)) @ V.T
            T       = (V * d**(-0.5)) @ V.T * sqrt(N1)
            # docs/snippets/trHK.jpg
            trHK    = np.sum((s**2+N1)**(-1.0) * s**2)
        elif &#39;sS&#39; in upd_a:
            # Same as &#39;svd&#39;, but with slightly different notation
            # (sometimes used by Sakov) using the normalization sqrt(N1).
            S       = Y @ R.sym_sqrt_inv.T / sqrt(N1)
            V, s, _ = svd0(S)
            d       = pad0(s**2, N) + 1
            Pw      = (V * d**(-1.0))@V.T / N1  # = G/(N1)
            T       = (V * d**(-0.5))@V.T
            # docs/snippets/trHK.jpg
            trHK    = np.sum((s**2 + 1)**(-1.0)*s**2)
        else:  # &#39;eig&#39; in upd_a:
            # Implementation using eig. val. decomp.
            d, V   = sla.eigh(Y @ R.inv @ Y.T + N1*eye(N))
            T      = V@diag(d**(-0.5))@V.T * sqrt(N1)
            Pw     = V@diag(d**(-1.0))@V.T
            HK     = R.inv @ Y.T @ (V @ diag(d**(-1)) @ V.T) @ Y
        w = dy @ R.inv @ Y.T @ Pw
        E = mu + w@A + T@A

    elif &#39;Serial&#39; in upd_a:
        # Observations assimilated one-at-a-time:
        inds = serial_inds(upd_a, y, R, A)
        #  Requires de-correlation:
        dy   = dy @ R.sym_sqrt_inv.T
        Y    = Y  @ R.sym_sqrt_inv.T
        # Enhancement in the nonlinear case:
        # re-compute Y each scalar obs assim.
        # But: little benefit, model costly (?),
        # updates cannot be accumulated on S and T.

        if any(x in upd_a for x in [&#39;Stoch&#39;, &#39;ESOPS&#39;, &#39;Var1&#39;]):
            # More details: Misc/Serial_ESOPS.py.
            for i, j in enumerate(inds):

                # Perturbation creation
                if &#39;ESOPS&#39; in upd_a:
                    # &#34;2nd-O exact perturbation sampling&#34;
                    if i == 0:
                        # Init -- increase nullspace by 1
                        V, s, UT = svd0(A)
                        s[N-2:] = 0
                        A = svdi(V, s, UT)
                        v = V[:, N-2]
                    else:
                        # Orthogonalize v wrt. the new A
                        #
                        # v = Zj - Yj (from paper) requires Y==HX.
                        # Instead: mult` should be c*ones(Nx) so we can
                        # project v into ker(A) such that v@A is null.
                        mult  = (v@A) / (Yj@A) # noqa
                        v     = v - mult[0]*Yj # noqa
                        v    /= sqrt(v@v)
                    Zj  = v*sqrt(N1)  # Standardized perturbation along v
                    Zj *= np.sign(rnd.rand()-0.5)  # Random sign
                else:
                    # The usual stochastic perturbations.
                    Zj = mean0(rnd.randn(N))  # Un-coloured noise
                    if &#39;Var1&#39; in upd_a:
                        Zj *= sqrt(N/(Zj@Zj))

                # Select j-th obs
                Yj  = Y[:, j]       # [j] obs anomalies
                dyj = dy[j]         # [j] innov mean
                DYj = Zj - Yj       # [j] innov anomalies
                DYj = DYj[:, None]  # Make 2d vertical

                # Kalman gain computation
                C     = Yj@Yj + N1  # Total obs cov
                KGx   = Yj @ A / C  # KG to update state
                KGy   = Yj @ Y / C  # KG to update obs

                # Updates
                A    += DYj * KGx
                mu   += dyj * KGx
                Y    += DYj * KGy
                dy   -= dyj * KGy
            E = mu + A
        else:
            # &#34;Potter scheme&#34;, &#34;EnSRF&#34;
            # - EAKF&#39;s two-stage &#34;update-regress&#34; form yields
            #   the same *ensemble* as this.
            # - The form below may be derived as &#34;serial ETKF&#34;,
            #   but does not yield the same
            #   ensemble as &#39;Sqrt&#39; (which processes obs as a batch)
            #   -- only the same mean/cov.
            T = eye(N)
            for j in inds:
                Yj = Y[:, j]
                C  = Yj@Yj + N1
                Tj = np.outer(Yj, Yj / (C + sqrt(N1*C)))
                T -= Tj @ T
                Y -= Tj @ Y
            w = dy@Y.T@T/N1
            E = mu + w@A + T@A

    elif &#39;DEnKF&#39; == upd_a:
        # Uses &#34;Deterministic EnKF&#34; (sakov&#39;08)
        C  = Y.T @ Y + R.full*N1
        YC = mrdiv(Y, C)
        KG = A.T @ YC
        HK = Y.T @ YC
        E  = E + KG@dy - 0.5*(KG@Y.T).T

    else:
        raise KeyError(&#34;No analysis update method found: &#39;&#34; + upd_a + &#34;&#39;.&#34;)

    # Diagnostic: relative influence of observations
    if &#39;trHK&#39; in locals():
        stats.trHK[kObs] = trHK      / hnoise.M
    elif &#39;HK&#39; in locals():
        stats.trHK[kObs] = HK.trace()/hnoise.M

    return E


def post_process(E, infl, rot):
    &#34;&#34;&#34;Inflate, Rotate.

    To avoid recomputing/recombining anomalies,
    this should have been inside :func:`EnKF_analysis`

    But it is kept as a separate function

    - for readability;
    - to avoid inflating/rotationg smoothed states (for the :func:`EnKS`).
    &#34;&#34;&#34;
    do_infl = infl != 1.0 and infl != &#39;-N&#39;

    if do_infl or rot:
        A, mu  = center(E)
        N, Nx  = E.shape
        T      = eye(N)

        if do_infl:
            T = infl * T

        if rot:
            T = genOG_1(N, rot) @ T

        E = mu + T@A
    return E


def add_noise(E, dt, noise, method):
    &#34;&#34;&#34;Treatment of additive noise for ensembles.

    Refs: `bib.raanes2014ext`
    &#34;&#34;&#34;
    if noise.C == 0:
        return E

    N, Nx = E.shape
    A, mu = center(E)
    Q12   = noise.C.Left
    Q     = noise.C.full

    def sqrt_core():
        T    = np.nan    # cause error if used
        Qa12 = np.nan    # cause error if used
        A2   = A.copy()  # Instead of using (the implicitly nonlocal) A,
        # which changes A outside as well. NB: This is a bug in Datum!
        if N &lt;= Nx:
            Ainv = tinv(A2.T)
            Qa12 = Ainv@Q12
            T    = funm_psd(eye(N) + dt*(N-1)*(Qa12@Qa12.T), sqrt)
            A2   = T@A2
        else:  # &#34;Left-multiplying&#34; form
            P  = A2.T @ A2 / (N-1)
            L  = funm_psd(eye(Nx) + dt*mrdiv(Q, P), sqrt)
            A2 = A2 @ L.T
        E = mu + A2
        return E, T, Qa12

    if method == &#39;Stoch&#39;:
        # In-place addition works (also) for empty [] noise sample.
        E += sqrt(dt)*noise.sample(N)

    elif method == &#39;none&#39;:
        pass

    elif method == &#39;Mult-1&#39;:
        varE   = np.var(E, axis=0, ddof=1).sum()
        ratio  = (varE + dt*diag(Q).sum())/varE
        E      = mu + sqrt(ratio)*A
        E      = svdi(*tsvd(E, 0.999))  # Explained in Datum

    elif method == &#39;Mult-M&#39;:
        varE   = np.var(E, axis=0)
        ratios = sqrt((varE + dt*diag(Q))/varE)
        E      = mu + A*ratios
        E      = svdi(*tsvd(E, 0.999))  # Explained in Datum

    elif method == &#39;Sqrt-Core&#39;:
        E = sqrt_core()[0]

    elif method == &#39;Sqrt-Mult-1&#39;:
        varE0 = np.var(E, axis=0, ddof=1).sum()
        varE2 = (varE0 + dt*diag(Q).sum())
        E, _, Qa12 = sqrt_core()
        if N &lt;= Nx:
            A, mu   = center(E)
            varE1   = np.var(E, axis=0, ddof=1).sum()
            ratio   = varE2/varE1
            E       = mu + sqrt(ratio)*A
            E       = svdi(*tsvd(E, 0.999))  # Explained in Datum

    elif method == &#39;Sqrt-Add-Z&#39;:
        E, _, Qa12 = sqrt_core()
        if N &lt;= Nx:
            Z  = Q12 - A.T@Qa12
            E += sqrt(dt)*(Z@rnd.randn(Z.shape[1], N)).T

    elif method == &#39;Sqrt-Dep&#39;:
        E, T, Qa12 = sqrt_core()
        if N &lt;= Nx:
            # Q_hat12: reuse svd for both inversion and projection.
            Q_hat12      = A.T @ Qa12
            U, s, VT     = tsvd(Q_hat12, 0.99)
            Q_hat12_inv  = (VT.T * s**(-1.0)) @ U.T
            Q_hat12_proj = VT.T@VT
            rQ = Q12.shape[1]
            # Calc D_til
            Z      = Q12 - Q_hat12
            D_hat  = A.T@(T-eye(N))
            Xi_hat = Q_hat12_inv @ D_hat
            Xi_til = (eye(rQ) - Q_hat12_proj)@rnd.randn(rQ, N)
            D_til  = Z@(Xi_hat + sqrt(dt)*Xi_til)
            E     += D_til.T

    else:
        raise KeyError(&#39;No such method&#39;)

    return E


@ens_method
class EnKS:
    &#34;&#34;&#34;The ensemble Kalman smoother.

    Refs: `bib.evensen2009ensemble`

    The only difference to the EnKF
    is the management of the lag and the reshapings.
    &#34;&#34;&#34;

    upd_a: str
    N: int
    Lag: int

    # Reshapings used in smoothers to go to/from
    # 3D arrays, where the 0th axis is the Lag index.
    def reshape_to(self, E):
        K, N, Nx = E.shape
        return E.transpose([1, 0, 2]).reshape((N, K*Nx))

    def reshape_fr(self, E, Nx):
        N, Km = E.shape
        K    = Km//Nx
        return E.reshape((N, K, Nx)).transpose([1, 0, 2])

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

        # Inefficient version, storing full time series ensemble.
        # See iEnKS for a &#34;rolling&#34; version.
        E    = zeros((chrono.K+1, self.N, Dyn.M))
        E[0] = X0.sample(self.N)

        for k, kObs, t, dt in progbar(chrono.ticker):
            E[k] = Dyn(E[k-1], t-dt, dt)
            E[k] = add_noise(E[k], dt, Dyn.noise, self.fnoise_treatm)

            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E[k])

                Eo    = Obs(E[k], t)
                y     = yy[kObs]

                # Inds within Lag
                kk    = range(max(0, k-self.Lag*chrono.dkObs), k+1)

                EE    = E[kk]

                EE    = self.reshape_to(EE)
                EE    = EnKF_analysis(EE, Eo, Obs.noise, y, self.upd_a, stats, kObs)
                E[kk] = self.reshape_fr(EE, Dyn.M)
                E[k]  = post_process(E[k], self.infl, self.rot)
                stats.assess(k, kObs, &#39;a&#39;, E=E[k])

        for k, kObs, _, _ in progbar(chrono.ticker, desc=&#39;Assessing&#39;):
            stats.assess(k, kObs, &#39;u&#39;, E=E[k])
            if kObs is not None:
                stats.assess(k, kObs, &#39;s&#39;, E=E[k])


@ens_method
class EnRTS:
    &#34;&#34;&#34;EnRTS (Rauch-Tung-Striebel) smoother.

    Refs: `bib.raanes2016thesis`
    &#34;&#34;&#34;

    upd_a: str
    N: int
    cntr: float

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

        E    = zeros((chrono.K+1, self.N, Dyn.M))
        Ef   = E.copy()
        E[0] = X0.sample(self.N)

        # Forward pass
        for k, kObs, t, dt in progbar(chrono.ticker):
            E[k]  = Dyn(E[k-1], t-dt, dt)
            E[k]  = add_noise(E[k], dt, Dyn.noise, self.fnoise_treatm)
            Ef[k] = E[k]

            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E[k])
                Eo   = Obs(E[k], t)
                y    = yy[kObs]
                E[k] = EnKF_analysis(E[k], Eo, Obs.noise, y, self.upd_a, stats, kObs)
                E[k] = post_process(E[k], self.infl, self.rot)
                stats.assess(k, kObs, &#39;a&#39;, E=E[k])

        # Backward pass
        for k in progbar(range(chrono.K)[::-1]):
            A  = center(E[k])[0]
            Af = center(Ef[k+1])[0]

            J = tinv(Af) @ A
            J *= self.cntr

            E[k] += (E[k+1] - Ef[k+1]) @ J

        for k, kObs, _, _ in progbar(chrono.ticker, desc=&#39;Assessing&#39;):
            stats.assess(k, kObs, &#39;u&#39;, E=E[k])
            if kObs is not None:
                stats.assess(k, kObs, &#39;s&#39;, E=E[k])


def serial_inds(upd_a, y, cvR, A):
    &#34;&#34;&#34;Get the indices used for serial updating.

    - Default: random ordering
    - if &#34;mono&#34; in `upd_a`: `1, 2, ..., len(y)`
    - if &#34;sorted&#34; in `upd_a`: sort by variance
    &#34;&#34;&#34;
    if &#39;mono&#39; in upd_a:
        # Not robust?
        inds = np.arange(len(y))
    elif &#39;sorted&#39; in upd_a:
        N = len(A)
        dC = cvR.diag
        if np.all(dC == dC[0]):
            # Sort y by P
            dC = np.sum(A*A, 0)/(N-1)
        inds = np.argsort(dC)
    else:  # Default: random ordering
        inds = rnd.permutation(len(y))
    return inds


@ens_method
class SL_EAKF:
    &#34;&#34;&#34;Serial, covariance-localized EAKF.

    Refs: `bib.karspeck2007experimental`.

    Used without localization, this should be equivalent (full ensemble equality)
    to the `EnKF` with `upd_a=&#39;Serial&#39;`.
    &#34;&#34;&#34;

    N: int
    loc_rad: float
    taper: str  = &#39;GC&#39;
    ordr: str   = &#39;rand&#39;

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

        N1   = self.N-1
        R    = Obs.noise
        Rm12 = Obs.noise.C.sym_sqrt_inv

        E = X0.sample(self.N)
        stats.assess(0, E=E)

        for k, kObs, t, dt in progbar(chrono.ticker):
            E = Dyn(E, t-dt, dt)
            E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E)
                y    = yy[kObs]
                inds = serial_inds(self.ordr, y, R, center(E)[0])

                state_taperer = Obs.localizer(self.loc_rad, &#39;y2x&#39;, t, self.taper)
                for j in inds:
                    # Prep:
                    # ------------------------------------------------------
                    Eo = Obs(E, t)
                    xo = np.mean(Eo, 0)
                    Y  = Eo - xo
                    mu = np.mean(E, 0)
                    A  = E-mu
                    # Update j-th component of observed ensemble:
                    # ------------------------------------------------------
                    Y_j    = Rm12[j, :] @ Y.T
                    dy_j   = Rm12[j, :] @ (y - xo)
                    # Prior var * N1:
                    sig2_j = Y_j@Y_j
                    if sig2_j &lt; 1e-9:
                        continue
                    # Update (below, we drop the locality subscript: _j)
                    sig2_u = 1/(1/sig2_j + 1/N1)      # Postr. var * N1
                    alpha  = (N1/(N1+sig2_j))**(0.5)  # Update contraction factor
                    dy2    = sig2_u * dy_j/N1         # Mean update
                    Y2     = alpha*Y_j                # Anomaly update
                    # Update state (regress update from obs space, using localization)
                    # ------------------------------------------------------
                    ii, tapering = state_taperer(j)
                    # ii, tapering = ..., 1  # cancel localization
                    if len(ii) == 0:
                        continue
                    Xi = A[:, ii]*tapering
                    Regression = Xi.T @ Y_j/np.sum(Y_j**2)
                    mu[ii] += Regression*dy2
                    A[:, ii] += np.outer(Y2 - Y_j, Regression)
                    E = mu + A

                E = post_process(E, self.infl, self.rot)

            stats.assess(k, kObs, E=E)


@ens_method
class LETKF:
    &#34;&#34;&#34;Same as EnKF (sqrt), but with localization.

    Refs: `bib.hunt2007efficient`.

    NB: Multiproc. yields slow-down for `dapper.mods.Lorenz96`,
    even with `batch_size=(1,)`. But for `dapper.mods.QG`
    (`batch_size=(2,2)` or less) it is quicker.

    NB: If `len(ii)` is small, analysis may be slowed-down with &#39;-N&#39; infl.
    &#34;&#34;&#34;

    N: int
    loc_rad: float
    taper: str = &#39;GC&#39;
    xN: float  = 1.0
    g: int     = 0
    mp: bool   = False

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats, N = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats, self.N
        R, N1 = HMM.Obs.noise.C, N-1

        _map = mp.map if self.mp else map

        E = X0.sample(N)
        stats.assess(0, E=E)

        for k, kObs, t, dt in progbar(chrono.ticker):
            # Forecast
            E = Dyn(E, t-dt, dt)
            E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E)

                # Decompose ensmeble
                mu = np.mean(E, 0)
                A  = E - mu
                # Obs space variables
                y     = yy[kObs]
                Y, xo = center(Obs(E, t))
                # Transform obs space
                Y  = Y        @ R.sym_sqrt_inv.T
                dy = (y - xo) @ R.sym_sqrt_inv.T

                # Local analyses
                # Get localization configuration
                state_batches, obs_taperer = \
                    Obs.localizer(self.loc_rad, &#39;x2y&#39;, t, self.taper)
                # Avoid pickling self
                xN, g, infl = self.xN, self.g, self.infl

                def local_analysis(ii):
                    &#34;&#34;&#34;Do the local analysis.

                    Notation:

                    - ii: inds for the state batch defining the locality
                    - jj: inds for the associated obs
                    &#34;&#34;&#34;
                    # Locate local obs
                    jj, tapering = obs_taperer(ii)
                    if len(jj) == 0:
                        return E[:, ii], N1  # no update
                    Y_jj   = Y[:, jj]
                    dy_jj  = dy[jj]

                    # Adaptive inflation
                    za = effective_N(Y_jj, dy_jj, xN, g) if infl == &#39;-N&#39; else N1

                    # Taper
                    Y_jj  *= sqrt(tapering)
                    dy_jj *= sqrt(tapering)

                    # Compute ETKF update
                    if len(jj) &lt; N:
                        # SVD version
                        V, sd, _ = svd0(Y_jj)
                        d      = pad0(sd**2, N) + za
                        Pw     = (V * d**(-1.0)) @ V.T
                        T      = (V * d**(-0.5)) @ V.T * sqrt(za)
                    else:
                        # EVD version
                        d, V   = sla.eigh(Y_jj@Y_jj.T + za*eye(N))
                        T     = V@diag(d**(-0.5))@V.T * sqrt(za)
                        Pw    = V@diag(d**(-1.0))@V.T
                    AT  = T @ A[:, ii]
                    dmu = dy_jj @ Y_jj.T @ Pw @ A[:, ii]
                    Eii = mu[ii] + dmu + AT
                    return Eii, za

                # Run local analyses
                EE, za = zip(*_map(local_analysis, state_batches))
                for ii, Eii in zip(state_batches, EE):
                    E[:, ii] = Eii

                # Global post-processing
                E = post_process(E, self.infl, self.rot)

                stats.infl[kObs] = sqrt(N1/np.mean(za))

            stats.assess(k, kObs, E=E)


def effective_N(YR, dyR, xN, g):
    &#34;&#34;&#34;Effective ensemble size N.

    As measured by the finite-size EnKF-N
    &#34;&#34;&#34;
    N, Ny = YR.shape
    N1   = N-1

    V, s, UT = svd0(YR)
    du     = UT @ dyR

    eN, cL = hyperprior_coeffs(s, N, xN, g)

    def pad_rk(arr): return pad0(arr, min(N, Ny))
    def dgn_rk(l1): return pad_rk((l1*s)**2) + N1

    # Make dual cost function (in terms of l1)
    def J(l1):
        val = np.sum(du**2/dgn_rk(l1)) \
            + eN/l1**2 \
            + cL*np.log(l1**2)
        return val

    # Derivatives (not required with minimize_scalar):
    def Jp(l1):
        val = -2*l1   * np.sum(pad_rk(s**2) * du**2/dgn_rk(l1)**2) \
            + -2*eN/l1**3 \
            + 2*cL/l1
        return val

    def Jpp(l1):
        val = 8*l1**2 * np.sum(pad_rk(s**4) * du**2/dgn_rk(l1)**3) \
            + 6*eN/l1**4 \
            + -2*cL/l1**2
        return val

    # Find inflation factor (optimize)
    l1 = Newton_m(Jp, Jpp, 1.0)
    # l1 = fmin_bfgs(J, x0=[1], gtol=1e-4, disp=0)
    # l1 = minimize_scalar(J, bracket=(sqrt(prior_mode), 1e2), tol=1e-4).x

    za = N1/l1**2
    return za


# Notes on optimizers for the &#39;dual&#39; EnKF-N:
# ----------------------------------------
#  Using minimize_scalar:
#  - Doesn&#39;t take dJdx. Advantage: only need J
#  - method=&#39;bounded&#39; not necessary and slower than &#39;brent&#39;.
#  - bracket not necessary either...
#  Using multivariate minimization: fmin_cg, fmin_bfgs, fmin_ncg
#  - these also accept dJdx. But only fmin_bfgs approaches
#    the speed of the scalar minimizers.
#  Using scalar root-finders:
#  - brenth(dJ1, LowB, 1e2,     xtol=1e-6) # Same speed as minimization
#  - newton(dJ1,1.0, fprime=dJ2, tol=1e-6) # No improvement
#  - newton(dJ1,1.0, fprime=dJ2, tol=1e-6, fprime2=dJ3) # No improvement
#  - Newton_m(dJ1,dJ2, 1.0) # Significantly faster. Also slightly better CV?
# =&gt; Despite inconvienience of defining analytic derivatives,
#    Newton_m seems like the best option.
#  - In extreme (or just non-linear Obs.mod) cases,
#    the EnKF-N cost function may have multiple minima.
#    Then: should use more robust optimizer!
#
# For &#39;primal&#39;
# ----------------------------------------
# Similarly, Newton_m seems like the best option,
# although alternatives are provided (commented out).
#
def Newton_m(fun, deriv, x0, is_inverted=False,
             conf=1.0, xtol=1e-4, ytol=1e-7, itermax=10**2):
    &#34;&#34;&#34;Find root of `fun`.

    This is a simple (and pretty fast) implementation of Newton&#39;s method.
    &#34;&#34;&#34;
    itr, dx, Jx = 0, np.inf, fun(x0)
    def norm(x): return sqrt(np.sum(x**2))
    while ytol &lt; norm(Jx) and xtol &lt; norm(dx) and itr &lt; itermax:
        Dx  = deriv(x0)
        if is_inverted:
            dx  = Dx @ Jx
        elif isinstance(Dx, float):
            dx  = Jx/Dx
        else:
            dx  = mldiv(Dx, Jx)
        dx *= conf
        x0 -= dx
        Jx  = fun(x0)
    return x0


def hyperprior_coeffs(s, N, xN=1, g=0):
    r&#34;&#34;&#34;Set EnKF-N inflation hyperparams.

    The EnKF-N prior may be specified by the constants:

    - eN: Effect of unknown mean
    - cL: Coeff in front of log term

    These are trivial constants in the original EnKF-N,
    but are further adjusted (corrected and tuned) for the following reasons.

    - Reason 1: mode correction.
      These parameters bridge the Jeffreys (`xN=1`) and Dirac (`xN=Inf`) hyperpriors
      for the prior covariance, B, as discussed in `bib.bocquet2015expanding`.
      Indeed, mode correction becomes necessary when $$ R \rightarrow \infty $$
      because then there should be no ensemble update (and also no inflation!).
      More specifically, the mode of `l1`&#39;s should be adjusted towards 1
      as a function of $$ I - K H $$ (&#34;prior&#39;s weight&#34;).
      PS: why do we leave the prior mode below 1 at all?
      Because it sets up &#34;tension&#34; (negative feedback) in the inflation cycle:
      the prior pulls downwards, while the likelihood tends to pull upwards.

    - Reason 2: Boosting the inflation prior&#39;s certainty from N to xN*N.
      The aim is to take advantage of the fact that the ensemble may not
      have quite as much sampling error as a fully stochastic sample,
      as illustrated in section 2.1 of `bib.raanes2019adaptive`.

    - Its damping effect is similar to work done by J. Anderson.

    The tuning is controlled by:

    - `xN=1`: is fully agnostic, i.e. assumes the ensemble is generated
      from a highly chaotic or stochastic model.
    - `xN&gt;1`: increases the certainty of the hyper-prior,
      which is appropriate for more linear and deterministic systems.
    - `xN&lt;1`: yields a more (than &#39;fully&#39;) agnostic hyper-prior,
      as if N were smaller than it truly is.
    - `xN&lt;=0` is not meaningful.
    &#34;&#34;&#34;
    N1 = N-1

    eN = (N+1)/N
    cL = (N+g)/N1

    # Mode correction (almost) as in eqn 36 of `bib.bocquet2015expanding`
    prior_mode = eN/cL                        # Mode of l1 (before correction)
    diagonal   = pad0(s**2, N) + N1           # diag of Y@R.inv@Y + N1*I
    #                                           (Hessian of J)
    I_KH       = np.mean(diagonal**(-1))*N1   # â‰ˆ 1/(1 + HBH/R)
    # I_KH      = 1/(1 + (s**2).sum()/N1)     # Scalar alternative: use tr(HBH/R).
    mc         = sqrt(prior_mode**I_KH)       # Correction coeff

    # Apply correction
    eN /= mc
    cL *= mc

    # Boost by xN
    eN *= xN
    cL *= xN

    return eN, cL


def zeta_a(eN, cL, w):
    &#34;&#34;&#34;EnKF-N inflation estimation via w.

    Returns `zeta_a = (N-1)/pre-inflation^2`.

    Using this inside an iterative minimization as in the
    `dapper.da_methods.variational.iEnKS` effectively blends
    the distinction between the primal and dual EnKF-N.
    &#34;&#34;&#34;
    N  = len(w)
    N1 = N-1
    za = N1*cL/(eN + w@w)
    return za


@ens_method
class EnKF_N:
    &#34;&#34;&#34;Finite-size EnKF (EnKF-N).

    Refs: `bib.bocquet2011ensemble`, `bib.bocquet2015expanding`

    This implementation is pedagogical, prioritizing the &#34;dual&#34; form.
    In consequence, the efficiency of the &#34;primal&#34; form suffers a bit.
    The primal form is included for completeness and to demonstrate equivalence.
    In `dapper.da_methods.variational.iEnKS`, however,
    the primal form is preferred because it
    already does optimization for w (as treatment for nonlinear models).

    `infl` should be unnecessary (assuming no model error, or that Q is correct).

    `Hess`: use non-approx Hessian for ensemble transform matrix?

    `g` is the nullity of A (state anomalies&#39;s), ie. g=max(1,N-Nx),
    compensating for the redundancy in the space of w.
    But we have made it an input argument instead, with default 0,
    because mode-finding (of p(x) via the dual) completely ignores this redundancy,
    and the mode gets (undesireably) modified by g.

    `xN` allows tuning the hyper-prior for the inflation.
    Usually, I just try setting it to 1 (default), or 2.
    Further description in hyperprior_coeffs().
    &#34;&#34;&#34;

    N: int
    dual: bool = False
    Hess: bool = False
    xN: float  = 1.0
    g: int     = 0

    def assimilate(self, HMM, xx, yy):
        # Unpack
        Dyn, Obs, chrono, X0, stats = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats
        R, N, N1 = HMM.Obs.noise.C, self.N, self.N-1

        # Init
        E = X0.sample(N)
        stats.assess(0, E=E)

        # Loop
        for k, kObs, t, dt in progbar(chrono.ticker):
            # Forecast
            E = Dyn(E, t-dt, dt)
            E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

            # Analysis
            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E)
                Eo = Obs(E, t)
                y  = yy[kObs]

                mu = np.mean(E, 0)
                A  = E - mu

                xo = np.mean(Eo, 0)
                Y  = Eo-xo
                dy = y - xo

                V, s, UT = svd0(Y @ R.sym_sqrt_inv.T)
                du       = UT @ (dy @ R.sym_sqrt_inv.T)
                def dgn_N(l1): return pad0((l1*s)**2, N) + N1

                # Adjust hyper-prior
                # xN_ = noise_level(self.xN,stats,chrono,N1,kObs,A,
                #                   locals().get(&#39;A_old&#39;,None))
                eN, cL = hyperprior_coeffs(s, N, self.xN, self.g)

                if self.dual:
                    # Make dual cost function (in terms of l1)
                    def pad_rk(arr): return pad0(arr, min(N, Obs.M))
                    def dgn_rk(l1): return pad_rk((l1*s)**2) + N1

                    def J(l1):
                        val = np.sum(du**2/dgn_rk(l1)) \
                            + eN/l1**2 \
                            + cL*np.log(l1**2)
                        return val

                    # Derivatives (not required with minimize_scalar):
                    def Jp(l1):
                        val = -2*l1 * np.sum(pad_rk(s**2) * du**2/dgn_rk(l1)**2) \
                            + -2*eN/l1**3 + 2*cL/l1
                        return val

                    def Jpp(l1):
                        val = 8*l1**2 * np.sum(pad_rk(s**4) * du**2/dgn_rk(l1)**3) \
                            + 6*eN/l1**4 + -2*cL/l1**2
                        return val
                    # Find inflation factor (optimize)
                    l1 = Newton_m(Jp, Jpp, 1.0)
                    # l1 = fmin_bfgs(J, x0=[1], gtol=1e-4, disp=0)
                    # l1 = minimize_scalar(J, bracket=(sqrt(prior_mode), 1e2),
                    #                      tol=1e-4).x

                else:
                    # Primal form, in a fully linearized version.
                    def za(w): return zeta_a(eN, cL, w)

                    def J(w): return \
                        .5*np.sum(((dy-w@Y)@R.sym_sqrt_inv.T)**2) + \
                        .5*N1*cL*np.log(eN + w@w)
                    # Derivatives (not required with fmin_bfgs):
                    def Jp(w): return -Y@R.inv@(dy-w@Y) + w*za(w)
                    # Jpp   = lambda w:  Y@R.inv@Y.T + \
                    #     za(w)*(eye(N) - 2*np.outer(w,w)/(eN + w@w))
                    # Approx: no radial-angular cross-deriv:
                    # Jpp   = lambda w:  Y@R.inv@Y.T + za(w)*eye(N)

                    def nvrs(w):
                        # inverse of Jpp-approx
                        return (V * (pad0(s**2, N) + za(w)) ** -1.0) @ V.T
                    # Find w (optimize)
                    wa     = Newton_m(Jp, nvrs, zeros(N), is_inverted=True)
                    # wa   = Newton_m(Jp,Jpp ,zeros(N))
                    # wa   = fmin_bfgs(J,zeros(N),Jp,disp=0)
                    l1     = sqrt(N1/za(wa))

                # Uncomment to revert to ETKF
                # l1 = 1.0

                # Explicitly inflate prior
                # =&gt; formulae look different from `bib.bocquet2015expanding`.
                A *= l1
                Y *= l1

                # Compute sqrt update
                Pw = (V * dgn_N(l1)**(-1.0)) @ V.T
                w  = dy@R.inv@Y.T@Pw
                # For the anomalies:
                if not self.Hess:
                    # Regular ETKF (i.e. sym sqrt) update (with inflation)
                    T = (V * dgn_N(l1)**(-0.5)) @ V.T * sqrt(N1)
                    # = (Y@R.inv@Y.T/N1 + eye(N))**(-0.5)
                else:
                    # Also include angular-radial co-dependence.
                    # Note: denominator not squared coz
                    # unlike `bib.bocquet2015expanding` we have inflated Y.
                    Hw = Y@R.inv@Y.T/N1 + eye(N) - 2*np.outer(w, w)/(eN + w@w)
                    T  = funm_psd(Hw, lambda x: x**-.5)  # is there a sqrtm Woodbury?

                E = mu + w@A + T@A
                E = post_process(E, self.infl, self.rot)

                stats.infl[kObs] = l1
                stats.trHK[kObs] = (((l1*s)**2 + N1)**(-1.0)*s**2).sum()/HMM.Ny

            stats.assess(k, kObs, E=E)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dapper.da_methods.ensemble.EnKF_analysis"><code class="name flex">
<span>def <span class="ident">EnKF_analysis</span></span>(<span>E, Eo, hnoise, y, upd_a, stats, kObs)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform the EnKF analysis update.</p>
<p>This implementation includes several flavours and forms,
specified by <code>upd_a</code>.</p>
<p>Main references: <code><a title="bib.sakov2008deterministic" href="../../bib.html#bib.sakov2008deterministic">sakov2008deterministic</a></code>,
<code><a title="bib.sakov2008implications" href="../../bib.html#bib.sakov2008implications">sakov2008implications</a></code>, <code><a title="bib.hoteit2015mitigating" href="../../bib.html#bib.hoteit2015mitigating">hoteit2015mitigating</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L59-L225" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def EnKF_analysis(E, Eo, hnoise, y, upd_a, stats, kObs):
    &#34;&#34;&#34;Perform the EnKF analysis update.

    This implementation includes several flavours and forms,
    specified by `upd_a`.

    Main references: `bib.sakov2008deterministic`,
    `bib.sakov2008implications`, `bib.hoteit2015mitigating`
    &#34;&#34;&#34;
    R     = hnoise.C     # Obs noise cov
    N, Nx = E.shape      # Dimensionality
    N1    = N-1          # Ens size - 1

    mu = np.mean(E, 0)   # Ens mean
    A  = E - mu          # Ens anomalies

    xo = np.mean(Eo, 0)  # Obs ens mean
    Y  = Eo-xo           # Obs ens anomalies
    dy = y - xo          # Mean &#34;innovation&#34;

    if &#39;PertObs&#39; in upd_a:
        # Uses classic, perturbed observations (Burgers&#39;98)
        C  = Y.T @ Y + R.full*N1
        D  = mean0(hnoise.sample(N))
        YC = mrdiv(Y, C)
        KG = A.T @ YC
        HK = Y.T @ YC
        dE = (KG @ (y - D - Eo).T).T
        E  = E + dE

    elif &#39;Sqrt&#39; in upd_a:
        # Uses a symmetric square root (ETKF)
        # to deterministically transform the ensemble.

        # The various versions below differ only numerically.
        # EVD is default, but for large N use SVD version.
        if upd_a == &#39;Sqrt&#39; and N &gt; Nx:
            upd_a = &#39;Sqrt svd&#39;

        if &#39;explicit&#39; in upd_a:
            # Not recommended due to numerical costs and instability.
            # Implementation using inv (in ens space)
            Pw = sla.inv(Y @ R.inv @ Y.T + N1*eye(N))
            T  = sla.sqrtm(Pw) * sqrt(N1)
            HK = R.inv @ Y.T @ Pw @ Y
            # KG = R.inv @ Y.T @ Pw @ A
        elif &#39;svd&#39; in upd_a:
            # Implementation using svd of Y R^{-1/2}.
            V, s, _ = svd0(Y @ R.sym_sqrt_inv.T)
            d       = pad0(s**2, N) + N1
            Pw      = (V * d**(-1.0)) @ V.T
            T       = (V * d**(-0.5)) @ V.T * sqrt(N1)
            # docs/snippets/trHK.jpg
            trHK    = np.sum((s**2+N1)**(-1.0) * s**2)
        elif &#39;sS&#39; in upd_a:
            # Same as &#39;svd&#39;, but with slightly different notation
            # (sometimes used by Sakov) using the normalization sqrt(N1).
            S       = Y @ R.sym_sqrt_inv.T / sqrt(N1)
            V, s, _ = svd0(S)
            d       = pad0(s**2, N) + 1
            Pw      = (V * d**(-1.0))@V.T / N1  # = G/(N1)
            T       = (V * d**(-0.5))@V.T
            # docs/snippets/trHK.jpg
            trHK    = np.sum((s**2 + 1)**(-1.0)*s**2)
        else:  # &#39;eig&#39; in upd_a:
            # Implementation using eig. val. decomp.
            d, V   = sla.eigh(Y @ R.inv @ Y.T + N1*eye(N))
            T      = V@diag(d**(-0.5))@V.T * sqrt(N1)
            Pw     = V@diag(d**(-1.0))@V.T
            HK     = R.inv @ Y.T @ (V @ diag(d**(-1)) @ V.T) @ Y
        w = dy @ R.inv @ Y.T @ Pw
        E = mu + w@A + T@A

    elif &#39;Serial&#39; in upd_a:
        # Observations assimilated one-at-a-time:
        inds = serial_inds(upd_a, y, R, A)
        #  Requires de-correlation:
        dy   = dy @ R.sym_sqrt_inv.T
        Y    = Y  @ R.sym_sqrt_inv.T
        # Enhancement in the nonlinear case:
        # re-compute Y each scalar obs assim.
        # But: little benefit, model costly (?),
        # updates cannot be accumulated on S and T.

        if any(x in upd_a for x in [&#39;Stoch&#39;, &#39;ESOPS&#39;, &#39;Var1&#39;]):
            # More details: Misc/Serial_ESOPS.py.
            for i, j in enumerate(inds):

                # Perturbation creation
                if &#39;ESOPS&#39; in upd_a:
                    # &#34;2nd-O exact perturbation sampling&#34;
                    if i == 0:
                        # Init -- increase nullspace by 1
                        V, s, UT = svd0(A)
                        s[N-2:] = 0
                        A = svdi(V, s, UT)
                        v = V[:, N-2]
                    else:
                        # Orthogonalize v wrt. the new A
                        #
                        # v = Zj - Yj (from paper) requires Y==HX.
                        # Instead: mult` should be c*ones(Nx) so we can
                        # project v into ker(A) such that v@A is null.
                        mult  = (v@A) / (Yj@A) # noqa
                        v     = v - mult[0]*Yj # noqa
                        v    /= sqrt(v@v)
                    Zj  = v*sqrt(N1)  # Standardized perturbation along v
                    Zj *= np.sign(rnd.rand()-0.5)  # Random sign
                else:
                    # The usual stochastic perturbations.
                    Zj = mean0(rnd.randn(N))  # Un-coloured noise
                    if &#39;Var1&#39; in upd_a:
                        Zj *= sqrt(N/(Zj@Zj))

                # Select j-th obs
                Yj  = Y[:, j]       # [j] obs anomalies
                dyj = dy[j]         # [j] innov mean
                DYj = Zj - Yj       # [j] innov anomalies
                DYj = DYj[:, None]  # Make 2d vertical

                # Kalman gain computation
                C     = Yj@Yj + N1  # Total obs cov
                KGx   = Yj @ A / C  # KG to update state
                KGy   = Yj @ Y / C  # KG to update obs

                # Updates
                A    += DYj * KGx
                mu   += dyj * KGx
                Y    += DYj * KGy
                dy   -= dyj * KGy
            E = mu + A
        else:
            # &#34;Potter scheme&#34;, &#34;EnSRF&#34;
            # - EAKF&#39;s two-stage &#34;update-regress&#34; form yields
            #   the same *ensemble* as this.
            # - The form below may be derived as &#34;serial ETKF&#34;,
            #   but does not yield the same
            #   ensemble as &#39;Sqrt&#39; (which processes obs as a batch)
            #   -- only the same mean/cov.
            T = eye(N)
            for j in inds:
                Yj = Y[:, j]
                C  = Yj@Yj + N1
                Tj = np.outer(Yj, Yj / (C + sqrt(N1*C)))
                T -= Tj @ T
                Y -= Tj @ Y
            w = dy@Y.T@T/N1
            E = mu + w@A + T@A

    elif &#39;DEnKF&#39; == upd_a:
        # Uses &#34;Deterministic EnKF&#34; (sakov&#39;08)
        C  = Y.T @ Y + R.full*N1
        YC = mrdiv(Y, C)
        KG = A.T @ YC
        HK = Y.T @ YC
        E  = E + KG@dy - 0.5*(KG@Y.T).T

    else:
        raise KeyError(&#34;No analysis update method found: &#39;&#34; + upd_a + &#34;&#39;.&#34;)

    # Diagnostic: relative influence of observations
    if &#39;trHK&#39; in locals():
        stats.trHK[kObs] = trHK      / hnoise.M
    elif &#39;HK&#39; in locals():
        stats.trHK[kObs] = HK.trace()/hnoise.M

    return E</code></pre>
</details>
</dd>
<dt id="dapper.da_methods.ensemble.post_process"><code class="name flex">
<span>def <span class="ident">post_process</span></span>(<span>E, infl, rot)</span>
</code></dt>
<dd>
<div class="desc"><p>Inflate, Rotate.</p>
<p>To avoid recomputing/recombining anomalies,
this should have been inside :func:<code><a title="dapper.da_methods.ensemble.EnKF_analysis" href="#dapper.da_methods.ensemble.EnKF_analysis">EnKF_analysis()</a></code></p>
<p>But it is kept as a separate function</p>
<ul>
<li>for readability;</li>
<li>to avoid inflating/rotationg smoothed states (for the :func:<code><a title="dapper.da_methods.ensemble.EnKS" href="#dapper.da_methods.ensemble.EnKS">EnKS</a></code>).</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L228-L253" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def post_process(E, infl, rot):
    &#34;&#34;&#34;Inflate, Rotate.

    To avoid recomputing/recombining anomalies,
    this should have been inside :func:`EnKF_analysis`

    But it is kept as a separate function

    - for readability;
    - to avoid inflating/rotationg smoothed states (for the :func:`EnKS`).
    &#34;&#34;&#34;
    do_infl = infl != 1.0 and infl != &#39;-N&#39;

    if do_infl or rot:
        A, mu  = center(E)
        N, Nx  = E.shape
        T      = eye(N)

        if do_infl:
            T = infl * T

        if rot:
            T = genOG_1(N, rot) @ T

        E = mu + T@A
    return E</code></pre>
</details>
</dd>
<dt id="dapper.da_methods.ensemble.add_noise"><code class="name flex">
<span>def <span class="ident">add_noise</span></span>(<span>E, dt, noise, method)</span>
</code></dt>
<dd>
<div class="desc"><p>Treatment of additive noise for ensembles.</p>
<p>Refs: <code><a title="bib.raanes2014ext" href="../../bib.html#bib.raanes2014ext">raanes2014ext</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L256-L345" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def add_noise(E, dt, noise, method):
    &#34;&#34;&#34;Treatment of additive noise for ensembles.

    Refs: `bib.raanes2014ext`
    &#34;&#34;&#34;
    if noise.C == 0:
        return E

    N, Nx = E.shape
    A, mu = center(E)
    Q12   = noise.C.Left
    Q     = noise.C.full

    def sqrt_core():
        T    = np.nan    # cause error if used
        Qa12 = np.nan    # cause error if used
        A2   = A.copy()  # Instead of using (the implicitly nonlocal) A,
        # which changes A outside as well. NB: This is a bug in Datum!
        if N &lt;= Nx:
            Ainv = tinv(A2.T)
            Qa12 = Ainv@Q12
            T    = funm_psd(eye(N) + dt*(N-1)*(Qa12@Qa12.T), sqrt)
            A2   = T@A2
        else:  # &#34;Left-multiplying&#34; form
            P  = A2.T @ A2 / (N-1)
            L  = funm_psd(eye(Nx) + dt*mrdiv(Q, P), sqrt)
            A2 = A2 @ L.T
        E = mu + A2
        return E, T, Qa12

    if method == &#39;Stoch&#39;:
        # In-place addition works (also) for empty [] noise sample.
        E += sqrt(dt)*noise.sample(N)

    elif method == &#39;none&#39;:
        pass

    elif method == &#39;Mult-1&#39;:
        varE   = np.var(E, axis=0, ddof=1).sum()
        ratio  = (varE + dt*diag(Q).sum())/varE
        E      = mu + sqrt(ratio)*A
        E      = svdi(*tsvd(E, 0.999))  # Explained in Datum

    elif method == &#39;Mult-M&#39;:
        varE   = np.var(E, axis=0)
        ratios = sqrt((varE + dt*diag(Q))/varE)
        E      = mu + A*ratios
        E      = svdi(*tsvd(E, 0.999))  # Explained in Datum

    elif method == &#39;Sqrt-Core&#39;:
        E = sqrt_core()[0]

    elif method == &#39;Sqrt-Mult-1&#39;:
        varE0 = np.var(E, axis=0, ddof=1).sum()
        varE2 = (varE0 + dt*diag(Q).sum())
        E, _, Qa12 = sqrt_core()
        if N &lt;= Nx:
            A, mu   = center(E)
            varE1   = np.var(E, axis=0, ddof=1).sum()
            ratio   = varE2/varE1
            E       = mu + sqrt(ratio)*A
            E       = svdi(*tsvd(E, 0.999))  # Explained in Datum

    elif method == &#39;Sqrt-Add-Z&#39;:
        E, _, Qa12 = sqrt_core()
        if N &lt;= Nx:
            Z  = Q12 - A.T@Qa12
            E += sqrt(dt)*(Z@rnd.randn(Z.shape[1], N)).T

    elif method == &#39;Sqrt-Dep&#39;:
        E, T, Qa12 = sqrt_core()
        if N &lt;= Nx:
            # Q_hat12: reuse svd for both inversion and projection.
            Q_hat12      = A.T @ Qa12
            U, s, VT     = tsvd(Q_hat12, 0.99)
            Q_hat12_inv  = (VT.T * s**(-1.0)) @ U.T
            Q_hat12_proj = VT.T@VT
            rQ = Q12.shape[1]
            # Calc D_til
            Z      = Q12 - Q_hat12
            D_hat  = A.T@(T-eye(N))
            Xi_hat = Q_hat12_inv @ D_hat
            Xi_til = (eye(rQ) - Q_hat12_proj)@rnd.randn(rQ, N)
            D_til  = Z@(Xi_hat + sqrt(dt)*Xi_til)
            E     += D_til.T

    else:
        raise KeyError(&#39;No such method&#39;)

    return E</code></pre>
</details>
</dd>
<dt id="dapper.da_methods.ensemble.serial_inds"><code class="name flex">
<span>def <span class="ident">serial_inds</span></span>(<span>upd_a, y, cvR, A)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the indices used for serial updating.</p>
<ul>
<li>Default: random ordering</li>
<li>if "mono" in <code>upd_a</code>: <code>1, 2, &hellip;, len(y)</code></li>
<li>if "sorted" in <code>upd_a</code>: sort by variance</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L458-L477" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def serial_inds(upd_a, y, cvR, A):
    &#34;&#34;&#34;Get the indices used for serial updating.

    - Default: random ordering
    - if &#34;mono&#34; in `upd_a`: `1, 2, ..., len(y)`
    - if &#34;sorted&#34; in `upd_a`: sort by variance
    &#34;&#34;&#34;
    if &#39;mono&#39; in upd_a:
        # Not robust?
        inds = np.arange(len(y))
    elif &#39;sorted&#39; in upd_a:
        N = len(A)
        dC = cvR.diag
        if np.all(dC == dC[0]):
            # Sort y by P
            dC = np.sum(A*A, 0)/(N-1)
        inds = np.argsort(dC)
    else:  # Default: random ordering
        inds = rnd.permutation(len(y))
    return inds</code></pre>
</details>
</dd>
<dt id="dapper.da_methods.ensemble.effective_N"><code class="name flex">
<span>def <span class="ident">effective_N</span></span>(<span>YR, dyR, xN, g)</span>
</code></dt>
<dd>
<div class="desc"><p>Effective ensemble size N.</p>
<p>As measured by the finite-size EnKF-N</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L660-L702" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def effective_N(YR, dyR, xN, g):
    &#34;&#34;&#34;Effective ensemble size N.

    As measured by the finite-size EnKF-N
    &#34;&#34;&#34;
    N, Ny = YR.shape
    N1   = N-1

    V, s, UT = svd0(YR)
    du     = UT @ dyR

    eN, cL = hyperprior_coeffs(s, N, xN, g)

    def pad_rk(arr): return pad0(arr, min(N, Ny))
    def dgn_rk(l1): return pad_rk((l1*s)**2) + N1

    # Make dual cost function (in terms of l1)
    def J(l1):
        val = np.sum(du**2/dgn_rk(l1)) \
            + eN/l1**2 \
            + cL*np.log(l1**2)
        return val

    # Derivatives (not required with minimize_scalar):
    def Jp(l1):
        val = -2*l1   * np.sum(pad_rk(s**2) * du**2/dgn_rk(l1)**2) \
            + -2*eN/l1**3 \
            + 2*cL/l1
        return val

    def Jpp(l1):
        val = 8*l1**2 * np.sum(pad_rk(s**4) * du**2/dgn_rk(l1)**3) \
            + 6*eN/l1**4 \
            + -2*cL/l1**2
        return val

    # Find inflation factor (optimize)
    l1 = Newton_m(Jp, Jpp, 1.0)
    # l1 = fmin_bfgs(J, x0=[1], gtol=1e-4, disp=0)
    # l1 = minimize_scalar(J, bracket=(sqrt(prior_mode), 1e2), tol=1e-4).x

    za = N1/l1**2
    return za</code></pre>
</details>
</dd>
<dt id="dapper.da_methods.ensemble.Newton_m"><code class="name flex">
<span>def <span class="ident">Newton_m</span></span>(<span>fun, deriv, x0, is_inverted=False, conf=1.0, xtol=0.0001, ytol=1e-07, itermax=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Find root of <code>fun</code>.</p>
<p>This is a simple (and pretty fast) implementation of Newton's method.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L730-L749" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def Newton_m(fun, deriv, x0, is_inverted=False,
             conf=1.0, xtol=1e-4, ytol=1e-7, itermax=10**2):
    &#34;&#34;&#34;Find root of `fun`.

    This is a simple (and pretty fast) implementation of Newton&#39;s method.
    &#34;&#34;&#34;
    itr, dx, Jx = 0, np.inf, fun(x0)
    def norm(x): return sqrt(np.sum(x**2))
    while ytol &lt; norm(Jx) and xtol &lt; norm(dx) and itr &lt; itermax:
        Dx  = deriv(x0)
        if is_inverted:
            dx  = Dx @ Jx
        elif isinstance(Dx, float):
            dx  = Jx/Dx
        else:
            dx  = mldiv(Dx, Jx)
        dx *= conf
        x0 -= dx
        Jx  = fun(x0)
    return x0</code></pre>
</details>
</dd>
<dt id="dapper.da_methods.ensemble.hyperprior_coeffs"><code class="name flex">
<span>def <span class="ident">hyperprior_coeffs</span></span>(<span>s, N, xN=1, g=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Set EnKF-N inflation hyperparams.</p>
<p>The EnKF-N prior may be specified by the constants:</p>
<ul>
<li>eN: Effect of unknown mean</li>
<li>cL: Coeff in front of log term</li>
</ul>
<p>These are trivial constants in the original EnKF-N,
but are further adjusted (corrected and tuned) for the following reasons.</p>
<ul>
<li>
<p>Reason 1: mode correction.
These parameters bridge the Jeffreys (<code>xN=1</code>) and Dirac (<code>xN=Inf</code>) hyperpriors
for the prior covariance, B, as discussed in <code><a title="bib.bocquet2015expanding" href="../../bib.html#bib.bocquet2015expanding">bocquet2015expanding</a></code>.
Indeed, mode correction becomes necessary when <span><span class="MathJax_Preview"> R \rightarrow \infty </span><script type="math/tex; mode=display"> R \rightarrow \infty </script></span>
because then there should be no ensemble update (and also no inflation!).
More specifically, the mode of <code>l1</code>'s should be adjusted towards 1
as a function of <span><span class="MathJax_Preview"> I - K H </span><script type="math/tex; mode=display"> I - K H </script></span> ("prior's weight").
PS: why do we leave the prior mode below 1 at all?
Because it sets up "tension" (negative feedback) in the inflation cycle:
the prior pulls downwards, while the likelihood tends to pull upwards.</p>
</li>
<li>
<p>Reason 2: Boosting the inflation prior's certainty from N to xN*N.
The aim is to take advantage of the fact that the ensemble may not
have quite as much sampling error as a fully stochastic sample,
as illustrated in section 2.1 of <code><a title="bib.raanes2019adaptive" href="../../bib.html#bib.raanes2019adaptive">raanes2019adaptive</a></code>.</p>
</li>
<li>
<p>Its damping effect is similar to work done by J. Anderson.</p>
</li>
</ul>
<p>The tuning is controlled by:</p>
<ul>
<li><code>xN=1</code>: is fully agnostic, i.e. assumes the ensemble is generated
from a highly chaotic or stochastic model.</li>
<li><code>xN&gt;1</code>: increases the certainty of the hyper-prior,
which is appropriate for more linear and deterministic systems.</li>
<li><code>xN&lt;1</code>: yields a more (than 'fully') agnostic hyper-prior,
as if N were smaller than it truly is.</li>
<li><code>xN&lt;=0</code> is not meaningful.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L752-L812" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def hyperprior_coeffs(s, N, xN=1, g=0):
    r&#34;&#34;&#34;Set EnKF-N inflation hyperparams.

    The EnKF-N prior may be specified by the constants:

    - eN: Effect of unknown mean
    - cL: Coeff in front of log term

    These are trivial constants in the original EnKF-N,
    but are further adjusted (corrected and tuned) for the following reasons.

    - Reason 1: mode correction.
      These parameters bridge the Jeffreys (`xN=1`) and Dirac (`xN=Inf`) hyperpriors
      for the prior covariance, B, as discussed in `bib.bocquet2015expanding`.
      Indeed, mode correction becomes necessary when $$ R \rightarrow \infty $$
      because then there should be no ensemble update (and also no inflation!).
      More specifically, the mode of `l1`&#39;s should be adjusted towards 1
      as a function of $$ I - K H $$ (&#34;prior&#39;s weight&#34;).
      PS: why do we leave the prior mode below 1 at all?
      Because it sets up &#34;tension&#34; (negative feedback) in the inflation cycle:
      the prior pulls downwards, while the likelihood tends to pull upwards.

    - Reason 2: Boosting the inflation prior&#39;s certainty from N to xN*N.
      The aim is to take advantage of the fact that the ensemble may not
      have quite as much sampling error as a fully stochastic sample,
      as illustrated in section 2.1 of `bib.raanes2019adaptive`.

    - Its damping effect is similar to work done by J. Anderson.

    The tuning is controlled by:

    - `xN=1`: is fully agnostic, i.e. assumes the ensemble is generated
      from a highly chaotic or stochastic model.
    - `xN&gt;1`: increases the certainty of the hyper-prior,
      which is appropriate for more linear and deterministic systems.
    - `xN&lt;1`: yields a more (than &#39;fully&#39;) agnostic hyper-prior,
      as if N were smaller than it truly is.
    - `xN&lt;=0` is not meaningful.
    &#34;&#34;&#34;
    N1 = N-1

    eN = (N+1)/N
    cL = (N+g)/N1

    # Mode correction (almost) as in eqn 36 of `bib.bocquet2015expanding`
    prior_mode = eN/cL                        # Mode of l1 (before correction)
    diagonal   = pad0(s**2, N) + N1           # diag of Y@R.inv@Y + N1*I
    #                                           (Hessian of J)
    I_KH       = np.mean(diagonal**(-1))*N1   # â‰ˆ 1/(1 + HBH/R)
    # I_KH      = 1/(1 + (s**2).sum()/N1)     # Scalar alternative: use tr(HBH/R).
    mc         = sqrt(prior_mode**I_KH)       # Correction coeff

    # Apply correction
    eN /= mc
    cL *= mc

    # Boost by xN
    eN *= xN
    cL *= xN

    return eN, cL</code></pre>
</details>
</dd>
<dt id="dapper.da_methods.ensemble.zeta_a"><code class="name flex">
<span>def <span class="ident">zeta_a</span></span>(<span>eN, cL, w)</span>
</code></dt>
<dd>
<div class="desc"><p>EnKF-N inflation estimation via w.</p>
<p>Returns <code>zeta_a = (N-1)/pre-inflation^2</code>.</p>
<p>Using this inside an iterative minimization as in the
<code><a title="dapper.da_methods.variational.iEnKS" href="variational.html#dapper.da_methods.variational.iEnKS">iEnKS</a></code> effectively blends
the distinction between the primal and dual EnKF-N.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L815-L827" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def zeta_a(eN, cL, w):
    &#34;&#34;&#34;EnKF-N inflation estimation via w.

    Returns `zeta_a = (N-1)/pre-inflation^2`.

    Using this inside an iterative minimization as in the
    `dapper.da_methods.variational.iEnKS` effectively blends
    the distinction between the primal and dual EnKF-N.
    &#34;&#34;&#34;
    N  = len(w)
    N1 = N-1
    za = N1*cL/(eN + w@w)
    return za</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dapper.da_methods.ensemble.EnKF"><code class="flex name class">
<span>class <span class="ident">EnKF</span></span>
<span>(</span><span>upd_a:Â str, N:Â int, infl:Â floatÂ =Â 1.0, rot:Â boolÂ =Â False, fnoise_treatm:Â strÂ =Â 'Stoch')</span>
</code></dt>
<dd>
<div class="desc"><p>The ensemble Kalman filter.</p>
<p>Refs: <code><a title="bib.evensen2009ensemble" href="../../bib.html#bib.evensen2009ensemble">evensen2009ensemble</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L27-L56" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class EnKF:
    &#34;&#34;&#34;The ensemble Kalman filter.

    Refs: `bib.evensen2009ensemble`.
    &#34;&#34;&#34;

    upd_a: str
    N: int

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

        # Init
        E = X0.sample(self.N)
        stats.assess(0, E=E)

        # Loop
        for k, kObs, t, dt in progbar(chrono.ticker):
            E = Dyn(E, t-dt, dt)
            E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

            # Analysis update
            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E)
                E = EnKF_analysis(E, Obs(E, t), Obs.noise,
                                  yy[kObs], self.upd_a, stats, kObs)
                E = post_process(E, self.infl, self.rot)

            stats.assess(k, kObs, E=E)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dapper.da_methods.ensemble.EnKF.upd_a"><code class="name">var <span class="ident">upd_a</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF.N"><code class="name">var <span class="ident">N</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF.infl"><code class="name">var <span class="ident">infl</span> :Â float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF.rot"><code class="name">var <span class="ident">rot</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF.fnoise_treatm"><code class="name">var <span class="ident">fnoise_treatm</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF.da_method"><code class="name">var <span class="ident">da_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.da_methods.ensemble.EnKF.assimilate"><code class="name flex">
<span>def <span class="ident">assimilate</span></span>(<span>self, HMM, xx, yy)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L36-L56" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def assimilate(self, HMM, xx, yy):
    Dyn, Obs, chrono, X0, stats = \
        HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

    # Init
    E = X0.sample(self.N)
    stats.assess(0, E=E)

    # Loop
    for k, kObs, t, dt in progbar(chrono.ticker):
        E = Dyn(E, t-dt, dt)
        E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

        # Analysis update
        if kObs is not None:
            stats.assess(k, kObs, &#39;f&#39;, E=E)
            E = EnKF_analysis(E, Obs(E, t), Obs.noise,
                              yy[kObs], self.upd_a, stats, kObs)
            E = post_process(E, self.infl, self.rot)

        stats.assess(k, kObs, E=E)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dapper.da_methods.ensemble.EnKS"><code class="flex name class">
<span>class <span class="ident">EnKS</span></span>
<span>(</span><span>upd_a:Â str, N:Â int, Lag:Â int, infl:Â floatÂ =Â 1.0, rot:Â boolÂ =Â False, fnoise_treatm:Â strÂ =Â 'Stoch')</span>
</code></dt>
<dd>
<div class="desc"><p>The ensemble Kalman smoother.</p>
<p>Refs: <code><a title="bib.evensen2009ensemble" href="../../bib.html#bib.evensen2009ensemble">evensen2009ensemble</a></code></p>
<p>The only difference to the EnKF
is the management of the lag and the reshapings.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L349-L406" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class EnKS:
    &#34;&#34;&#34;The ensemble Kalman smoother.

    Refs: `bib.evensen2009ensemble`

    The only difference to the EnKF
    is the management of the lag and the reshapings.
    &#34;&#34;&#34;

    upd_a: str
    N: int
    Lag: int

    # Reshapings used in smoothers to go to/from
    # 3D arrays, where the 0th axis is the Lag index.
    def reshape_to(self, E):
        K, N, Nx = E.shape
        return E.transpose([1, 0, 2]).reshape((N, K*Nx))

    def reshape_fr(self, E, Nx):
        N, Km = E.shape
        K    = Km//Nx
        return E.reshape((N, K, Nx)).transpose([1, 0, 2])

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

        # Inefficient version, storing full time series ensemble.
        # See iEnKS for a &#34;rolling&#34; version.
        E    = zeros((chrono.K+1, self.N, Dyn.M))
        E[0] = X0.sample(self.N)

        for k, kObs, t, dt in progbar(chrono.ticker):
            E[k] = Dyn(E[k-1], t-dt, dt)
            E[k] = add_noise(E[k], dt, Dyn.noise, self.fnoise_treatm)

            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E[k])

                Eo    = Obs(E[k], t)
                y     = yy[kObs]

                # Inds within Lag
                kk    = range(max(0, k-self.Lag*chrono.dkObs), k+1)

                EE    = E[kk]

                EE    = self.reshape_to(EE)
                EE    = EnKF_analysis(EE, Eo, Obs.noise, y, self.upd_a, stats, kObs)
                E[kk] = self.reshape_fr(EE, Dyn.M)
                E[k]  = post_process(E[k], self.infl, self.rot)
                stats.assess(k, kObs, &#39;a&#39;, E=E[k])

        for k, kObs, _, _ in progbar(chrono.ticker, desc=&#39;Assessing&#39;):
            stats.assess(k, kObs, &#39;u&#39;, E=E[k])
            if kObs is not None:
                stats.assess(k, kObs, &#39;s&#39;, E=E[k])</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dapper.da_methods.ensemble.EnKS.upd_a"><code class="name">var <span class="ident">upd_a</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKS.N"><code class="name">var <span class="ident">N</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKS.Lag"><code class="name">var <span class="ident">Lag</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKS.infl"><code class="name">var <span class="ident">infl</span> :Â float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKS.rot"><code class="name">var <span class="ident">rot</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKS.fnoise_treatm"><code class="name">var <span class="ident">fnoise_treatm</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKS.da_method"><code class="name">var <span class="ident">da_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.da_methods.ensemble.EnKS.reshape_to"><code class="name flex">
<span>def <span class="ident">reshape_to</span></span>(<span>self, E)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L364-L366" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def reshape_to(self, E):
    K, N, Nx = E.shape
    return E.transpose([1, 0, 2]).reshape((N, K*Nx))</code></pre>
</details>
</dd>
<dt id="dapper.da_methods.ensemble.EnKS.reshape_fr"><code class="name flex">
<span>def <span class="ident">reshape_fr</span></span>(<span>self, E, Nx)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L368-L371" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def reshape_fr(self, E, Nx):
    N, Km = E.shape
    K    = Km//Nx
    return E.reshape((N, K, Nx)).transpose([1, 0, 2])</code></pre>
</details>
</dd>
<dt id="dapper.da_methods.ensemble.EnKS.assimilate"><code class="name flex">
<span>def <span class="ident">assimilate</span></span>(<span>self, HMM, xx, yy)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L373-L406" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def assimilate(self, HMM, xx, yy):
    Dyn, Obs, chrono, X0, stats = \
        HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

    # Inefficient version, storing full time series ensemble.
    # See iEnKS for a &#34;rolling&#34; version.
    E    = zeros((chrono.K+1, self.N, Dyn.M))
    E[0] = X0.sample(self.N)

    for k, kObs, t, dt in progbar(chrono.ticker):
        E[k] = Dyn(E[k-1], t-dt, dt)
        E[k] = add_noise(E[k], dt, Dyn.noise, self.fnoise_treatm)

        if kObs is not None:
            stats.assess(k, kObs, &#39;f&#39;, E=E[k])

            Eo    = Obs(E[k], t)
            y     = yy[kObs]

            # Inds within Lag
            kk    = range(max(0, k-self.Lag*chrono.dkObs), k+1)

            EE    = E[kk]

            EE    = self.reshape_to(EE)
            EE    = EnKF_analysis(EE, Eo, Obs.noise, y, self.upd_a, stats, kObs)
            E[kk] = self.reshape_fr(EE, Dyn.M)
            E[k]  = post_process(E[k], self.infl, self.rot)
            stats.assess(k, kObs, &#39;a&#39;, E=E[k])

    for k, kObs, _, _ in progbar(chrono.ticker, desc=&#39;Assessing&#39;):
        stats.assess(k, kObs, &#39;u&#39;, E=E[k])
        if kObs is not None:
            stats.assess(k, kObs, &#39;s&#39;, E=E[k])</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dapper.da_methods.ensemble.EnRTS"><code class="flex name class">
<span>class <span class="ident">EnRTS</span></span>
<span>(</span><span>upd_a:Â str, N:Â int, cntr:Â float, infl:Â floatÂ =Â 1.0, rot:Â boolÂ =Â False, fnoise_treatm:Â strÂ =Â 'Stoch')</span>
</code></dt>
<dd>
<div class="desc"><p>EnRTS (Rauch-Tung-Striebel) smoother.</p>
<p>Refs: <code><a title="bib.raanes2016thesis" href="../../bib.html#bib.raanes2016thesis">raanes2016thesis</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L410-L455" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class EnRTS:
    &#34;&#34;&#34;EnRTS (Rauch-Tung-Striebel) smoother.

    Refs: `bib.raanes2016thesis`
    &#34;&#34;&#34;

    upd_a: str
    N: int
    cntr: float

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

        E    = zeros((chrono.K+1, self.N, Dyn.M))
        Ef   = E.copy()
        E[0] = X0.sample(self.N)

        # Forward pass
        for k, kObs, t, dt in progbar(chrono.ticker):
            E[k]  = Dyn(E[k-1], t-dt, dt)
            E[k]  = add_noise(E[k], dt, Dyn.noise, self.fnoise_treatm)
            Ef[k] = E[k]

            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E[k])
                Eo   = Obs(E[k], t)
                y    = yy[kObs]
                E[k] = EnKF_analysis(E[k], Eo, Obs.noise, y, self.upd_a, stats, kObs)
                E[k] = post_process(E[k], self.infl, self.rot)
                stats.assess(k, kObs, &#39;a&#39;, E=E[k])

        # Backward pass
        for k in progbar(range(chrono.K)[::-1]):
            A  = center(E[k])[0]
            Af = center(Ef[k+1])[0]

            J = tinv(Af) @ A
            J *= self.cntr

            E[k] += (E[k+1] - Ef[k+1]) @ J

        for k, kObs, _, _ in progbar(chrono.ticker, desc=&#39;Assessing&#39;):
            stats.assess(k, kObs, &#39;u&#39;, E=E[k])
            if kObs is not None:
                stats.assess(k, kObs, &#39;s&#39;, E=E[k])</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dapper.da_methods.ensemble.EnRTS.upd_a"><code class="name">var <span class="ident">upd_a</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnRTS.N"><code class="name">var <span class="ident">N</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnRTS.cntr"><code class="name">var <span class="ident">cntr</span> :Â float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnRTS.infl"><code class="name">var <span class="ident">infl</span> :Â float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnRTS.rot"><code class="name">var <span class="ident">rot</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnRTS.fnoise_treatm"><code class="name">var <span class="ident">fnoise_treatm</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnRTS.da_method"><code class="name">var <span class="ident">da_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.da_methods.ensemble.EnRTS.assimilate"><code class="name flex">
<span>def <span class="ident">assimilate</span></span>(<span>self, HMM, xx, yy)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L420-L455" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def assimilate(self, HMM, xx, yy):
    Dyn, Obs, chrono, X0, stats = \
        HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

    E    = zeros((chrono.K+1, self.N, Dyn.M))
    Ef   = E.copy()
    E[0] = X0.sample(self.N)

    # Forward pass
    for k, kObs, t, dt in progbar(chrono.ticker):
        E[k]  = Dyn(E[k-1], t-dt, dt)
        E[k]  = add_noise(E[k], dt, Dyn.noise, self.fnoise_treatm)
        Ef[k] = E[k]

        if kObs is not None:
            stats.assess(k, kObs, &#39;f&#39;, E=E[k])
            Eo   = Obs(E[k], t)
            y    = yy[kObs]
            E[k] = EnKF_analysis(E[k], Eo, Obs.noise, y, self.upd_a, stats, kObs)
            E[k] = post_process(E[k], self.infl, self.rot)
            stats.assess(k, kObs, &#39;a&#39;, E=E[k])

    # Backward pass
    for k in progbar(range(chrono.K)[::-1]):
        A  = center(E[k])[0]
        Af = center(Ef[k+1])[0]

        J = tinv(Af) @ A
        J *= self.cntr

        E[k] += (E[k+1] - Ef[k+1]) @ J

    for k, kObs, _, _ in progbar(chrono.ticker, desc=&#39;Assessing&#39;):
        stats.assess(k, kObs, &#39;u&#39;, E=E[k])
        if kObs is not None:
            stats.assess(k, kObs, &#39;s&#39;, E=E[k])</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dapper.da_methods.ensemble.SL_EAKF"><code class="flex name class">
<span>class <span class="ident">SL_EAKF</span></span>
<span>(</span><span>N:Â int, loc_rad:Â float, taper:Â strÂ =Â 'GC', ordr:Â strÂ =Â 'rand', infl:Â floatÂ =Â 1.0, rot:Â boolÂ =Â False, fnoise_treatm:Â strÂ =Â 'Stoch')</span>
</code></dt>
<dd>
<div class="desc"><p>Serial, covariance-localized EAKF.</p>
<p>Refs: <code><a title="bib.karspeck2007experimental" href="../../bib.html#bib.karspeck2007experimental">karspeck2007experimental</a></code>.</p>
<p>Used without localization, this should be equivalent (full ensemble equality)
to the <code><a title="dapper.da_methods.ensemble.EnKF" href="#dapper.da_methods.ensemble.EnKF">EnKF</a></code> with <code>upd_a='Serial'</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L481-L550" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class SL_EAKF:
    &#34;&#34;&#34;Serial, covariance-localized EAKF.

    Refs: `bib.karspeck2007experimental`.

    Used without localization, this should be equivalent (full ensemble equality)
    to the `EnKF` with `upd_a=&#39;Serial&#39;`.
    &#34;&#34;&#34;

    N: int
    loc_rad: float
    taper: str  = &#39;GC&#39;
    ordr: str   = &#39;rand&#39;

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

        N1   = self.N-1
        R    = Obs.noise
        Rm12 = Obs.noise.C.sym_sqrt_inv

        E = X0.sample(self.N)
        stats.assess(0, E=E)

        for k, kObs, t, dt in progbar(chrono.ticker):
            E = Dyn(E, t-dt, dt)
            E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E)
                y    = yy[kObs]
                inds = serial_inds(self.ordr, y, R, center(E)[0])

                state_taperer = Obs.localizer(self.loc_rad, &#39;y2x&#39;, t, self.taper)
                for j in inds:
                    # Prep:
                    # ------------------------------------------------------
                    Eo = Obs(E, t)
                    xo = np.mean(Eo, 0)
                    Y  = Eo - xo
                    mu = np.mean(E, 0)
                    A  = E-mu
                    # Update j-th component of observed ensemble:
                    # ------------------------------------------------------
                    Y_j    = Rm12[j, :] @ Y.T
                    dy_j   = Rm12[j, :] @ (y - xo)
                    # Prior var * N1:
                    sig2_j = Y_j@Y_j
                    if sig2_j &lt; 1e-9:
                        continue
                    # Update (below, we drop the locality subscript: _j)
                    sig2_u = 1/(1/sig2_j + 1/N1)      # Postr. var * N1
                    alpha  = (N1/(N1+sig2_j))**(0.5)  # Update contraction factor
                    dy2    = sig2_u * dy_j/N1         # Mean update
                    Y2     = alpha*Y_j                # Anomaly update
                    # Update state (regress update from obs space, using localization)
                    # ------------------------------------------------------
                    ii, tapering = state_taperer(j)
                    # ii, tapering = ..., 1  # cancel localization
                    if len(ii) == 0:
                        continue
                    Xi = A[:, ii]*tapering
                    Regression = Xi.T @ Y_j/np.sum(Y_j**2)
                    mu[ii] += Regression*dy2
                    A[:, ii] += np.outer(Y2 - Y_j, Regression)
                    E = mu + A

                E = post_process(E, self.infl, self.rot)

            stats.assess(k, kObs, E=E)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dapper.da_methods.ensemble.SL_EAKF.N"><code class="name">var <span class="ident">N</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.SL_EAKF.loc_rad"><code class="name">var <span class="ident">loc_rad</span> :Â float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.SL_EAKF.taper"><code class="name">var <span class="ident">taper</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.SL_EAKF.ordr"><code class="name">var <span class="ident">ordr</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.SL_EAKF.infl"><code class="name">var <span class="ident">infl</span> :Â float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.SL_EAKF.rot"><code class="name">var <span class="ident">rot</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.SL_EAKF.fnoise_treatm"><code class="name">var <span class="ident">fnoise_treatm</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.SL_EAKF.da_method"><code class="name">var <span class="ident">da_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.da_methods.ensemble.SL_EAKF.assimilate"><code class="name flex">
<span>def <span class="ident">assimilate</span></span>(<span>self, HMM, xx, yy)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L495-L550" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def assimilate(self, HMM, xx, yy):
    Dyn, Obs, chrono, X0, stats = HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats

    N1   = self.N-1
    R    = Obs.noise
    Rm12 = Obs.noise.C.sym_sqrt_inv

    E = X0.sample(self.N)
    stats.assess(0, E=E)

    for k, kObs, t, dt in progbar(chrono.ticker):
        E = Dyn(E, t-dt, dt)
        E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

        if kObs is not None:
            stats.assess(k, kObs, &#39;f&#39;, E=E)
            y    = yy[kObs]
            inds = serial_inds(self.ordr, y, R, center(E)[0])

            state_taperer = Obs.localizer(self.loc_rad, &#39;y2x&#39;, t, self.taper)
            for j in inds:
                # Prep:
                # ------------------------------------------------------
                Eo = Obs(E, t)
                xo = np.mean(Eo, 0)
                Y  = Eo - xo
                mu = np.mean(E, 0)
                A  = E-mu
                # Update j-th component of observed ensemble:
                # ------------------------------------------------------
                Y_j    = Rm12[j, :] @ Y.T
                dy_j   = Rm12[j, :] @ (y - xo)
                # Prior var * N1:
                sig2_j = Y_j@Y_j
                if sig2_j &lt; 1e-9:
                    continue
                # Update (below, we drop the locality subscript: _j)
                sig2_u = 1/(1/sig2_j + 1/N1)      # Postr. var * N1
                alpha  = (N1/(N1+sig2_j))**(0.5)  # Update contraction factor
                dy2    = sig2_u * dy_j/N1         # Mean update
                Y2     = alpha*Y_j                # Anomaly update
                # Update state (regress update from obs space, using localization)
                # ------------------------------------------------------
                ii, tapering = state_taperer(j)
                # ii, tapering = ..., 1  # cancel localization
                if len(ii) == 0:
                    continue
                Xi = A[:, ii]*tapering
                Regression = Xi.T @ Y_j/np.sum(Y_j**2)
                mu[ii] += Regression*dy2
                A[:, ii] += np.outer(Y2 - Y_j, Regression)
                E = mu + A

            E = post_process(E, self.infl, self.rot)

        stats.assess(k, kObs, E=E)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dapper.da_methods.ensemble.LETKF"><code class="flex name class">
<span>class <span class="ident">LETKF</span></span>
<span>(</span><span>N:Â int, loc_rad:Â float, taper:Â strÂ =Â 'GC', xN:Â floatÂ =Â 1.0, g:Â intÂ =Â 0, mp:Â boolÂ =Â False, infl:Â floatÂ =Â 1.0, rot:Â boolÂ =Â False, fnoise_treatm:Â strÂ =Â 'Stoch')</span>
</code></dt>
<dd>
<div class="desc"><p>Same as EnKF (sqrt), but with localization.</p>
<p>Refs: <code><a title="bib.hunt2007efficient" href="../../bib.html#bib.hunt2007efficient">hunt2007efficient</a></code>.</p>
<p>NB: Multiproc. yields slow-down for <code><a title="dapper.mods.Lorenz96" href="../mods/Lorenz96/index.html">dapper.mods.Lorenz96</a></code>,
even with <code>batch_size=(1,)</code>. But for <code><a title="dapper.mods.QG" href="../mods/QG/index.html">dapper.mods.QG</a></code>
(<code>batch_size=(2,2)</code> or less) it is quicker.</p>
<p>NB: If <code>len(ii)</code> is small, analysis may be slowed-down with '-N' infl.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L554-L657" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class LETKF:
    &#34;&#34;&#34;Same as EnKF (sqrt), but with localization.

    Refs: `bib.hunt2007efficient`.

    NB: Multiproc. yields slow-down for `dapper.mods.Lorenz96`,
    even with `batch_size=(1,)`. But for `dapper.mods.QG`
    (`batch_size=(2,2)` or less) it is quicker.

    NB: If `len(ii)` is small, analysis may be slowed-down with &#39;-N&#39; infl.
    &#34;&#34;&#34;

    N: int
    loc_rad: float
    taper: str = &#39;GC&#39;
    xN: float  = 1.0
    g: int     = 0
    mp: bool   = False

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats, N = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats, self.N
        R, N1 = HMM.Obs.noise.C, N-1

        _map = mp.map if self.mp else map

        E = X0.sample(N)
        stats.assess(0, E=E)

        for k, kObs, t, dt in progbar(chrono.ticker):
            # Forecast
            E = Dyn(E, t-dt, dt)
            E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E)

                # Decompose ensmeble
                mu = np.mean(E, 0)
                A  = E - mu
                # Obs space variables
                y     = yy[kObs]
                Y, xo = center(Obs(E, t))
                # Transform obs space
                Y  = Y        @ R.sym_sqrt_inv.T
                dy = (y - xo) @ R.sym_sqrt_inv.T

                # Local analyses
                # Get localization configuration
                state_batches, obs_taperer = \
                    Obs.localizer(self.loc_rad, &#39;x2y&#39;, t, self.taper)
                # Avoid pickling self
                xN, g, infl = self.xN, self.g, self.infl

                def local_analysis(ii):
                    &#34;&#34;&#34;Do the local analysis.

                    Notation:

                    - ii: inds for the state batch defining the locality
                    - jj: inds for the associated obs
                    &#34;&#34;&#34;
                    # Locate local obs
                    jj, tapering = obs_taperer(ii)
                    if len(jj) == 0:
                        return E[:, ii], N1  # no update
                    Y_jj   = Y[:, jj]
                    dy_jj  = dy[jj]

                    # Adaptive inflation
                    za = effective_N(Y_jj, dy_jj, xN, g) if infl == &#39;-N&#39; else N1

                    # Taper
                    Y_jj  *= sqrt(tapering)
                    dy_jj *= sqrt(tapering)

                    # Compute ETKF update
                    if len(jj) &lt; N:
                        # SVD version
                        V, sd, _ = svd0(Y_jj)
                        d      = pad0(sd**2, N) + za
                        Pw     = (V * d**(-1.0)) @ V.T
                        T      = (V * d**(-0.5)) @ V.T * sqrt(za)
                    else:
                        # EVD version
                        d, V   = sla.eigh(Y_jj@Y_jj.T + za*eye(N))
                        T     = V@diag(d**(-0.5))@V.T * sqrt(za)
                        Pw    = V@diag(d**(-1.0))@V.T
                    AT  = T @ A[:, ii]
                    dmu = dy_jj @ Y_jj.T @ Pw @ A[:, ii]
                    Eii = mu[ii] + dmu + AT
                    return Eii, za

                # Run local analyses
                EE, za = zip(*_map(local_analysis, state_batches))
                for ii, Eii in zip(state_batches, EE):
                    E[:, ii] = Eii

                # Global post-processing
                E = post_process(E, self.infl, self.rot)

                stats.infl[kObs] = sqrt(N1/np.mean(za))

            stats.assess(k, kObs, E=E)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dapper.da_methods.ensemble.LETKF.N"><code class="name">var <span class="ident">N</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.LETKF.loc_rad"><code class="name">var <span class="ident">loc_rad</span> :Â float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.LETKF.taper"><code class="name">var <span class="ident">taper</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.LETKF.xN"><code class="name">var <span class="ident">xN</span> :Â float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.LETKF.g"><code class="name">var <span class="ident">g</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.LETKF.mp"><code class="name">var <span class="ident">mp</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.LETKF.infl"><code class="name">var <span class="ident">infl</span> :Â float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.LETKF.rot"><code class="name">var <span class="ident">rot</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.LETKF.fnoise_treatm"><code class="name">var <span class="ident">fnoise_treatm</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.LETKF.da_method"><code class="name">var <span class="ident">da_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.da_methods.ensemble.LETKF.assimilate"><code class="name flex">
<span>def <span class="ident">assimilate</span></span>(<span>self, HMM, xx, yy)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L573-L657" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def assimilate(self, HMM, xx, yy):
    Dyn, Obs, chrono, X0, stats, N = \
        HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats, self.N
    R, N1 = HMM.Obs.noise.C, N-1

    _map = mp.map if self.mp else map

    E = X0.sample(N)
    stats.assess(0, E=E)

    for k, kObs, t, dt in progbar(chrono.ticker):
        # Forecast
        E = Dyn(E, t-dt, dt)
        E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

        if kObs is not None:
            stats.assess(k, kObs, &#39;f&#39;, E=E)

            # Decompose ensmeble
            mu = np.mean(E, 0)
            A  = E - mu
            # Obs space variables
            y     = yy[kObs]
            Y, xo = center(Obs(E, t))
            # Transform obs space
            Y  = Y        @ R.sym_sqrt_inv.T
            dy = (y - xo) @ R.sym_sqrt_inv.T

            # Local analyses
            # Get localization configuration
            state_batches, obs_taperer = \
                Obs.localizer(self.loc_rad, &#39;x2y&#39;, t, self.taper)
            # Avoid pickling self
            xN, g, infl = self.xN, self.g, self.infl

            def local_analysis(ii):
                &#34;&#34;&#34;Do the local analysis.

                Notation:

                - ii: inds for the state batch defining the locality
                - jj: inds for the associated obs
                &#34;&#34;&#34;
                # Locate local obs
                jj, tapering = obs_taperer(ii)
                if len(jj) == 0:
                    return E[:, ii], N1  # no update
                Y_jj   = Y[:, jj]
                dy_jj  = dy[jj]

                # Adaptive inflation
                za = effective_N(Y_jj, dy_jj, xN, g) if infl == &#39;-N&#39; else N1

                # Taper
                Y_jj  *= sqrt(tapering)
                dy_jj *= sqrt(tapering)

                # Compute ETKF update
                if len(jj) &lt; N:
                    # SVD version
                    V, sd, _ = svd0(Y_jj)
                    d      = pad0(sd**2, N) + za
                    Pw     = (V * d**(-1.0)) @ V.T
                    T      = (V * d**(-0.5)) @ V.T * sqrt(za)
                else:
                    # EVD version
                    d, V   = sla.eigh(Y_jj@Y_jj.T + za*eye(N))
                    T     = V@diag(d**(-0.5))@V.T * sqrt(za)
                    Pw    = V@diag(d**(-1.0))@V.T
                AT  = T @ A[:, ii]
                dmu = dy_jj @ Y_jj.T @ Pw @ A[:, ii]
                Eii = mu[ii] + dmu + AT
                return Eii, za

            # Run local analyses
            EE, za = zip(*_map(local_analysis, state_batches))
            for ii, Eii in zip(state_batches, EE):
                E[:, ii] = Eii

            # Global post-processing
            E = post_process(E, self.infl, self.rot)

            stats.infl[kObs] = sqrt(N1/np.mean(za))

        stats.assess(k, kObs, E=E)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF_N"><code class="flex name class">
<span>class <span class="ident">EnKF_N</span></span>
<span>(</span><span>N:Â int, dual:Â boolÂ =Â False, Hess:Â boolÂ =Â False, xN:Â floatÂ =Â 1.0, g:Â intÂ =Â 0, infl:Â floatÂ =Â 1.0, rot:Â boolÂ =Â False, fnoise_treatm:Â strÂ =Â 'Stoch')</span>
</code></dt>
<dd>
<div class="desc"><p>Finite-size EnKF (EnKF-N).</p>
<p>Refs: <code><a title="bib.bocquet2011ensemble" href="../../bib.html#bib.bocquet2011ensemble">bocquet2011ensemble</a></code>, <code><a title="bib.bocquet2015expanding" href="../../bib.html#bib.bocquet2015expanding">bocquet2015expanding</a></code></p>
<p>This implementation is pedagogical, prioritizing the "dual" form.
In consequence, the efficiency of the "primal" form suffers a bit.
The primal form is included for completeness and to demonstrate equivalence.
In <code><a title="dapper.da_methods.variational.iEnKS" href="variational.html#dapper.da_methods.variational.iEnKS">iEnKS</a></code>, however,
the primal form is preferred because it
already does optimization for w (as treatment for nonlinear models).</p>
<p><code>infl</code> should be unnecessary (assuming no model error, or that Q is correct).</p>
<p><code>Hess</code>: use non-approx Hessian for ensemble transform matrix?</p>
<p><code>g</code> is the nullity of A (state anomalies's), ie. g=max(1,N-Nx),
compensating for the redundancy in the space of w.
But we have made it an input argument instead, with default 0,
because mode-finding (of p(x) via the dual) completely ignores this redundancy,
and the mode gets (undesireably) modified by g.</p>
<p><code>xN</code> allows tuning the hyper-prior for the inflation.
Usually, I just try setting it to 1 (default), or 2.
Further description in hyperprior_coeffs().</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L831-L981" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class EnKF_N:
    &#34;&#34;&#34;Finite-size EnKF (EnKF-N).

    Refs: `bib.bocquet2011ensemble`, `bib.bocquet2015expanding`

    This implementation is pedagogical, prioritizing the &#34;dual&#34; form.
    In consequence, the efficiency of the &#34;primal&#34; form suffers a bit.
    The primal form is included for completeness and to demonstrate equivalence.
    In `dapper.da_methods.variational.iEnKS`, however,
    the primal form is preferred because it
    already does optimization for w (as treatment for nonlinear models).

    `infl` should be unnecessary (assuming no model error, or that Q is correct).

    `Hess`: use non-approx Hessian for ensemble transform matrix?

    `g` is the nullity of A (state anomalies&#39;s), ie. g=max(1,N-Nx),
    compensating for the redundancy in the space of w.
    But we have made it an input argument instead, with default 0,
    because mode-finding (of p(x) via the dual) completely ignores this redundancy,
    and the mode gets (undesireably) modified by g.

    `xN` allows tuning the hyper-prior for the inflation.
    Usually, I just try setting it to 1 (default), or 2.
    Further description in hyperprior_coeffs().
    &#34;&#34;&#34;

    N: int
    dual: bool = False
    Hess: bool = False
    xN: float  = 1.0
    g: int     = 0

    def assimilate(self, HMM, xx, yy):
        # Unpack
        Dyn, Obs, chrono, X0, stats = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats
        R, N, N1 = HMM.Obs.noise.C, self.N, self.N-1

        # Init
        E = X0.sample(N)
        stats.assess(0, E=E)

        # Loop
        for k, kObs, t, dt in progbar(chrono.ticker):
            # Forecast
            E = Dyn(E, t-dt, dt)
            E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

            # Analysis
            if kObs is not None:
                stats.assess(k, kObs, &#39;f&#39;, E=E)
                Eo = Obs(E, t)
                y  = yy[kObs]

                mu = np.mean(E, 0)
                A  = E - mu

                xo = np.mean(Eo, 0)
                Y  = Eo-xo
                dy = y - xo

                V, s, UT = svd0(Y @ R.sym_sqrt_inv.T)
                du       = UT @ (dy @ R.sym_sqrt_inv.T)
                def dgn_N(l1): return pad0((l1*s)**2, N) + N1

                # Adjust hyper-prior
                # xN_ = noise_level(self.xN,stats,chrono,N1,kObs,A,
                #                   locals().get(&#39;A_old&#39;,None))
                eN, cL = hyperprior_coeffs(s, N, self.xN, self.g)

                if self.dual:
                    # Make dual cost function (in terms of l1)
                    def pad_rk(arr): return pad0(arr, min(N, Obs.M))
                    def dgn_rk(l1): return pad_rk((l1*s)**2) + N1

                    def J(l1):
                        val = np.sum(du**2/dgn_rk(l1)) \
                            + eN/l1**2 \
                            + cL*np.log(l1**2)
                        return val

                    # Derivatives (not required with minimize_scalar):
                    def Jp(l1):
                        val = -2*l1 * np.sum(pad_rk(s**2) * du**2/dgn_rk(l1)**2) \
                            + -2*eN/l1**3 + 2*cL/l1
                        return val

                    def Jpp(l1):
                        val = 8*l1**2 * np.sum(pad_rk(s**4) * du**2/dgn_rk(l1)**3) \
                            + 6*eN/l1**4 + -2*cL/l1**2
                        return val
                    # Find inflation factor (optimize)
                    l1 = Newton_m(Jp, Jpp, 1.0)
                    # l1 = fmin_bfgs(J, x0=[1], gtol=1e-4, disp=0)
                    # l1 = minimize_scalar(J, bracket=(sqrt(prior_mode), 1e2),
                    #                      tol=1e-4).x

                else:
                    # Primal form, in a fully linearized version.
                    def za(w): return zeta_a(eN, cL, w)

                    def J(w): return \
                        .5*np.sum(((dy-w@Y)@R.sym_sqrt_inv.T)**2) + \
                        .5*N1*cL*np.log(eN + w@w)
                    # Derivatives (not required with fmin_bfgs):
                    def Jp(w): return -Y@R.inv@(dy-w@Y) + w*za(w)
                    # Jpp   = lambda w:  Y@R.inv@Y.T + \
                    #     za(w)*(eye(N) - 2*np.outer(w,w)/(eN + w@w))
                    # Approx: no radial-angular cross-deriv:
                    # Jpp   = lambda w:  Y@R.inv@Y.T + za(w)*eye(N)

                    def nvrs(w):
                        # inverse of Jpp-approx
                        return (V * (pad0(s**2, N) + za(w)) ** -1.0) @ V.T
                    # Find w (optimize)
                    wa     = Newton_m(Jp, nvrs, zeros(N), is_inverted=True)
                    # wa   = Newton_m(Jp,Jpp ,zeros(N))
                    # wa   = fmin_bfgs(J,zeros(N),Jp,disp=0)
                    l1     = sqrt(N1/za(wa))

                # Uncomment to revert to ETKF
                # l1 = 1.0

                # Explicitly inflate prior
                # =&gt; formulae look different from `bib.bocquet2015expanding`.
                A *= l1
                Y *= l1

                # Compute sqrt update
                Pw = (V * dgn_N(l1)**(-1.0)) @ V.T
                w  = dy@R.inv@Y.T@Pw
                # For the anomalies:
                if not self.Hess:
                    # Regular ETKF (i.e. sym sqrt) update (with inflation)
                    T = (V * dgn_N(l1)**(-0.5)) @ V.T * sqrt(N1)
                    # = (Y@R.inv@Y.T/N1 + eye(N))**(-0.5)
                else:
                    # Also include angular-radial co-dependence.
                    # Note: denominator not squared coz
                    # unlike `bib.bocquet2015expanding` we have inflated Y.
                    Hw = Y@R.inv@Y.T/N1 + eye(N) - 2*np.outer(w, w)/(eN + w@w)
                    T  = funm_psd(Hw, lambda x: x**-.5)  # is there a sqrtm Woodbury?

                E = mu + w@A + T@A
                E = post_process(E, self.infl, self.rot)

                stats.infl[kObs] = l1
                stats.trHK[kObs] = (((l1*s)**2 + N1)**(-1.0)*s**2).sum()/HMM.Ny

            stats.assess(k, kObs, E=E)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dapper.da_methods.ensemble.EnKF_N.N"><code class="name">var <span class="ident">N</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF_N.dual"><code class="name">var <span class="ident">dual</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF_N.Hess"><code class="name">var <span class="ident">Hess</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF_N.xN"><code class="name">var <span class="ident">xN</span> :Â float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF_N.g"><code class="name">var <span class="ident">g</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF_N.infl"><code class="name">var <span class="ident">infl</span> :Â float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF_N.rot"><code class="name">var <span class="ident">rot</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF_N.fnoise_treatm"><code class="name">var <span class="ident">fnoise_treatm</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.ensemble.EnKF_N.da_method"><code class="name">var <span class="ident">da_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.da_methods.ensemble.EnKF_N.assimilate"><code class="name flex">
<span>def <span class="ident">assimilate</span></span>(<span>self, HMM, xx, yy)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/ensemble.py#L864-L981" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def assimilate(self, HMM, xx, yy):
    # Unpack
    Dyn, Obs, chrono, X0, stats = \
        HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats
    R, N, N1 = HMM.Obs.noise.C, self.N, self.N-1

    # Init
    E = X0.sample(N)
    stats.assess(0, E=E)

    # Loop
    for k, kObs, t, dt in progbar(chrono.ticker):
        # Forecast
        E = Dyn(E, t-dt, dt)
        E = add_noise(E, dt, Dyn.noise, self.fnoise_treatm)

        # Analysis
        if kObs is not None:
            stats.assess(k, kObs, &#39;f&#39;, E=E)
            Eo = Obs(E, t)
            y  = yy[kObs]

            mu = np.mean(E, 0)
            A  = E - mu

            xo = np.mean(Eo, 0)
            Y  = Eo-xo
            dy = y - xo

            V, s, UT = svd0(Y @ R.sym_sqrt_inv.T)
            du       = UT @ (dy @ R.sym_sqrt_inv.T)
            def dgn_N(l1): return pad0((l1*s)**2, N) + N1

            # Adjust hyper-prior
            # xN_ = noise_level(self.xN,stats,chrono,N1,kObs,A,
            #                   locals().get(&#39;A_old&#39;,None))
            eN, cL = hyperprior_coeffs(s, N, self.xN, self.g)

            if self.dual:
                # Make dual cost function (in terms of l1)
                def pad_rk(arr): return pad0(arr, min(N, Obs.M))
                def dgn_rk(l1): return pad_rk((l1*s)**2) + N1

                def J(l1):
                    val = np.sum(du**2/dgn_rk(l1)) \
                        + eN/l1**2 \
                        + cL*np.log(l1**2)
                    return val

                # Derivatives (not required with minimize_scalar):
                def Jp(l1):
                    val = -2*l1 * np.sum(pad_rk(s**2) * du**2/dgn_rk(l1)**2) \
                        + -2*eN/l1**3 + 2*cL/l1
                    return val

                def Jpp(l1):
                    val = 8*l1**2 * np.sum(pad_rk(s**4) * du**2/dgn_rk(l1)**3) \
                        + 6*eN/l1**4 + -2*cL/l1**2
                    return val
                # Find inflation factor (optimize)
                l1 = Newton_m(Jp, Jpp, 1.0)
                # l1 = fmin_bfgs(J, x0=[1], gtol=1e-4, disp=0)
                # l1 = minimize_scalar(J, bracket=(sqrt(prior_mode), 1e2),
                #                      tol=1e-4).x

            else:
                # Primal form, in a fully linearized version.
                def za(w): return zeta_a(eN, cL, w)

                def J(w): return \
                    .5*np.sum(((dy-w@Y)@R.sym_sqrt_inv.T)**2) + \
                    .5*N1*cL*np.log(eN + w@w)
                # Derivatives (not required with fmin_bfgs):
                def Jp(w): return -Y@R.inv@(dy-w@Y) + w*za(w)
                # Jpp   = lambda w:  Y@R.inv@Y.T + \
                #     za(w)*(eye(N) - 2*np.outer(w,w)/(eN + w@w))
                # Approx: no radial-angular cross-deriv:
                # Jpp   = lambda w:  Y@R.inv@Y.T + za(w)*eye(N)

                def nvrs(w):
                    # inverse of Jpp-approx
                    return (V * (pad0(s**2, N) + za(w)) ** -1.0) @ V.T
                # Find w (optimize)
                wa     = Newton_m(Jp, nvrs, zeros(N), is_inverted=True)
                # wa   = Newton_m(Jp,Jpp ,zeros(N))
                # wa   = fmin_bfgs(J,zeros(N),Jp,disp=0)
                l1     = sqrt(N1/za(wa))

            # Uncomment to revert to ETKF
            # l1 = 1.0

            # Explicitly inflate prior
            # =&gt; formulae look different from `bib.bocquet2015expanding`.
            A *= l1
            Y *= l1

            # Compute sqrt update
            Pw = (V * dgn_N(l1)**(-1.0)) @ V.T
            w  = dy@R.inv@Y.T@Pw
            # For the anomalies:
            if not self.Hess:
                # Regular ETKF (i.e. sym sqrt) update (with inflation)
                T = (V * dgn_N(l1)**(-0.5)) @ V.T * sqrt(N1)
                # = (Y@R.inv@Y.T/N1 + eye(N))**(-0.5)
            else:
                # Also include angular-radial co-dependence.
                # Note: denominator not squared coz
                # unlike `bib.bocquet2015expanding` we have inflated Y.
                Hw = Y@R.inv@Y.T/N1 + eye(N) - 2*np.outer(w, w)/(eN + w@w)
                T  = funm_psd(Hw, lambda x: x**-.5)  # is there a sqrtm Woodbury?

            E = mu + w@A + T@A
            E = post_process(E, self.infl, self.rot)

            stats.infl[kObs] = l1
            stats.trHK[kObs] = (((l1*s)**2 + N1)**(-1.0)*s**2).sum()/HMM.Ny

        stats.assess(k, kObs, E=E)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="DAPPER" href="https://nansencenter.github.io/DAPPER">
<img src="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo_wtxt.png" alt="">
<!-- can add style="width:200px;" to img -->
</a>
</header>
<div class="gcse-search" style="height: 70px"
data-as_oq="inurl:github.com/nansencenter/DAPPER site:nansencenter.github.io/DAPPER"
data-gaCategoryParameter="dapper.da_methods.ensemble">
</div>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dapper.da_methods" href="index.html">dapper.da_methods</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="dapper.da_methods.ensemble.EnKF_analysis" href="#dapper.da_methods.ensemble.EnKF_analysis">EnKF_analysis</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.post_process" href="#dapper.da_methods.ensemble.post_process">post_process</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.add_noise" href="#dapper.da_methods.ensemble.add_noise">add_noise</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.serial_inds" href="#dapper.da_methods.ensemble.serial_inds">serial_inds</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.effective_N" href="#dapper.da_methods.ensemble.effective_N">effective_N</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.Newton_m" href="#dapper.da_methods.ensemble.Newton_m">Newton_m</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.hyperprior_coeffs" href="#dapper.da_methods.ensemble.hyperprior_coeffs">hyperprior_coeffs</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.zeta_a" href="#dapper.da_methods.ensemble.zeta_a">zeta_a</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dapper.da_methods.ensemble.EnKF" href="#dapper.da_methods.ensemble.EnKF">EnKF</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.da_methods.ensemble.EnKF.assimilate" href="#dapper.da_methods.ensemble.EnKF.assimilate">assimilate</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF.upd_a" href="#dapper.da_methods.ensemble.EnKF.upd_a">upd_a</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF.N" href="#dapper.da_methods.ensemble.EnKF.N">N</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF.infl" href="#dapper.da_methods.ensemble.EnKF.infl">infl</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF.rot" href="#dapper.da_methods.ensemble.EnKF.rot">rot</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF.fnoise_treatm" href="#dapper.da_methods.ensemble.EnKF.fnoise_treatm">fnoise_treatm</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF.da_method" href="#dapper.da_methods.ensemble.EnKF.da_method">da_method</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.da_methods.ensemble.EnKS" href="#dapper.da_methods.ensemble.EnKS">EnKS</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.da_methods.ensemble.EnKS.reshape_to" href="#dapper.da_methods.ensemble.EnKS.reshape_to">reshape_to</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKS.reshape_fr" href="#dapper.da_methods.ensemble.EnKS.reshape_fr">reshape_fr</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKS.assimilate" href="#dapper.da_methods.ensemble.EnKS.assimilate">assimilate</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKS.upd_a" href="#dapper.da_methods.ensemble.EnKS.upd_a">upd_a</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKS.N" href="#dapper.da_methods.ensemble.EnKS.N">N</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKS.Lag" href="#dapper.da_methods.ensemble.EnKS.Lag">Lag</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKS.infl" href="#dapper.da_methods.ensemble.EnKS.infl">infl</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKS.rot" href="#dapper.da_methods.ensemble.EnKS.rot">rot</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKS.fnoise_treatm" href="#dapper.da_methods.ensemble.EnKS.fnoise_treatm">fnoise_treatm</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKS.da_method" href="#dapper.da_methods.ensemble.EnKS.da_method">da_method</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.da_methods.ensemble.EnRTS" href="#dapper.da_methods.ensemble.EnRTS">EnRTS</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.da_methods.ensemble.EnRTS.assimilate" href="#dapper.da_methods.ensemble.EnRTS.assimilate">assimilate</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnRTS.upd_a" href="#dapper.da_methods.ensemble.EnRTS.upd_a">upd_a</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnRTS.N" href="#dapper.da_methods.ensemble.EnRTS.N">N</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnRTS.cntr" href="#dapper.da_methods.ensemble.EnRTS.cntr">cntr</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnRTS.infl" href="#dapper.da_methods.ensemble.EnRTS.infl">infl</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnRTS.rot" href="#dapper.da_methods.ensemble.EnRTS.rot">rot</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnRTS.fnoise_treatm" href="#dapper.da_methods.ensemble.EnRTS.fnoise_treatm">fnoise_treatm</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnRTS.da_method" href="#dapper.da_methods.ensemble.EnRTS.da_method">da_method</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.da_methods.ensemble.SL_EAKF" href="#dapper.da_methods.ensemble.SL_EAKF">SL_EAKF</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.da_methods.ensemble.SL_EAKF.assimilate" href="#dapper.da_methods.ensemble.SL_EAKF.assimilate">assimilate</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.SL_EAKF.N" href="#dapper.da_methods.ensemble.SL_EAKF.N">N</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.SL_EAKF.loc_rad" href="#dapper.da_methods.ensemble.SL_EAKF.loc_rad">loc_rad</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.SL_EAKF.taper" href="#dapper.da_methods.ensemble.SL_EAKF.taper">taper</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.SL_EAKF.ordr" href="#dapper.da_methods.ensemble.SL_EAKF.ordr">ordr</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.SL_EAKF.infl" href="#dapper.da_methods.ensemble.SL_EAKF.infl">infl</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.SL_EAKF.rot" href="#dapper.da_methods.ensemble.SL_EAKF.rot">rot</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.SL_EAKF.fnoise_treatm" href="#dapper.da_methods.ensemble.SL_EAKF.fnoise_treatm">fnoise_treatm</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.SL_EAKF.da_method" href="#dapper.da_methods.ensemble.SL_EAKF.da_method">da_method</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.da_methods.ensemble.LETKF" href="#dapper.da_methods.ensemble.LETKF">LETKF</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.da_methods.ensemble.LETKF.assimilate" href="#dapper.da_methods.ensemble.LETKF.assimilate">assimilate</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.LETKF.N" href="#dapper.da_methods.ensemble.LETKF.N">N</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.LETKF.loc_rad" href="#dapper.da_methods.ensemble.LETKF.loc_rad">loc_rad</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.LETKF.taper" href="#dapper.da_methods.ensemble.LETKF.taper">taper</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.LETKF.xN" href="#dapper.da_methods.ensemble.LETKF.xN">xN</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.LETKF.g" href="#dapper.da_methods.ensemble.LETKF.g">g</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.LETKF.mp" href="#dapper.da_methods.ensemble.LETKF.mp">mp</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.LETKF.infl" href="#dapper.da_methods.ensemble.LETKF.infl">infl</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.LETKF.rot" href="#dapper.da_methods.ensemble.LETKF.rot">rot</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.LETKF.fnoise_treatm" href="#dapper.da_methods.ensemble.LETKF.fnoise_treatm">fnoise_treatm</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.LETKF.da_method" href="#dapper.da_methods.ensemble.LETKF.da_method">da_method</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.da_methods.ensemble.EnKF_N" href="#dapper.da_methods.ensemble.EnKF_N">EnKF_N</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.da_methods.ensemble.EnKF_N.assimilate" href="#dapper.da_methods.ensemble.EnKF_N.assimilate">assimilate</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF_N.N" href="#dapper.da_methods.ensemble.EnKF_N.N">N</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF_N.dual" href="#dapper.da_methods.ensemble.EnKF_N.dual">dual</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF_N.Hess" href="#dapper.da_methods.ensemble.EnKF_N.Hess">Hess</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF_N.xN" href="#dapper.da_methods.ensemble.EnKF_N.xN">xN</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF_N.g" href="#dapper.da_methods.ensemble.EnKF_N.g">g</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF_N.infl" href="#dapper.da_methods.ensemble.EnKF_N.infl">infl</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF_N.rot" href="#dapper.da_methods.ensemble.EnKF_N.rot">rot</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF_N.fnoise_treatm" href="#dapper.da_methods.ensemble.EnKF_N.fnoise_treatm">fnoise_treatm</a></code></li>
<li><code><a title="dapper.da_methods.ensemble.EnKF_N.da_method" href="#dapper.da_methods.ensemble.EnKF_N.da_method">da_method</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>