<!-- Search file for "CHANGE" for my own changes -->
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>dapper.da_methods.variational API documentation</title>
<meta name="description" content="Variational DA methods (iEnKS, 4D-Var, etc)." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<link rel="preconnect" href="https://www.google.com">
<script async src="https://cse.google.com/cse.js?cx=017837193012385208679:pey8ky8gdqw"></script>
<style>
.gsc-control-cse {padding:0 !important;margin-top:1em}
body.gsc-overflow-hidden #sidebar {overflow: visible;}
</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo.png">
<!-- Dont work coz pdoc already defines these:
<title>DAPPER doc</title>
<meta name="description" content="Data Assimilation with Python: a Package for Experimental Research" />
-->
<a href="https://github.com/nansencenter/DAPPER" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dapper.da_methods.variational</code></h1>
</header>
<section id="section-intro">
<p>Variational DA methods (iEnKS, 4D-Var, etc).</p>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/variational.py#L0-L375" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;Variational DA methods (iEnKS, 4D-Var, etc).&#34;&#34;&#34;

from typing import Optional

import numpy as np
import scipy.linalg as sla

from dapper.da_methods.ensemble import hyperprior_coeffs, post_process, zeta_a
from dapper.stats import center, inflate_ens, mean0
from dapper.tools.linalg import pad0, svd0, tinv
from dapper.tools.matrices import CovMat
from dapper.tools.progressbar import progbar

from . import da_method


@da_method
class var_method:
    &#34;&#34;&#34;Declare default variational arguments.&#34;&#34;&#34;

    Lag: int    = 1
    nIter: int  = 10
    wtol: float = 0


@var_method
class iEnKS:
    &#34;&#34;&#34;Iterative EnKS.

    Special cases: EnRML, ES-MDA, iEnKF, EnKF `bib.raanes2019revising`.

    As in `bib.bocquet2014iterative`, optimization uses Gauss-Newton.
    See `bib.bocquet2012combining` for Levenberg-Marquardt.
    If MDA=True, then there&#39;s not really any optimization,
    but rather Gaussian annealing.

    Args:
      upd_a (str):
        Analysis update form (flavour). One of:

        - &#34;Sqrt&#34;   : as in ETKF  , using a deterministic matrix square root transform.
        - &#34;PertObs&#34;: as in EnRML , using stochastic, perturbed-observations.
        - &#34;Order1&#34; : as in DEnKF of `bib.sakov2008deterministic`.

      Lag:
        Length of the DA window (DAW), in multiples of dkObs (i.e. cycles).

        - Lag=1 (default) =&gt; iterative &#34;filter&#34; iEnKF `bib.sakov2012iterative`.
        - Lag=0           =&gt; maximum-likelihood filter `bib.zupanski2005maximum`.

      Shift : How far (in cycles) to slide the DAW.
              Fixed at 1 for code simplicity.

      nIter : Maximal num. of iterations used (&gt;=1).
              Supporting nIter==0 requires more code than it&#39;s worth.

      wtol  : Rel. tolerance defining convergence.
              Default: 0 =&gt; always do nIter iterations.
              Recommended: 1e-5.

      MDA   : Use iterations of the &#34;multiple data assimlation&#34; type.
              Ref `bib.emerick2012history`

      bundle: Use finite-diff. linearization instead of of least-squares regression.
              Makes the iEnKS very much alike the iterative, extended KF (IEKS).

      xN    : If set, use EnKF_N() pre-inflation. See further documentation there.

    Total number of model simulations (of duration dtObs): N * (nIter*Lag + 1).
    (due to boundary cases: only asymptotically valid)

    Refs: `bib.bocquet2012combining`, `bib.bocquet2013joint`,
    `bib.bocquet2014iterative`.
    &#34;&#34;&#34;

    upd_a: str
    N: int
    MDA: bool    = False
    step: bool   = False
    bundle: bool = False
    xN: float    = None
    infl: float  = 1.0
    rot: bool    = False

    # NB It&#39;s very difficult to preview what should happen to
    # all of the time indices in all cases of nIter and Lag.
    # =&gt; Any changes to this function must be unit-tested via
    # scripts/test_iEnKS.py.

    # TODO 6:
    # - step length
    # - Implement quasi-static assimilation. Boc notes:
    #   * The &#39;balancing step&#39; is complicated.
    #   * Trouble playing nice with &#39;-N&#39; inflation estimation.

    def assimilate(self, HMM, xx, yy):
        chrono, X0, stats = HMM.t, HMM.X0, self.stats
        R, KObs  = HMM.Obs.noise.C, HMM.t.KObs
        Rm12 = R.sym_sqrt_inv

        assert HMM.Dyn.noise.C == 0, (
            &#34;Q&gt;0 not yet supported.&#34;
            &#34; See Sakov et al 2017: &#39;An iEnKF with mod. error&#39;&#34;)

        if self.bundle:
            EPS = 1e-4  # Sakov/Boc use T=EPS*eye(N), with EPS=1e-4, but I ...
        else:
            EPS = 1.0  # ... prefer using  T=EPS*T, yielding a conditional cloud shape

        # Initial ensemble
        E = X0.sample(self.N)

        # Forward ensemble to kObs = 0 if Lag = 0
        t = 0
        k = 0
        if self.Lag == 0:
            for k, t, dt in chrono.cycle(kObs=0):
                stats.assess(k-1, None, &#39;u&#39;, E=E)
                E = HMM.Dyn(E, t-dt, dt)

        # Loop over DA windows (DAW).
        for kObs in progbar(range(0, KObs+self.Lag+1)):
            kLag = kObs-self.Lag
            DAW  = range(max(0, kLag+1), min(kObs, KObs) + 1)

            # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
            if kObs &lt;= KObs:
                E = iEnKS_update(self.upd_a, E, DAW, HMM, stats,
                                 EPS, yy[kObs], (k, kObs, t), Rm12,
                                 self.xN, self.MDA, (self.nIter, self.wtol))
                E = post_process(E, self.infl, self.rot)

            # Slide/shift DAW by propagating smoothed (&#39;s&#39;) ensemble from [kLag].
            if kLag &gt;= 0:
                stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, E=E)
            cycle_window = range(max(kLag+1, 0), min(max(kLag+1+1, 0), KObs+1))

            for kCycle in cycle_window:
                for k, t, dt in chrono.cycle(kCycle):
                    stats.assess(k-1, None, &#39;u&#39;, E=E)
                    E = HMM.Dyn(E, t-dt, dt)

        stats.assess(k, KObs, &#39;us&#39;, E=E)


def iEnKS_update(upd_a, E, DAW, HMM, stats, EPS, y, time, Rm12, xN, MDA, threshold):
    &#34;&#34;&#34;Perform the iEnKS update.

    This implementation includes several flavours and forms,
    specified by `upd_a` (See `iEnKS`)
    &#34;&#34;&#34;
    # distribute variable
    k, kObs, t = time
    nIter, wtol = threshold
    N, Nx = E.shape

    # Init iterations.
    N1 = N-1
    X0, x0 = center(E)    # Decompose ensemble.
    w      = np.zeros(N)  # Control vector for the mean state.
    T      = np.eye(N)    # Anomalies transform matrix.
    Tinv   = np.eye(N)
    # Explicit Tinv [instead of tinv(T)] allows for merging MDA code
    # with iEnKS/EnRML code, and flop savings in &#39;Sqrt&#39; case.

    for iteration in np.arange(nIter):
        # Reconstruct smoothed ensemble.
        E = x0 + (w + EPS*T)@X0
        # Forecast.
        for kCycle in DAW:
            for k, t, dt in HMM.t.cycle(kCycle):  # noqa
                E = HMM.Dyn(E, t-dt, dt)
        # Observe.
        Eo = HMM.Obs(E, t)

        # Undo the bundle scaling of ensemble.
        if EPS != 1.0:
            E  = inflate_ens(E, 1/EPS)
            Eo = inflate_ens(Eo, 1/EPS)

        # Assess forecast stats; store {Xf, T_old} for analysis assessment.
        if iteration == 0:
            stats.assess(k, kObs, &#39;f&#39;, E=E)
            Xf, xf = center(E)
        T_old = T

        # Prepare analysis.
        Y, xo  = center(Eo)         # Get obs {anomalies, mean}.
        dy     = (y - xo) @ Rm12.T  # Transform obs space.
        Y      = Y        @ Rm12.T  # Transform obs space.
        Y0     = Tinv @ Y           # &#34;De-condition&#34; the obs anomalies.
        V, s, UT = svd0(Y0)         # Decompose Y0.

        # Set &#34;cov normlzt fctr&#34; za (&#34;effective ensemble size&#34;)
        # =&gt; pre_infl^2 = (N-1)/za.
        if xN is None:
            za  = N1
        else:
            za  = zeta_a(*hyperprior_coeffs(s, N, xN), w)
        if MDA:
            # inflation (factor: nIter) of the ObsErrCov.
            za *= nIter

        # Post. cov (approx) of w,
        # estimated at current iteration, raised to power.
        def Cowp(expo): return (V * (pad0(s**2, N) + za)**-expo) @ V.T
        Cow1 = Cowp(1.0)

        if MDA:  # View update as annealing (progressive assimilation).
            Cow1 = Cow1 @ T  # apply previous update
            dw = dy @ Y.T @ Cow1
            if &#39;PertObs&#39; in upd_a:   # == &#34;ES-MDA&#34;. By Emerick/Reynolds
                D   = mean0(np.random.randn(*Y.shape)) * np.sqrt(nIter)
                T  -= (Y + D) @ Y.T @ Cow1
            elif &#39;Sqrt&#39; in upd_a:    # == &#34;ETKF-ish&#34;. By Raanes
                T   = Cowp(0.5) * np.sqrt(za) @ T
            elif &#39;Order1&#39; in upd_a:  # == &#34;DEnKF-ish&#34;. By Emerick
                T  -= 0.5 * Y @ Y.T @ Cow1
            # Tinv = eye(N) [as initialized] coz MDA does not de-condition.

        else:  # View update as Gauss-Newton optimzt. of log-posterior.
            grad  = Y0@dy - w*za                  # Cost function gradient
            dw    = grad@Cow1                     # Gauss-Newton step
            # ETKF-ish&#34;. By Bocquet/Sakov.
            if &#39;Sqrt&#39; in upd_a:
                # Sqrt-transforms
                T     = Cowp(0.5) * np.sqrt(N1)
                Tinv  = Cowp(-.5) / np.sqrt(N1)
                # Tinv saves time [vs tinv(T)] when Nx&lt;N
            # &#34;EnRML&#34;. By Oliver/Chen/Raanes/Evensen/Stordal.
            elif &#39;PertObs&#39; in upd_a:
                D     = mean0(np.random.randn(*Y.shape)) \
                    if iteration == 0 else D
                gradT = -(Y+D)@Y0.T + N1*(np.eye(N) - T)
                T     = T + gradT@Cow1
                # Tinv= tinv(T, threshold=N1)  # unstable
                Tinv  = sla.inv(T+1)           # the +1 is for stability.
            # &#34;DEnKF-ish&#34;. By Raanes.
            elif &#39;Order1&#39; in upd_a:
                # Included for completeness; does not make much sense.
                gradT = -0.5*Y@Y0.T + N1*(np.eye(N) - T)
                T     = T + gradT@Cow1
                Tinv  = tinv(T, threshold=N1)

        w += dw
        if dw@dw &lt; wtol*N:
            break

    # Assess (analysis) stats.
    # The final_increment is a linearization to
    # (i) avoid re-running the model and
    # (ii) reproduce EnKF in case nIter==1.
    final_increment = (dw+T-T_old)@Xf
    # See docs/snippets/iEnKS_Ea.jpg.
    stats.assess(k, kObs, &#39;a&#39;, E=E+final_increment)
    stats.iters[kObs] = iteration+1
    if xN:
        stats.infl[kObs] = np.sqrt(N1/za)

    # Final (smoothed) estimate of E at [kLag].
    E = x0 + (w+T)@X0

    return E


@var_method
class Var4D:
    &#34;&#34;&#34;4D-Var.

    Cycling scheme is same as in iEnKS (i.e. the shift is always 1*kObs).

    This implementation does NOT do gradient decent (nor quasi-Newton)
    in an inner loop, with simplified models.
    Instead, each (outer) iteration is computed
    non-iteratively as a Gauss-Newton step.
    Thus, since the full (approximate) Hessian is formed,
    there is no benefit to the adjoint trick (back-propagation).
    =&gt; This implementation is not suited for big systems.

    Incremental formulation is used, so the formulae look like the ones in iEnKS.
    &#34;&#34;&#34;

    B: Optional[np.ndarray] = None
    xB: float               = 1.0

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats
        R, KObs = HMM.Obs.noise.C, HMM.t.KObs
        Rm12 = R.sym_sqrt_inv
        Nx = Dyn.M

        # Set background covariance. Note that it is static (compare to iEnKS).
        if isinstance(self.B, np.ndarray):
            # compare ndarray 1st to avoid == error for ndarray
            B = self.B.astype(float)
        elif self.B in (None, &#39;clim&#39;):
            # Use climatological cov, estimated from truth
            B = np.cov(xx.T)
        elif self.B == &#39;eye&#39;:
            B = np.eye(Nx)
        else:
            raise ValueError(&#34;Bad input B.&#34;)
        B *= self.xB
        B12 = CovMat(B).sym_sqrt

        # Init
        x = X0.mu
        stats.assess(0, mu=x, Cov=B)

        # Loop over DA windows (DAW).
        for kObs in progbar(np.arange(-1, KObs+self.Lag+1)):
            kLag = kObs-self.Lag
            DAW = range(max(0, kLag+1), min(kObs, KObs) + 1)

            # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
            if 0 &lt;= kObs &lt;= KObs:

                # Init iterations.
                w   = np.zeros(Nx)  # Control vector for the mean state.
                x0  = x.copy()      # Increment reference.

                for iteration in np.arange(self.nIter):
                    # Reconstruct smoothed state.
                    x = x0 + B12@w
                    X = B12  # Aggregate composite TLMs onto B12
                    # Forecast.
                    for kCycle in DAW:
                        for k, t, dt in chrono.cycle(kCycle):  # noqa
                            X = Dyn.linear(x, t-dt, dt) @ X
                            x = Dyn(x, t-dt, dt)

                    # Assess forecast stats
                    if iteration == 0:
                        stats.assess(k, kObs, &#39;f&#39;, mu=x, Cov=X@X.T)

                    # Observe.
                    Y  = Obs.linear(x, t) @ X
                    xo = Obs(x, t)

                    # Analysis prep.
                    y      = yy[kObs]          # Get current obs.
                    dy     = Rm12 @ (y - xo)   # Transform obs space.
                    Y      = Rm12 @ Y          # Transform obs space.
                    V, s, UT = svd0(Y.T)       # Decomp for lin-alg update comps.

                    # Post. cov (approx) of w,
                    # estimated at current iteration, raised to power.
                    Cow1 = (V * (pad0(s**2, Nx) + 1)**-1.0) @ V.T

                    # Compute analysis update.
                    grad = Y.T@dy - w          # Cost function gradient
                    dw   = Cow1@grad           # Gauss-Newton step
                    w   += dw                  # Step

                    if dw@dw &lt; self.wtol*Nx:
                        break

                # Assess (analysis) stats.
                final_increment = X@dw
                stats.assess(k, kObs, &#39;a&#39;, mu=x+final_increment, Cov=X@Cow1@X.T)
                stats.iters[kObs] = iteration+1

                # Final (smoothed) estimate at [kLag].
                x = x0 + B12@w
                X = B12

            # Slide/shift DAW by propagating smoothed (&#39;s&#39;) state from [kLag].
            if -1 &lt;= kLag &lt; KObs:
                if kLag &gt;= 0:
                    stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, mu=x, Cov=X@Cow1@X.T)
                for k, t, dt in chrono.cycle(kLag+1):
                    stats.assess(k-1, None, &#39;u&#39;, mu=x, Cov=Y@Y.T)
                    X = Dyn.linear(x, t-dt, dt) @ X
                    x = Dyn(x, t-dt, dt)

        stats.assess(k, KObs, &#39;us&#39;, mu=x, Cov=X@Cow1@X.T)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dapper.da_methods.variational.iEnKS_update"><code class="name flex">
<span>def <span class="ident">iEnKS_update</span></span>(<span>upd_a, E, DAW, HMM, stats, EPS, y, time, Rm12, xN, MDA, threshold)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform the iEnKS update.</p>
<p>This implementation includes several flavours and forms,
specified by <code>upd_a</code> (See <code><a title="dapper.da_methods.variational.iEnKS" href="#dapper.da_methods.variational.iEnKS">iEnKS</a></code>)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/variational.py#L146-L263" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def iEnKS_update(upd_a, E, DAW, HMM, stats, EPS, y, time, Rm12, xN, MDA, threshold):
    &#34;&#34;&#34;Perform the iEnKS update.

    This implementation includes several flavours and forms,
    specified by `upd_a` (See `iEnKS`)
    &#34;&#34;&#34;
    # distribute variable
    k, kObs, t = time
    nIter, wtol = threshold
    N, Nx = E.shape

    # Init iterations.
    N1 = N-1
    X0, x0 = center(E)    # Decompose ensemble.
    w      = np.zeros(N)  # Control vector for the mean state.
    T      = np.eye(N)    # Anomalies transform matrix.
    Tinv   = np.eye(N)
    # Explicit Tinv [instead of tinv(T)] allows for merging MDA code
    # with iEnKS/EnRML code, and flop savings in &#39;Sqrt&#39; case.

    for iteration in np.arange(nIter):
        # Reconstruct smoothed ensemble.
        E = x0 + (w + EPS*T)@X0
        # Forecast.
        for kCycle in DAW:
            for k, t, dt in HMM.t.cycle(kCycle):  # noqa
                E = HMM.Dyn(E, t-dt, dt)
        # Observe.
        Eo = HMM.Obs(E, t)

        # Undo the bundle scaling of ensemble.
        if EPS != 1.0:
            E  = inflate_ens(E, 1/EPS)
            Eo = inflate_ens(Eo, 1/EPS)

        # Assess forecast stats; store {Xf, T_old} for analysis assessment.
        if iteration == 0:
            stats.assess(k, kObs, &#39;f&#39;, E=E)
            Xf, xf = center(E)
        T_old = T

        # Prepare analysis.
        Y, xo  = center(Eo)         # Get obs {anomalies, mean}.
        dy     = (y - xo) @ Rm12.T  # Transform obs space.
        Y      = Y        @ Rm12.T  # Transform obs space.
        Y0     = Tinv @ Y           # &#34;De-condition&#34; the obs anomalies.
        V, s, UT = svd0(Y0)         # Decompose Y0.

        # Set &#34;cov normlzt fctr&#34; za (&#34;effective ensemble size&#34;)
        # =&gt; pre_infl^2 = (N-1)/za.
        if xN is None:
            za  = N1
        else:
            za  = zeta_a(*hyperprior_coeffs(s, N, xN), w)
        if MDA:
            # inflation (factor: nIter) of the ObsErrCov.
            za *= nIter

        # Post. cov (approx) of w,
        # estimated at current iteration, raised to power.
        def Cowp(expo): return (V * (pad0(s**2, N) + za)**-expo) @ V.T
        Cow1 = Cowp(1.0)

        if MDA:  # View update as annealing (progressive assimilation).
            Cow1 = Cow1 @ T  # apply previous update
            dw = dy @ Y.T @ Cow1
            if &#39;PertObs&#39; in upd_a:   # == &#34;ES-MDA&#34;. By Emerick/Reynolds
                D   = mean0(np.random.randn(*Y.shape)) * np.sqrt(nIter)
                T  -= (Y + D) @ Y.T @ Cow1
            elif &#39;Sqrt&#39; in upd_a:    # == &#34;ETKF-ish&#34;. By Raanes
                T   = Cowp(0.5) * np.sqrt(za) @ T
            elif &#39;Order1&#39; in upd_a:  # == &#34;DEnKF-ish&#34;. By Emerick
                T  -= 0.5 * Y @ Y.T @ Cow1
            # Tinv = eye(N) [as initialized] coz MDA does not de-condition.

        else:  # View update as Gauss-Newton optimzt. of log-posterior.
            grad  = Y0@dy - w*za                  # Cost function gradient
            dw    = grad@Cow1                     # Gauss-Newton step
            # ETKF-ish&#34;. By Bocquet/Sakov.
            if &#39;Sqrt&#39; in upd_a:
                # Sqrt-transforms
                T     = Cowp(0.5) * np.sqrt(N1)
                Tinv  = Cowp(-.5) / np.sqrt(N1)
                # Tinv saves time [vs tinv(T)] when Nx&lt;N
            # &#34;EnRML&#34;. By Oliver/Chen/Raanes/Evensen/Stordal.
            elif &#39;PertObs&#39; in upd_a:
                D     = mean0(np.random.randn(*Y.shape)) \
                    if iteration == 0 else D
                gradT = -(Y+D)@Y0.T + N1*(np.eye(N) - T)
                T     = T + gradT@Cow1
                # Tinv= tinv(T, threshold=N1)  # unstable
                Tinv  = sla.inv(T+1)           # the +1 is for stability.
            # &#34;DEnKF-ish&#34;. By Raanes.
            elif &#39;Order1&#39; in upd_a:
                # Included for completeness; does not make much sense.
                gradT = -0.5*Y@Y0.T + N1*(np.eye(N) - T)
                T     = T + gradT@Cow1
                Tinv  = tinv(T, threshold=N1)

        w += dw
        if dw@dw &lt; wtol*N:
            break

    # Assess (analysis) stats.
    # The final_increment is a linearization to
    # (i) avoid re-running the model and
    # (ii) reproduce EnKF in case nIter==1.
    final_increment = (dw+T-T_old)@Xf
    # See docs/snippets/iEnKS_Ea.jpg.
    stats.assess(k, kObs, &#39;a&#39;, E=E+final_increment)
    stats.iters[kObs] = iteration+1
    if xN:
        stats.infl[kObs] = np.sqrt(N1/za)

    # Final (smoothed) estimate of E at [kLag].
    E = x0 + (w+T)@X0

    return E</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dapper.da_methods.variational.iEnKS"><code class="flex name class">
<span>class <span class="ident">iEnKS</span></span>
<span>(</span><span>upd_a: str, N: int, MDA: bool = False, step: bool = False, bundle: bool = False, xN: float = None, infl: float = 1.0, rot: bool = False, Lag: int = 1, nIter: int = 10, wtol: float = 0)</span>
</code></dt>
<dd>
<div class="desc"><p>Iterative EnKS.</p>
<p>Special cases: EnRML, ES-MDA, iEnKF, EnKF <code><a title="bib.raanes2019revising" href="../../bib.html#bib.raanes2019revising">raanes2019revising</a></code>.</p>
<p>As in <code><a title="bib.bocquet2014iterative" href="../../bib.html#bib.bocquet2014iterative">bocquet2014iterative</a></code>, optimization uses Gauss-Newton.
See <code><a title="bib.bocquet2012combining" href="../../bib.html#bib.bocquet2012combining">bocquet2012combining</a></code> for Levenberg-Marquardt.
If MDA=True, then there's not really any optimization,
but rather Gaussian annealing.</p>
<h2 id="args">Args</h2>
<p>upd_a (str):
Analysis update form (flavour). One of:</p>
<ul>
<li>"Sqrt"
: as in ETKF
, using a deterministic matrix square root transform.</li>
<li>"PertObs": as in EnRML , using stochastic, perturbed-observations.</li>
<li>"Order1" : as in DEnKF of <code><a title="bib.sakov2008deterministic" href="../../bib.html#bib.sakov2008deterministic">sakov2008deterministic</a></code>.</li>
</ul>
<p>Lag:
Length of the DA window (DAW), in multiples of dkObs (i.e. cycles).</p>
<ul>
<li>Lag=1 (default) =&gt; iterative "filter" iEnKF <code><a title="bib.sakov2012iterative" href="../../bib.html#bib.sakov2012iterative">sakov2012iterative</a></code>.</li>
<li>Lag=0
=&gt; maximum-likelihood filter <code><a title="bib.zupanski2005maximum" href="../../bib.html#bib.zupanski2005maximum">zupanski2005maximum</a></code>.</li>
</ul>
<p>Shift : How far (in cycles) to slide the DAW.
Fixed at 1 for code simplicity.</p>
<p>nIter : Maximal num. of iterations used (&gt;=1).
Supporting nIter==0 requires more code than it's worth.</p>
<p>wtol
: Rel. tolerance defining convergence.
Default: 0 =&gt; always do nIter iterations.
Recommended: 1e-5.</p>
<p>MDA
: Use iterations of the "multiple data assimlation" type.
Ref <code><a title="bib.emerick2012history" href="../../bib.html#bib.emerick2012history">emerick2012history</a></code></p>
<dl>
<dt><strong><code>bundle</code></strong></dt>
<dd>Use finite-diff. linearization instead of of least-squares regression.
Makes the iEnKS very much alike the iterative, extended KF (IEKS).</dd>
</dl>
<p>xN
: If set, use EnKF_N() pre-inflation. See further documentation there.
Total number of model simulations (of duration dtObs): N * (nIter*Lag + 1).
(due to boundary cases: only asymptotically valid)</p>
<p>Refs: <code><a title="bib.bocquet2012combining" href="../../bib.html#bib.bocquet2012combining">bocquet2012combining</a></code>, <code><a title="bib.bocquet2013joint" href="../../bib.html#bib.bocquet2013joint">bocquet2013joint</a></code>,
<code><a title="bib.bocquet2014iterative" href="../../bib.html#bib.bocquet2014iterative">bocquet2014iterative</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/variational.py#L27-L143" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class iEnKS:
    &#34;&#34;&#34;Iterative EnKS.

    Special cases: EnRML, ES-MDA, iEnKF, EnKF `bib.raanes2019revising`.

    As in `bib.bocquet2014iterative`, optimization uses Gauss-Newton.
    See `bib.bocquet2012combining` for Levenberg-Marquardt.
    If MDA=True, then there&#39;s not really any optimization,
    but rather Gaussian annealing.

    Args:
      upd_a (str):
        Analysis update form (flavour). One of:

        - &#34;Sqrt&#34;   : as in ETKF  , using a deterministic matrix square root transform.
        - &#34;PertObs&#34;: as in EnRML , using stochastic, perturbed-observations.
        - &#34;Order1&#34; : as in DEnKF of `bib.sakov2008deterministic`.

      Lag:
        Length of the DA window (DAW), in multiples of dkObs (i.e. cycles).

        - Lag=1 (default) =&gt; iterative &#34;filter&#34; iEnKF `bib.sakov2012iterative`.
        - Lag=0           =&gt; maximum-likelihood filter `bib.zupanski2005maximum`.

      Shift : How far (in cycles) to slide the DAW.
              Fixed at 1 for code simplicity.

      nIter : Maximal num. of iterations used (&gt;=1).
              Supporting nIter==0 requires more code than it&#39;s worth.

      wtol  : Rel. tolerance defining convergence.
              Default: 0 =&gt; always do nIter iterations.
              Recommended: 1e-5.

      MDA   : Use iterations of the &#34;multiple data assimlation&#34; type.
              Ref `bib.emerick2012history`

      bundle: Use finite-diff. linearization instead of of least-squares regression.
              Makes the iEnKS very much alike the iterative, extended KF (IEKS).

      xN    : If set, use EnKF_N() pre-inflation. See further documentation there.

    Total number of model simulations (of duration dtObs): N * (nIter*Lag + 1).
    (due to boundary cases: only asymptotically valid)

    Refs: `bib.bocquet2012combining`, `bib.bocquet2013joint`,
    `bib.bocquet2014iterative`.
    &#34;&#34;&#34;

    upd_a: str
    N: int
    MDA: bool    = False
    step: bool   = False
    bundle: bool = False
    xN: float    = None
    infl: float  = 1.0
    rot: bool    = False

    # NB It&#39;s very difficult to preview what should happen to
    # all of the time indices in all cases of nIter and Lag.
    # =&gt; Any changes to this function must be unit-tested via
    # scripts/test_iEnKS.py.

    # TODO 6:
    # - step length
    # - Implement quasi-static assimilation. Boc notes:
    #   * The &#39;balancing step&#39; is complicated.
    #   * Trouble playing nice with &#39;-N&#39; inflation estimation.

    def assimilate(self, HMM, xx, yy):
        chrono, X0, stats = HMM.t, HMM.X0, self.stats
        R, KObs  = HMM.Obs.noise.C, HMM.t.KObs
        Rm12 = R.sym_sqrt_inv

        assert HMM.Dyn.noise.C == 0, (
            &#34;Q&gt;0 not yet supported.&#34;
            &#34; See Sakov et al 2017: &#39;An iEnKF with mod. error&#39;&#34;)

        if self.bundle:
            EPS = 1e-4  # Sakov/Boc use T=EPS*eye(N), with EPS=1e-4, but I ...
        else:
            EPS = 1.0  # ... prefer using  T=EPS*T, yielding a conditional cloud shape

        # Initial ensemble
        E = X0.sample(self.N)

        # Forward ensemble to kObs = 0 if Lag = 0
        t = 0
        k = 0
        if self.Lag == 0:
            for k, t, dt in chrono.cycle(kObs=0):
                stats.assess(k-1, None, &#39;u&#39;, E=E)
                E = HMM.Dyn(E, t-dt, dt)

        # Loop over DA windows (DAW).
        for kObs in progbar(range(0, KObs+self.Lag+1)):
            kLag = kObs-self.Lag
            DAW  = range(max(0, kLag+1), min(kObs, KObs) + 1)

            # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
            if kObs &lt;= KObs:
                E = iEnKS_update(self.upd_a, E, DAW, HMM, stats,
                                 EPS, yy[kObs], (k, kObs, t), Rm12,
                                 self.xN, self.MDA, (self.nIter, self.wtol))
                E = post_process(E, self.infl, self.rot)

            # Slide/shift DAW by propagating smoothed (&#39;s&#39;) ensemble from [kLag].
            if kLag &gt;= 0:
                stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, E=E)
            cycle_window = range(max(kLag+1, 0), min(max(kLag+1+1, 0), KObs+1))

            for kCycle in cycle_window:
                for k, t, dt in chrono.cycle(kCycle):
                    stats.assess(k-1, None, &#39;u&#39;, E=E)
                    E = HMM.Dyn(E, t-dt, dt)

        stats.assess(k, KObs, &#39;us&#39;, E=E)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dapper.da_methods.variational.iEnKS.upd_a"><code class="name">var <span class="ident">upd_a</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.N"><code class="name">var <span class="ident">N</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.MDA"><code class="name">var <span class="ident">MDA</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.step"><code class="name">var <span class="ident">step</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.bundle"><code class="name">var <span class="ident">bundle</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.xN"><code class="name">var <span class="ident">xN</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.infl"><code class="name">var <span class="ident">infl</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.rot"><code class="name">var <span class="ident">rot</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.Lag"><code class="name">var <span class="ident">Lag</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.nIter"><code class="name">var <span class="ident">nIter</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.wtol"><code class="name">var <span class="ident">wtol</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.da_method"><code class="name">var <span class="ident">da_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.da_methods.variational.iEnKS.assimilate"><code class="name flex">
<span>def <span class="ident">assimilate</span></span>(<span>self, HMM, xx, yy)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/variational.py#L96-L143" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def assimilate(self, HMM, xx, yy):
    chrono, X0, stats = HMM.t, HMM.X0, self.stats
    R, KObs  = HMM.Obs.noise.C, HMM.t.KObs
    Rm12 = R.sym_sqrt_inv

    assert HMM.Dyn.noise.C == 0, (
        &#34;Q&gt;0 not yet supported.&#34;
        &#34; See Sakov et al 2017: &#39;An iEnKF with mod. error&#39;&#34;)

    if self.bundle:
        EPS = 1e-4  # Sakov/Boc use T=EPS*eye(N), with EPS=1e-4, but I ...
    else:
        EPS = 1.0  # ... prefer using  T=EPS*T, yielding a conditional cloud shape

    # Initial ensemble
    E = X0.sample(self.N)

    # Forward ensemble to kObs = 0 if Lag = 0
    t = 0
    k = 0
    if self.Lag == 0:
        for k, t, dt in chrono.cycle(kObs=0):
            stats.assess(k-1, None, &#39;u&#39;, E=E)
            E = HMM.Dyn(E, t-dt, dt)

    # Loop over DA windows (DAW).
    for kObs in progbar(range(0, KObs+self.Lag+1)):
        kLag = kObs-self.Lag
        DAW  = range(max(0, kLag+1), min(kObs, KObs) + 1)

        # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
        if kObs &lt;= KObs:
            E = iEnKS_update(self.upd_a, E, DAW, HMM, stats,
                             EPS, yy[kObs], (k, kObs, t), Rm12,
                             self.xN, self.MDA, (self.nIter, self.wtol))
            E = post_process(E, self.infl, self.rot)

        # Slide/shift DAW by propagating smoothed (&#39;s&#39;) ensemble from [kLag].
        if kLag &gt;= 0:
            stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, E=E)
        cycle_window = range(max(kLag+1, 0), min(max(kLag+1+1, 0), KObs+1))

        for kCycle in cycle_window:
            for k, t, dt in chrono.cycle(kCycle):
                stats.assess(k-1, None, &#39;u&#39;, E=E)
                E = HMM.Dyn(E, t-dt, dt)

    stats.assess(k, KObs, &#39;us&#39;, E=E)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dapper.da_methods.variational.Var4D"><code class="flex name class">
<span>class <span class="ident">Var4D</span></span>
<span>(</span><span>B: Union[numpy.ndarray, NoneType] = None, xB: float = 1.0, Lag: int = 1, nIter: int = 10, wtol: float = 0)</span>
</code></dt>
<dd>
<div class="desc"><p>4D-Var.</p>
<p>Cycling scheme is same as in iEnKS (i.e. the shift is always 1*kObs).</p>
<p>This implementation does NOT do gradient decent (nor quasi-Newton)
in an inner loop, with simplified models.
Instead, each (outer) iteration is computed
non-iteratively as a Gauss-Newton step.
Thus, since the full (approximate) Hessian is formed,
there is no benefit to the adjoint trick (back-propagation).
=&gt; This implementation is not suited for big systems.</p>
<p>Incremental formulation is used, so the formulae look like the ones in iEnKS.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/variational.py#L267-L376" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Var4D:
    &#34;&#34;&#34;4D-Var.

    Cycling scheme is same as in iEnKS (i.e. the shift is always 1*kObs).

    This implementation does NOT do gradient decent (nor quasi-Newton)
    in an inner loop, with simplified models.
    Instead, each (outer) iteration is computed
    non-iteratively as a Gauss-Newton step.
    Thus, since the full (approximate) Hessian is formed,
    there is no benefit to the adjoint trick (back-propagation).
    =&gt; This implementation is not suited for big systems.

    Incremental formulation is used, so the formulae look like the ones in iEnKS.
    &#34;&#34;&#34;

    B: Optional[np.ndarray] = None
    xB: float               = 1.0

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats
        R, KObs = HMM.Obs.noise.C, HMM.t.KObs
        Rm12 = R.sym_sqrt_inv
        Nx = Dyn.M

        # Set background covariance. Note that it is static (compare to iEnKS).
        if isinstance(self.B, np.ndarray):
            # compare ndarray 1st to avoid == error for ndarray
            B = self.B.astype(float)
        elif self.B in (None, &#39;clim&#39;):
            # Use climatological cov, estimated from truth
            B = np.cov(xx.T)
        elif self.B == &#39;eye&#39;:
            B = np.eye(Nx)
        else:
            raise ValueError(&#34;Bad input B.&#34;)
        B *= self.xB
        B12 = CovMat(B).sym_sqrt

        # Init
        x = X0.mu
        stats.assess(0, mu=x, Cov=B)

        # Loop over DA windows (DAW).
        for kObs in progbar(np.arange(-1, KObs+self.Lag+1)):
            kLag = kObs-self.Lag
            DAW = range(max(0, kLag+1), min(kObs, KObs) + 1)

            # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
            if 0 &lt;= kObs &lt;= KObs:

                # Init iterations.
                w   = np.zeros(Nx)  # Control vector for the mean state.
                x0  = x.copy()      # Increment reference.

                for iteration in np.arange(self.nIter):
                    # Reconstruct smoothed state.
                    x = x0 + B12@w
                    X = B12  # Aggregate composite TLMs onto B12
                    # Forecast.
                    for kCycle in DAW:
                        for k, t, dt in chrono.cycle(kCycle):  # noqa
                            X = Dyn.linear(x, t-dt, dt) @ X
                            x = Dyn(x, t-dt, dt)

                    # Assess forecast stats
                    if iteration == 0:
                        stats.assess(k, kObs, &#39;f&#39;, mu=x, Cov=X@X.T)

                    # Observe.
                    Y  = Obs.linear(x, t) @ X
                    xo = Obs(x, t)

                    # Analysis prep.
                    y      = yy[kObs]          # Get current obs.
                    dy     = Rm12 @ (y - xo)   # Transform obs space.
                    Y      = Rm12 @ Y          # Transform obs space.
                    V, s, UT = svd0(Y.T)       # Decomp for lin-alg update comps.

                    # Post. cov (approx) of w,
                    # estimated at current iteration, raised to power.
                    Cow1 = (V * (pad0(s**2, Nx) + 1)**-1.0) @ V.T

                    # Compute analysis update.
                    grad = Y.T@dy - w          # Cost function gradient
                    dw   = Cow1@grad           # Gauss-Newton step
                    w   += dw                  # Step

                    if dw@dw &lt; self.wtol*Nx:
                        break

                # Assess (analysis) stats.
                final_increment = X@dw
                stats.assess(k, kObs, &#39;a&#39;, mu=x+final_increment, Cov=X@Cow1@X.T)
                stats.iters[kObs] = iteration+1

                # Final (smoothed) estimate at [kLag].
                x = x0 + B12@w
                X = B12

            # Slide/shift DAW by propagating smoothed (&#39;s&#39;) state from [kLag].
            if -1 &lt;= kLag &lt; KObs:
                if kLag &gt;= 0:
                    stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, mu=x, Cov=X@Cow1@X.T)
                for k, t, dt in chrono.cycle(kLag+1):
                    stats.assess(k-1, None, &#39;u&#39;, mu=x, Cov=Y@Y.T)
                    X = Dyn.linear(x, t-dt, dt) @ X
                    x = Dyn(x, t-dt, dt)

        stats.assess(k, KObs, &#39;us&#39;, mu=x, Cov=X@Cow1@X.T)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dapper.da_methods.variational.Var4D.B"><code class="name">var <span class="ident">B</span> : Union[numpy.ndarray, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.Var4D.xB"><code class="name">var <span class="ident">xB</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.Var4D.Lag"><code class="name">var <span class="ident">Lag</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.Var4D.nIter"><code class="name">var <span class="ident">nIter</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.Var4D.wtol"><code class="name">var <span class="ident">wtol</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.Var4D.da_method"><code class="name">var <span class="ident">da_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.da_methods.variational.Var4D.assimilate"><code class="name flex">
<span>def <span class="ident">assimilate</span></span>(<span>self, HMM, xx, yy)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/da_methods/variational.py#L286-L376" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def assimilate(self, HMM, xx, yy):
    Dyn, Obs, chrono, X0, stats = HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats
    R, KObs = HMM.Obs.noise.C, HMM.t.KObs
    Rm12 = R.sym_sqrt_inv
    Nx = Dyn.M

    # Set background covariance. Note that it is static (compare to iEnKS).
    if isinstance(self.B, np.ndarray):
        # compare ndarray 1st to avoid == error for ndarray
        B = self.B.astype(float)
    elif self.B in (None, &#39;clim&#39;):
        # Use climatological cov, estimated from truth
        B = np.cov(xx.T)
    elif self.B == &#39;eye&#39;:
        B = np.eye(Nx)
    else:
        raise ValueError(&#34;Bad input B.&#34;)
    B *= self.xB
    B12 = CovMat(B).sym_sqrt

    # Init
    x = X0.mu
    stats.assess(0, mu=x, Cov=B)

    # Loop over DA windows (DAW).
    for kObs in progbar(np.arange(-1, KObs+self.Lag+1)):
        kLag = kObs-self.Lag
        DAW = range(max(0, kLag+1), min(kObs, KObs) + 1)

        # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
        if 0 &lt;= kObs &lt;= KObs:

            # Init iterations.
            w   = np.zeros(Nx)  # Control vector for the mean state.
            x0  = x.copy()      # Increment reference.

            for iteration in np.arange(self.nIter):
                # Reconstruct smoothed state.
                x = x0 + B12@w
                X = B12  # Aggregate composite TLMs onto B12
                # Forecast.
                for kCycle in DAW:
                    for k, t, dt in chrono.cycle(kCycle):  # noqa
                        X = Dyn.linear(x, t-dt, dt) @ X
                        x = Dyn(x, t-dt, dt)

                # Assess forecast stats
                if iteration == 0:
                    stats.assess(k, kObs, &#39;f&#39;, mu=x, Cov=X@X.T)

                # Observe.
                Y  = Obs.linear(x, t) @ X
                xo = Obs(x, t)

                # Analysis prep.
                y      = yy[kObs]          # Get current obs.
                dy     = Rm12 @ (y - xo)   # Transform obs space.
                Y      = Rm12 @ Y          # Transform obs space.
                V, s, UT = svd0(Y.T)       # Decomp for lin-alg update comps.

                # Post. cov (approx) of w,
                # estimated at current iteration, raised to power.
                Cow1 = (V * (pad0(s**2, Nx) + 1)**-1.0) @ V.T

                # Compute analysis update.
                grad = Y.T@dy - w          # Cost function gradient
                dw   = Cow1@grad           # Gauss-Newton step
                w   += dw                  # Step

                if dw@dw &lt; self.wtol*Nx:
                    break

            # Assess (analysis) stats.
            final_increment = X@dw
            stats.assess(k, kObs, &#39;a&#39;, mu=x+final_increment, Cov=X@Cow1@X.T)
            stats.iters[kObs] = iteration+1

            # Final (smoothed) estimate at [kLag].
            x = x0 + B12@w
            X = B12

        # Slide/shift DAW by propagating smoothed (&#39;s&#39;) state from [kLag].
        if -1 &lt;= kLag &lt; KObs:
            if kLag &gt;= 0:
                stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, mu=x, Cov=X@Cow1@X.T)
            for k, t, dt in chrono.cycle(kLag+1):
                stats.assess(k-1, None, &#39;u&#39;, mu=x, Cov=Y@Y.T)
                X = Dyn.linear(x, t-dt, dt) @ X
                x = Dyn(x, t-dt, dt)

    stats.assess(k, KObs, &#39;us&#39;, mu=x, Cov=X@Cow1@X.T)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="DAPPER" href="https://nansencenter.github.io/DAPPER">
<img src="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo_wtxt.png" alt="">
<!-- can add style="width:200px;" to img -->
</a>
</header>
<div class="gcse-search" style="height: 70px"
data-as_oq="inurl:github.com/nansencenter/DAPPER site:nansencenter.github.io/DAPPER"
data-gaCategoryParameter="dapper.da_methods.variational">
</div>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dapper.da_methods" href="index.html">dapper.da_methods</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dapper.da_methods.variational.iEnKS_update" href="#dapper.da_methods.variational.iEnKS_update">iEnKS_update</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dapper.da_methods.variational.iEnKS" href="#dapper.da_methods.variational.iEnKS">iEnKS</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.da_methods.variational.iEnKS.assimilate" href="#dapper.da_methods.variational.iEnKS.assimilate">assimilate</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.upd_a" href="#dapper.da_methods.variational.iEnKS.upd_a">upd_a</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.N" href="#dapper.da_methods.variational.iEnKS.N">N</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.MDA" href="#dapper.da_methods.variational.iEnKS.MDA">MDA</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.step" href="#dapper.da_methods.variational.iEnKS.step">step</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.bundle" href="#dapper.da_methods.variational.iEnKS.bundle">bundle</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.xN" href="#dapper.da_methods.variational.iEnKS.xN">xN</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.infl" href="#dapper.da_methods.variational.iEnKS.infl">infl</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.rot" href="#dapper.da_methods.variational.iEnKS.rot">rot</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.Lag" href="#dapper.da_methods.variational.iEnKS.Lag">Lag</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.nIter" href="#dapper.da_methods.variational.iEnKS.nIter">nIter</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.wtol" href="#dapper.da_methods.variational.iEnKS.wtol">wtol</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.da_method" href="#dapper.da_methods.variational.iEnKS.da_method">da_method</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.da_methods.variational.Var4D" href="#dapper.da_methods.variational.Var4D">Var4D</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.da_methods.variational.Var4D.assimilate" href="#dapper.da_methods.variational.Var4D.assimilate">assimilate</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.B" href="#dapper.da_methods.variational.Var4D.B">B</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.xB" href="#dapper.da_methods.variational.Var4D.xB">xB</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.Lag" href="#dapper.da_methods.variational.Var4D.Lag">Lag</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.nIter" href="#dapper.da_methods.variational.Var4D.nIter">nIter</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.wtol" href="#dapper.da_methods.variational.Var4D.wtol">wtol</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.da_method" href="#dapper.da_methods.variational.Var4D.da_method">da_method</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>