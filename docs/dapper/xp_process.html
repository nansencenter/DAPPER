<!-- Search file for "CHANGE" for my own changes -->
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>dapper.xp_process API documentation</title>
<meta name="description" content="Tools (notably `xpSpace`) for processing and presenting experiment data." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<link rel="preconnect" href="https://www.google.com">
<script async src="https://cse.google.com/cse.js?cx=017837193012385208679:pey8ky8gdqw"></script>
<style>
.gsc-control-cse {padding:0 !important;margin-top:1em}
body.gsc-overflow-hidden #sidebar {overflow: visible;}
</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo.png">
<!-- Dont work coz pdoc already defines these:
<title>DAPPER doc</title>
<meta name="description" content="Data Assimilation with Python: a Package for Experimental Research" />
-->
<a href="https://github.com/nansencenter/DAPPER" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dapper.xp_process</code></h1>
</header>
<section id="section-intro">
<p>Tools (notably <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code>) for processing and presenting experiment data.</p>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L0-L1052" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;Tools (notably `xpSpace`) for processing and presenting experiment data.&#34;&#34;&#34;

import collections
import copy
import logging
import os
import shutil
import warnings
from pathlib import Path

import colorama
import dill
import matplotlib as mpl
import numpy as np
import struct_tools
from matplotlib import cm, ticker
from patlib.std import set_tmp
from tabulate import tabulate
from tqdm import tqdm

import dapper.tools.remote.uplink as uplink
from dapper.stats import align_col, unpack_uqs
from dapper.tools.colors import color_text
from dapper.tools.rounding import UncertainQtty
from dapper.tools.viz import axis_scale_by_array, freshfig
from dapper.xp_launch import collapse_str, xpList

mpl_logger = logging.getLogger(&#39;matplotlib&#39;)

NO_KEY = (&#34;da_method&#34;, &#34;Const&#34;, &#34;upd_a&#34;)


def make_label(coord, no_key=NO_KEY, exclude=()):
    dct = {a: v for a, v in coord._asdict().items() if v != None}
    lbl = &#39;&#39;
    for k, v in dct.items():
        if k not in exclude:
            if any(x in k for x in no_key):
                lbl = lbl + f&#39; {v}&#39;
            else:
                lbl = lbl + f&#39; {collapse_str(k,7)}:{v}&#39;
    return lbl[1:]


def default_styles(coord, baseline_legends=False):
    &#34;&#34;&#34;Quick and dirty (but somewhat robust) styling.&#34;&#34;&#34;
    style = struct_tools.DotDict(ms=8)
    style.label = make_label(coord)

    try:
        if coord.da_method == &#34;Climatology&#34;:
            style.ls = &#34;:&#34;
            style.c = &#34;k&#34;
            if not baseline_legends:
                style.label = None

        elif coord.da_method == &#34;OptInterp&#34;:
            style.ls = &#34;:&#34;
            style.c = .7*np.ones(3)
            style.label = &#34;Opt. Interp.&#34;
            if not baseline_legends:
                style.label = None

        elif coord.da_method == &#34;Var3D&#34;:
            style.ls = &#34;:&#34;
            style.c = .5*np.ones(3)
            style.label = &#34;3D-Var&#34;
            if not baseline_legends:
                style.label = None

        elif coord.da_method == &#34;EnKF&#34;:
            style.marker = &#34;*&#34;
            style.c = &#34;C1&#34;

        elif coord.da_method == &#34;PartFilt&#34;:
            style.marker = &#34;X&#34;
            style.c = &#34;C2&#34;

        else:
            style.marker = &#34;.&#34;

    except AttributeError:
        pass

    return style


def rel_index(elem, lst, default=None):
    &#34;&#34;&#34;`lst.index(elem) / len(lst)` with fallback.&#34;&#34;&#34;
    try:
        return lst.index(elem) / len(lst)
    except ValueError:
        if default == None:
            raise
        return default


def discretize_cmap(cmap, N, val0=0, val1=1, name=None):
    &#34;&#34;&#34;Discretize `cmap` so that it partitions `[0, 1]` into `N` segments.

    I.e. `cmap(k/N) == cmap(k/N + eps)`.

    Also provide the ScalarMappable `sm`
    that maps range(N) to the segment centers,
    as will be reflected by `cb = fig.colorbar(sm)`.
    You can then re-label the ticks using
    `cb.set_ticks(np.arange(N)); cb.set_ticklabels([&#34;A&#34;,&#34;B&#34;,&#34;C&#34;,...])`.
    &#34;&#34;&#34;
    # cmap(k/N)
    from_list = mpl.colors.LinearSegmentedColormap.from_list
    colors = cmap(np.linspace(val0, val1, N))
    cmap = from_list(name, colors, N)
    # sm
    cNorm = mpl.colors.Normalize(-.5, -.5+N)
    sm = mpl.cm.ScalarMappable(cNorm, cmap)
    return cmap, sm


def cm_bond(cmap, xp_dict, axis, vmin=0, vmax=0):
    &#34;&#34;&#34;Map cmap for `coord.axis ∈ [0, len(ticks)]`.&#34;&#34;&#34;
    def link(coord):
        &#34;&#34;&#34;Essentially: `cmap(ticks.index(coord.axis))`&#34;&#34;&#34;
        if hasattr(coord, axis):
            ticks = xp_dict.ticks[axis]
            cNorm = mpl.colors.Normalize(vmin, vmax + len(ticks))
            ScMap = cm.ScalarMappable(cNorm, cmap).to_rgba
            index = ticks.index(getattr(coord, axis))
            return ScMap(index)
        else:
            return cmap(0.5)
    return link


def in_idx(coord, indices, xp_dict, axis):
    &#34;&#34;&#34;Essentially: `coord.axis in ticks[indices]`.&#34;&#34;&#34;
    if hasattr(coord, axis):
        ticks = np.array(xp_dict.ticks[axis])[indices]
        return getattr(coord, axis) in ticks
    else:
        return True


def load_HMM(save_as):
    save_as = Path(save_as).expanduser()
    HMM = dill.load(open(save_as/&#34;xp.com&#34;, &#34;rb&#34;))[&#34;HMM&#34;]
    return HMM


def load_xps(save_as):
    &#34;&#34;&#34;Load `xps` (as a simple list) from dir.&#34;&#34;&#34;
    save_as = Path(save_as).expanduser()
    files = [d/&#34;xp&#34; for d in uplink.list_job_dirs(save_as)]

    def load_any(filepath):
        &#34;&#34;&#34;Load any/all `xp&#39;s` from `filepath`.&#34;&#34;&#34;
        with open(filepath, &#34;rb&#34;) as F:
            # If experiment crashed, then xp will be empty
            try:
                data = dill.load(F)
            except EOFError:
                return []
            # Always return list
            try:
                return data[&#34;xps&#34;]
            except KeyError:
                return [data[&#34;xp&#34;]]

    print(&#34;Loading %d files from %s&#34; % (len(files), save_as))
    xps = []  # NB: progbar wont clean up properly w/ list compr.
    for f in tqdm(files, desc=&#34;Loading&#34;):
        xps.extend(load_any(f))

    if len(xps) &lt; len(files):
        print(f&#34;{len(files)-len(xps)} files could not be loaded.&#34;)

    return xps


def save_xps(xps, save_as, nDir=100):
    &#34;&#34;&#34;Split xps and save in save_as/i for i in range(nDir).

    Example
    -------
    Rename attr n_iter to nIter:
    &gt;&gt;&gt; proj_name = &#34;Stein&#34;
    &gt;&gt;&gt; dd = rc.dirs.data / proj_name
    &gt;&gt;&gt; save_as = dd / &#34;run_2020-09-22__19:36:13&#34;

    &gt;&gt;&gt; for save_as in dd.iterdir():  # doctest: +SKIP
    ...     save_as = dd / save_as
    ...
    ...     xps = load_xps(save_as)
    ...     HMM = load_HMM(save_as)
    ...
    ...     for xp in xps:
    ...         if hasattr(xp,&#34;n_iter&#34;):
    ...             xp.nIter = xp.n_iter
    ...             del xp.n_iter
    ...
    ...     overwrite_xps(xps, save_as)
    &#34;&#34;&#34;
    save_as = Path(save_as).expanduser()
    save_as.mkdir(parents=False, exist_ok=False)

    splitting = np.array_split(xps, nDir)
    for i, sub_xps in enumerate(tqdm(splitting, desc=&#34;Saving&#34;)):
        if len(sub_xps):
            iDir = save_as / str(i)
            os.mkdir(iDir)
            with open(iDir/&#34;xp&#34;, &#34;wb&#34;) as F:
                dill.dump({&#39;xps&#39;: sub_xps}, F)


def overwrite_xps(xps, save_as, nDir=100):
    &#34;&#34;&#34;Save xps in save_as, but safely (by first saving to tmp).&#34;&#34;&#34;
    save_xps(xps, save_as/&#34;tmp&#34;, nDir)

    # Delete
    for d in tqdm(uplink.list_job_dirs(save_as),
                  desc=&#34;Deleting old&#34;):
        shutil.rmtree(d)

    # Mv up from tmp/ -- goes quick, coz there are not many.
    for d in os.listdir(save_as/&#34;tmp&#34;):
        shutil.move(save_as/&#34;tmp&#34;/d, save_as/d)

    shutil.rmtree(save_as/&#34;tmp&#34;)


def reduce_inodes(save_as, nDir=100):
    &#34;&#34;&#34;Reduce the number of `xp` dirs

    by packing multiple `xp`s into lists (`xps`).

    This reduces the **number** of files (inodes) on the system,
    which limits storage capacity (along with **size**).

    It also deletes files &#34;xp.var&#34; and &#34;out&#34;
    (which tends to be relatively large coz of the progbar).
    This is probably also the reason that the loading time is sometimes reduced.
    &#34;&#34;&#34;
    overwrite_xps(load_xps(save_as), save_as, nDir)


class SparseSpace(dict):
    &#34;&#34;&#34;Subclass of `dict` that enforces key conformity to a `namedtuple`.

    Like a normal `dict`, it can hold any type of objects.
    But, since keys must conform, this effectively defines a coordinate system,
    i.e. vector **space**.

    The coordinate system is specified by its &#34;axes&#34;,
    which is used to produce `self.Coord` (a `namedtuple` class).

    In normal use, this space is highly sparse,
    coz there are many coordinates with no matching experiment,
    eg. `coord(da_method=Climatology, rot=True, ...)`.

    Indeed, operations across (potentially multiple) axes,
    such as optimization or averaging, should be carried out by iterating
    -- not over the axes -- but over the the list of items.

    The most important method is `nest`,
    which is used (by `xpSpace.table_tree`) to separate tables/columns,
    and also to carry out the mean/optim operations.

    In addition, `__getitem__` is very flexible, allowing accessing by:

    - The actual key, a `self.Coord` object. Returns single item.
    - A `dict` to match against (part of) the coordinates. Returns subspace.
    - An `int`. Returns `list(self)[key]`.
    - A list of any of the above. Returns list.

    This flexibility can cause bugs, but it&#39;s probably still worth it.
    Also see `__call__`, `get_for`, and `coords`,
    for further convenience.

    Inspired by

    - https://stackoverflow.com/a/7728830
    - https://stackoverflow.com/q/3387691
    &#34;&#34;&#34;

    @property
    def axes(self):
        return self.Coord._fields

    def __init__(self, axes, *args, **kwargs):
        &#34;&#34;&#34;Usually initialized through `xpSpace`.

        Parameters
        ----------
        axes: list
            The attributes defining the coordinate system.

        args: entries
            Nothing, or a list of `xp`s.
        &#34;&#34;&#34;
        # Define coordinate system
        self.Coord = collections.namedtuple(&#39;Coord&#39;, axes)
        # Write dict
        self.update(*args, **kwargs)
        # Add repr/str
        self.Coord.__repr__ = lambda c: &#34;,&#34;.join(
            f&#34;{k}={v!r}&#34; for k, v in zip(c._fields, c))
        self.Coord.__str__  = lambda c: &#34;,&#34;.join(str(v) for v in c)

    def update(self, *args, **kwargs):
        &#34;&#34;&#34;Update using custom `__setitem__`.&#34;&#34;&#34;
        # See https://stackoverflow.com/a/2588648
        # and https://stackoverflow.com/a/2390997
        for k, v in dict(*args, **kwargs).items():
            self[k] = v

    def __setitem__(self, key, val):
        &#34;&#34;&#34;Setitem ensuring coordinate conforms.&#34;&#34;&#34;
        try:
            key = self.Coord(*key)
        except TypeError:
            raise TypeError(
                f&#34;The key {key!r} did not fit the coord. system &#34;
                f&#34;which has axes {self.axes}&#34;)
        super().__setitem__(key, val)

    def __getitem__(self, key):
        &#34;&#34;&#34;Flexible indexing.&#34;&#34;&#34;
        # List of items (by a list of indices).
        # Also see get_for().
        if isinstance(key, list):
            return [self[k] for k in key]

        # Single (by integer) or list (by Slice)
        # Note: NOT validating np.int64 here catches quite a few bugs.
        elif isinstance(key, int) or isinstance(key, slice):
            return [*self.values()][key]

        # Subspace (by dict, ie. an informal, partial coordinate)
        elif isinstance(key, dict):
            outer = self.nest(outer_axes=list(key))  # nest
            coord = outer.Coord(*key.values())      # create coord
            inner = outer[coord]                    # chose subspace
            return inner

        # Single item (by Coord object, coz an integer (eg)
        # gets interpreted (above) as a list index)
        else:
            # NB: Dont&#39;t use isinstance(key, self.Coord)
            # coz it fails when the namedtuple (Coord) has been
            # instantiated in different places (but with equal params).
            # Also see bugs.python.org/issue7796
            return super().__getitem__(key)

    def __getkey__(self, entry):
        &#34;&#34;&#34;Inverse of `dict.__getitem__`, but also works on coords.

        Note: This dunder method is not a &#34;builtin&#34; naming convention.
        &#34;&#34;&#34;
        coord = (getattr(entry, a, None) for a in self.axes)
        return self.Coord(*coord)

    def __call__(self, **kwargs):
        &#34;&#34;&#34;Convenience.

        Example
        -------
        &gt;&gt;&gt; xp_dict(da_method=&#34;EnKF&#34;, infl=1, seed=3)  # doctest: +SKIP
        &#34;&#34;&#34;
        return self.__getitem__(kwargs)

    def get_for(self, ticks, default=None):
        &#34;&#34;&#34;Almost `[self.get(Coord(x)) for x in ticks]`.

        NB: using the &#34;naive&#34; thing: `[self[x] for x in ticks]`
        would probably be a BUG coz x gets interpreted as indices
        for the internal list.
        &#34;&#34;&#34;
        singleton = not hasattr(ticks[0], &#34;__iter__&#34;)
        def coord(xyz): return self.Coord(xyz if singleton else xyz)
        return [self.get(coord(x), default) for x in ticks]

    def coords(self, **kwargs):
        &#34;&#34;&#34;Get all `coord`s matching kwargs.

        Unlike `__getitem__(kwargs)`,
        - A list is returned, not a subspace.
        - This list constains keys (coords), not values.
        - The coords refer to the original space, not the subspace.

        The last point is especially useful for
        `SparseSpace.label_xSection`.
        &#34;&#34;&#34;
        def embed(coord): return {**kwargs, **coord._asdict()}
        return [self.Coord(**embed(x)) for x in self[kwargs]]

        # Old implementation.
        # - I prefer the new version for its re-use of __getitem__&#39;s
        #   nesting, evidencing their mutual relationship)
        # - Note that unlike xpList.inds(): missingval shenanigans
        #   are here unnecessary coz each coordinate is complete.
        # match  = lambda x: all(getattr(x,k)==kwargs[k] for k in kwargs)
        # return [x for x in self if match(x)]

    def __repr__(self):
        # Note: print(xpList(self)) produces more human-readable key listing,
        # but we don&#39;t want to implement it here, coz it requires split_attrs(),
        # which we don&#39;t really want to call again.
        L = 2
        keys = [str(k) for k in self]
        if 2*L &lt; len(keys):
            keys = keys[:L] + [&#34;...&#34;] + keys[-L:]
        keys = &#34;[\n  &#34; + &#34;,\n  &#34;.join(keys) + &#34;\n]&#34;
        txt = f&#34;&lt;{self.__class__.__name__}&gt; with {len(self)} keys: {keys}&#34;
        # txt += &#34; befitting the coord. sys. with axes &#34;
        txt += &#34;\nplaced in a coord-sys with axes &#34;
        try:
            txt += &#34;(and ticks):&#34; + str(struct_tools.AlignedDict(self.ticks))
        except AttributeError:
            txt += &#34;:\n&#34; + str(self.axes)
        return txt

    def nest(self, inner_axes=None, outer_axes=None):
        &#34;&#34;&#34;Return a new xpSpace with axes `outer_axes`,

        obtained by projecting along the `inner_axes`.
        The entries of this `xpSpace` are themselves `xpSpace`s,
        with axes `inner_axes`,
        each one regrouping the entries with the same (projected) coordinate.

        Note: is also called by `__getitem__(key)` if `key` is dict.
        &#34;&#34;&#34;
        # Default: a singleton outer space,
        # with everything contained in the inner (projection) space.
        if inner_axes is None and outer_axes is None:
            outer_axes = ()

        # Validate axes
        if inner_axes is None:
            assert outer_axes is not None
            inner_axes = struct_tools.complement(self.axes, outer_axes)
        else:
            assert outer_axes is None
            outer_axes = struct_tools.complement(self.axes, inner_axes)

        # Fill spaces
        outer_space = self.__class__(outer_axes)
        for coord, entry in self.items():
            outer_coord = outer_space.__getkey__(coord)
            try:
                inner_space = outer_space[outer_coord]
            except KeyError:
                inner_space = self.__class__(inner_axes)
                outer_space[outer_coord] = inner_space
            inner_space[inner_space.__getkey__(coord)] = entry

        return outer_space

    def add_axis(self, axis):
        self.__init__(self.axes+(axis,))
        for coord in list(self):
            entry = self.pop(coord)
            self[coord + (None,)] = entry

    def intersect_axes(self, attrs):
        &#34;&#34;&#34;Rm those a in attrs that are not in self.axes.

        This allows errors in the axes allotment, for ease-of-use.
        &#34;&#34;&#34;
        absent = struct_tools.complement(attrs, self.axes)
        if absent:
            print(color_text(&#34;Warning:&#34;, colorama.Fore.RED),
                  &#34;The requested attributes&#34;,
                  color_text(str(absent), colorama.Fore.RED),
                  (&#34;were not found among the&#34;
                   &#34; xpSpace axes (attrs. used as coordinates&#34;
                   &#34; for the set of experiments).&#34;
                   &#34; This may be no problem if the attr. is redundant&#34;
                   &#34; for the coord-sys.&#34;
                   &#34; However, if it is caused by confusion or mis-spelling,&#34;
                   &#34; then it is likely to cause mis-interpretation&#34;
                   &#34; of the shown results.&#34;))
            attrs = struct_tools.complement(attrs, absent)
        return attrs

    def label_xSection(self, label, *NoneAttrs, **sub_coord):
        &#34;&#34;&#34;Insert duplicate entries for the cross section

        whose `coord`s match `sub_coord`,
        adding the attr `Const=label` to their `coord`,
        reflecting the &#34;constance/constraint/fixation&#34; this represents.

        This distinguishes the entries in this fixed-affine subspace,
        preventing them from being gobbled up in `nest`.

        If you wish, you can specify the `NoneAttrs`,
        which are consequently set to None for the duplicated entries,
        preventing them from getting plotted in tuning panels.
        &#34;&#34;&#34;
        if &#34;Const&#34; not in self.axes:
            self.add_axis(&#39;Const&#39;)

        for coord in self.coords(**self.intersect_axes(sub_coord)):
            entry = copy.deepcopy(self[coord])
            coord = coord._replace(Const=label)
            coord = coord._replace(**{a: None for a in NoneAttrs})
            self[coord] = entry


AXES_ROLES = dict(outer=None, inner=None, mean=None, optim=None)


class xpSpace(SparseSpace):
    &#34;&#34;&#34;Functionality to facilitate working with `xps` and their results.

    `xpSpace.from_list` initializes a `SparseSpace` from a list
    of objects, typically experiments referred to as `xp`s, by
    (1) computing the relevant axes from the attributes, and
    (2) filling the dict by `xp`s.

    Using `xpSpace.from_list(xps)` creates a SparseSpace holding `xp`s.
    However, the nested `xpSpace`s output by `xpSpace.table_tree` will hold
    objects of type `UncertainQtty`,
    coz `xpSpace.table_tree` calls `mean` calls `field(statkey)`.

    The main use of `xpSpace` is through `xpSpace.print` &amp; `xpSpace.plot`,
    both of which call `xpSpace.table_tree` to nest the axes of the `SparseSpace`.
    &#34;&#34;&#34;

    @classmethod
    def from_list(cls, xps):
        &#34;&#34;&#34;Init xpSpace from xpList.&#34;&#34;&#34;
        def make_ticks(axes, ordering=dict(  # noqa TODO 5
                    N         = &#39;default&#39;,
                    seed      = &#39;default&#39;,
                    infl      = &#39;default&#39;,
                    loc_rad   = &#39;default&#39;,
                    rot       = &#39;as_found&#39;,
                    da_method = &#39;as_found&#39;,
                    )):
            &#34;&#34;&#34;Unique &amp; sort, for each axis (individually) in axes.&#34;&#34;&#34;
            for ax_name, arr in axes.items():
                ticks = set(arr)  # unique (jumbles order)

                # Sort
                order = ordering.get(ax_name, &#39;default&#39;).lower()
                if callable(order):  # eg. mylist.index
                    ticks = sorted(ticks, key=order)
                elif &#39;as_found&#39; in order:
                    ticks = sorted(ticks, key=arr.index)
                else:  # default sorting, with None placed at the end
                    ticks = sorted(ticks, key= lambda x: (x is None, x))
                if any(x in order for x in [&#39;rev&#39;, &#39;inv&#39;]):
                    ticks = ticks[::-1]
                axes[ax_name] = ticks

        # Define axes
        xp_list = xpList(xps)
        axes = xp_list.split_attrs(nomerge=[&#39;Const&#39;])[0]
        make_ticks(axes)
        self = cls(axes.keys())

        # Note: this attr (ticks) will not be propagated through nest().
        # That is fine. Otherwise we should have to prune the ticks
        # (if they are to be useful), which we don&#39;t want to do.
        self.ticks = axes

        # Fill
        self.update({self.__getkey__(xp): xp for xp in xps})

        return self

    def field(self, statkey=&#34;rmse.a&#34;):
        &#34;&#34;&#34;Extract `statkey` for each item in `self`.&#34;&#34;&#34;
        # Init a new xpDict to hold field
        avrgs = self.__class__(self.axes)

        found_anything = False
        for coord, xp in self.items():
            val = getattr(xp.avrgs, statkey, None)
            avrgs[coord] = val
            found_anything = found_anything or (val is not None)

        if not found_anything:
            raise AttributeError(
                f&#34;The stat. field &#39;{statkey}&#39; was not found&#34;
                &#34; among any of the xp&#39;s.&#34;)

        return avrgs

    def mean(self, axes=None):
        # Note: The case `axes=()` should work w/o special treatment.
        if axes is None:
            return self

        nested = self.nest(axes)
        for coord, space in nested.items():

            def getval(uq): return uq.val if isinstance(uq, UncertainQtty) else uq
            vals = [getval(uq) for uq in space.values()]

            # Don&#39;t use nanmean! It would give false impressions.
            mu = np.mean(vals)

            with warnings.catch_warnings():
                warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
                # Don&#39;t print warnings caused by N=1.
                # It already correctly yield nan&#39;s.
                var = np.var(vals, ddof=1)

            N = len(vals)
            uq = UncertainQtty(mu, np.sqrt(var/N))
            uq.nTotal   = N
            uq.nFail    = N - np.isfinite(vals).sum()
            uq.nSuccess = N - uq.nFail

            nested[coord] = uq
        return nested

    def tune(self, axes=None, costfun=None):
        &#34;&#34;&#34;Get (compile/tabulate) a stat field optimised wrt. tuning params.&#34;&#34;&#34;
        # Define cost-function
        costfun = (costfun or &#39;increasing&#39;).lower()
        if &#39;increas&#39; in costfun:
            costfun = (lambda x: +x)
        elif &#39;decreas&#39; in costfun:
            costfun = (lambda x: -x)
        else:
            assert callable(costfun)  # custom

        # Note: The case `axes=()` should work w/o special treatment.
        if axes is None:
            return self

        nested = self.nest(axes)
        for coord, space in nested.items():

            # Find optimal value and coord within space
            MIN = np.inf
            for inner_coord, uq in space.items():
                cost = costfun(uq.val)
                if cost &lt;= MIN:
                    MIN                = cost
                    uq_opt             = uq
                    uq_opt.tuned_coord = inner_coord

            nested[coord] = uq_opt

        return nested

    def validate_axes(self, axes):
        &#34;&#34;&#34;Validate axes.

        Note: This does not convert None to (),
              allowing None to remain special.
              Use `axis or ()` wherever tuples are required.
        &#34;&#34;&#34;
        roles = {}  # &#34;inv&#34;
        for role in set(axes) | set(AXES_ROLES):
            assert role in AXES_ROLES, f&#34;Invalid role {role!r}&#34;
            aa = axes.get(role, AXES_ROLES[role])

            if aa is None:
                pass  # Purposely special
            else:
                # Ensure iterable
                if isinstance(aa, str) or not hasattr(aa, &#34;__iter__&#34;):
                    aa = (aa,)

                aa = self.intersect_axes(aa)

                for axis in aa:

                    # Ensure unique
                    if axis in roles:
                        raise TypeError(
                            f&#34;An axis (here {axis!r}) cannot be assigned to 2&#34;
                            f&#34; roles (here {role!r} and {roles[axis]!r}).&#34;)
                    else:
                        roles[axis] = role
            axes[role] = aa
        return axes

    def table_tree(self, statkey, axes):
        &#34;&#34;&#34;Hierarchical nest(): xp_dict&gt;outer&gt;inner&gt;mean&gt;optim.

        as specified by `axes`. Returns this new xpSpace.

        - print_1d / plot_1d (respectively) separate
          tables / panel(row)s for `axes[&#39;outer&#39;]`, and
          columns/ x-axis      for `axes[&#39;inner&#39;]`.

        - The `axes[&#39;mean&#39;]` and `axes[&#39;optim&#39;]` get eliminated
          by the mean()/tune() operations.

        Note: cannot support multiple statkeys
              because it&#39;s not (obviously) meaningful
              when optimizing over tuning_axes.
        &#34;&#34;&#34;
        axes = self.validate_axes(axes)

        def mean_tune(xp_dict):
            &#34;&#34;&#34;Take mean, then tune.

            Note: the SparseDict implementation should be sufficiently
            &#34;uncluttered&#34; that mean_tune() (or a few of its code lines)
            could be called anywhere above/between/below
            the `nest()`ing of `outer` or `inner`.
            These possibile call locations are commented in the code.
            &#34;&#34;&#34;
            uq_dict = xp_dict.field(statkey)
            uq_dict = uq_dict.mean(axes[&#39;mean&#39;])
            uq_dict = uq_dict.tune(axes[&#39;optim&#39;])
            return uq_dict

        self = mean_tune(self)
        # Prefer calling mean_tune() [also see its docstring]
        # before doing outer/inner nesting. This is because then the axes of
        # a row (xpSpace) should not include mean&amp;optim, and thus:
        #  - Column header/coords may be had directly as row.keys(),
        #    without extraction by __getkey__() from (e.g.) row[0].
        #  - Don&#39;t need to propagate mean&amp;optim axes down to the row level.
        #    which would require defining rows by the nesting:
        #    rows = table.nest(outer_axes=struct_tools.complement(table.axes,
        #        *(axes[&#39;inner&#39;] or ()),
        #        *(axes[&#39;mean&#39;]  or ()),
        #        *(axes[&#39;optim&#39;] or ()) ))
        #  - Each level of the output from table_tree
        #    is a smaller (and more manageable) dict.

        tables = self.nest(outer_axes=axes[&#39;outer&#39;])
        for table_coord, table in tables.items():
            # table = mean_tune(table)

            # Should not be used (nesting as rows is more natural,
            # and is required for getting distinct/row_keys).
            # cols = table.nest(outer_axes=axes[&#39;inner&#39;])

            rows = table.nest(inner_axes=axes[&#39;inner&#39;] or ())

            # Overwrite table by its nesting as rows
            tables[table_coord] = rows

            # for row_coord, row in rows.items():
            # rows[row_coord] = mean_tune(row)

        return axes, tables

    def tickz(self, axis_name):
        &#34;&#34;&#34;Axis ticks without None&#34;&#34;&#34;
        return [x for x in self.ticks[axis_name] if x is not None]

    def print(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES,  # noqa
              subcols=True, decimals=None):
        &#34;&#34;&#34;Print tables of results.

        Parameters
        ----------
        statkey: str
            The statistical field from the experiments to report.
        subcols: bool
            If `True`, then subcolumns are added to indicate the
            1σ confidence interval, and potentially some other stuff.
        axes: dict
            Allots (maps) each role to a set of axis of the `xpSpace`.
            Example:

            &gt;&gt;&gt; dict(outer=&#39;da_method&#39;, inner=&#39;N&#39;, mean=&#39;seed&#39;,  # doctest: +SKIP
            ...      optim=(&#39;infl&#39;,&#39;loc_rad&#39;))

            - Herein, the &#34;role&#34; `outer` should list the axes/attributes
            used to define the splitting of the results into *separate tables*:
            one table for each distinct combination of attributes.
            - Similarly , the role `inner` determines which attributes
            split a table into its columns.
            - `mean` lists the attributes used over which the mean is taken.
            - `optim` lists the attributes used over which the optimum result
               is searched for.

            Example: If `mean` is assigned to:

            - `(&#34;seed&#34;,)`: Experiments are averaged accross seeds,
                           and the 1σ (sub)col is computed as sqrt(var(xps)/N),
                           where xps is a set of experiments.

            - `()`       : Experiments are averaged across nothing
                           (i.e. this is an edge case).

            - `None`     : Experiments are not averaged
                           (i.e. the values are the same as above),
                           and the 1σ (sub)col is computed from
                           the time series of that single experiment.
        decimals: int
            Number of decimals to print.
            If `None`, this is determined for each statistic by its uncertainty.
        &#34;&#34;&#34;
        def make_cols(rows, cc, subcols, h2):
            &#34;&#34;&#34;Subcolumns: align, justify, join.&#34;&#34;&#34;
            # Define subcol formats
            if subcols:
                templ = &#34;{val} ±{prec}&#34;
                templ += &#34;&#34; if axes[&#39;optim&#39;] is None else &#34; *{tuned_coord}&#34;
                templ += &#34;&#34; if  axes[&#39;mean&#39;] is None else &#34; {nFail} {nSuccess}&#34;  # noqa
                aligns = dict(prec=&#34;&lt;&#34;, tuned_coord=&#34;&lt;&#34;)
                labels = dict(val=statkey, prec=&#34;1σ&#34;,
                              tuned_coord=axes[&#34;optim&#34;],
                              nFail=&#34;☠&#34;, nSuccess=&#34;✓&#34;)

            def align(column):
                col = unpack_uqs(column, decimals)
                if subcols:
                    for key in list(col):
                        if key in templ:
                            subcolmn = [labels.get(key, key)] + col[key]
                            col[key] = align_col(subcolmn, just=aligns.get(key, &#34;&gt;&#34;))
                        else:
                            del col[key]
                    col = [templ.format(**row) for row in struct_tools.transps(col)]
                else:
                    col = align_col([statkey] + col[&#34;val&#34;])
                return col

            def super_header(col_coord, idx, col):
                header, matter = col[0], col[1:]
                if idx:
                    super_header = str(col_coord)
                else:
                    super_header = repr(col_coord)
                width = len(header)  # += 1 if using unicode chars like ✔️
                super_header = super_header.center(width, &#34;_&#34;)
                header = super_header + &#34;\n&#34; + header
                return [header] + matter

            # Transpose
            columns = [list(x) for x in zip(*rows)]

            # Format column
            for j, (col_coord, column) in enumerate(zip(cc, columns)):
                col = align(column)
                if h2:
                    col = super_header(col_coord, j, col)
                columns[j] = col

            # Un-transpose
            rows = [list(x) for x in zip(*columns)]

            return rows

        # Inform axes[&#34;mean&#34;]
        if axes.get(&#39;mean&#39;, None):
            print(f&#34;Averages (in time and) over {axes[&#39;mean&#39;]}.&#34;)
        else:
            print(&#34;Averages in time only&#34;
                  &#34; (=&gt; the 1σ estimates may be unreliable).&#34;)

        axes, tables = self.table_tree(statkey, axes)
        for table_coord, table in tables.items():

            # Get this table&#39;s column coords (cc). Use dict for sorted&amp;unique.
            # cc = xp_dict.ticks[axes[&#34;inner&#34;]] # May be larger than needed.
            # cc = table[0].keys()              # May be too small a set.
            cc = {c: None for row in table.values() for c in row}

            # Convert table (rows) into rows (lists) of equal length
            rows = [[row.get(c, None) for c in cc] for row in table.values()]

            if False:  # ****************** Simple (for debugging) table
                for i, (row_coord, row) in enumerate(zip(table, rows)):
                    row_key = &#34;, &#34;.join(str(v) for v in row_coord)
                    rows[i] = [row_key] + row
                rows.insert(0, [f&#34;{table.axes}&#34;] + [repr(c) for c in cc])
            else:  # ********************** Elegant table.
                h2 = &#34;\n&#34; if len(cc) &gt; 1 else &#34;&#34;  # do column-super-header
                rows = make_cols(rows, cc, subcols, h2)

                # Make and prepend left-side table
                # - It&#39;s prettier if row_keys don&#39;t have unnecessary cols.
                #   For example, the table of Climatology should not have an
                #   entire column repeatedly displaying &#34;infl=None&#34;.
                #   =&gt; split_attrs().
                # - Why didn&#39;t we do this for the column attrs?
                #   Coz there we have no ambition to split the attrs,
                #   which would also require excessive processing:
                #   nesting the table as cols, and then split_attrs() on cols.
                row_keys = xpList(table.keys()).split_attrs()[0]
                if len(row_keys):
                    # Header
                    rows[0] = [h2+k for k in row_keys] + [h2+&#39;⑊&#39;] + rows[0]
                    # Matter
                    for i, (row, key) in enumerate(zip(
                            rows[1:], struct_tools.transps(row_keys))):
                        rows[i+1] = [*key.values()] + [&#39;|&#39;] + row

            # Print
            print(&#34;\n&#34;, end=&#34;&#34;)
            if axes[&#39;outer&#39;]:
                table_title = &#34;Table for &#34; + repr(table_coord)
                print(color_text(table_title, colorama.Back.YELLOW))
            headers, *rows = rows
            t = tabulate(rows, headers).replace(&#39;␣&#39;, &#39; &#39;)
            print(t)

    def plot(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES, get_style=default_styles,
             fignum=None, figsize=None, panels=None,
             title2=None, costfun=None, unique_labels=True):
        &#34;&#34;&#34;Plot the avrgs of `statkey` as a function of `axis[&#34;inner&#34;]`.

        Optionally, the experiments can be grouped by `axis[&#34;outer&#34;]`,
        producing a figure with columns of panels.
        Firs of all, though, mean and optimum computations are done for
        `axis[&#34;mean&#34;]` and `axis[&#34;optim&#34;]`, where the optimization can
        be controlled through `costfun` (see `xpSpace.tune`)

        This is entirely analogous to the roles of `axis` in `xpSpace.print`.

        The optimal parameters are plotted in smaller panels below the main plot.
        This can be prevented by providing the figure axes through the `panels` arg.
        &#34;&#34;&#34;
        def plot1(panelcol, row, style):
            &#34;&#34;&#34;Plot a given line (row) in the main panel and the optim panels.

            Involves: Sort, insert None&#39;s, handle constant lines.
            &#34;&#34;&#34;
            # Make a full row (yy) of vals, whether is_constant or not.
            # row.is_constant = (len(row)==1 and next(iter(row))==row.Coord(None))
            row.is_constant = all(x == row.Coord(None) for x in row)
            yy = [row[0] if row.is_constant else y for y in row.get_for(xticks)]

            # Plot main
            row.vals = [getattr(y, &#39;val&#39;, None) for y in yy]
            row.handles = {}
            row.handles[&#34;main_panel&#34;] = panelcol[0].plot(xticks, row.vals, **style)[0]

            # Plot tuning params
            row.tuned_coords = {}  # Store ordered, &#34;transposed&#34; argmins
            argmins = [getattr(y, &#39;tuned_coord&#39;, None) for y in yy]
            for a, panel in zip(axes[&#34;optim&#34;], panelcol[1:]):
                yy = [getattr(coord, a, None) for coord in argmins]
                row.tuned_coords[a] = yy

                # Plotting all None&#39;s sets axes units (like any plotting call)
                # which can cause trouble if the axes units were actually supposed
                # to be categorical (eg upd_a), but this is only revealed later.
                if not all(y == None for y in yy):
                    row.handles[a] = panel.plot(xticks, yy, **style)

        # Nest axes through table_tree()
        assert len(axes[&#34;inner&#34;]) == 1, &#34;You must chose the abscissa.&#34;
        axes, tables = self.table_tree(statkey, axes)
        xticks = self.tickz(axes[&#34;inner&#34;][0])

        # Figure panels
        if panels is None:
            nrows   = len(axes[&#39;optim&#39;] or ()) + 1
            ncols   = len(tables)
            maxW    = 12.7  # my mac screen
            figsize = figsize or (min(5*ncols, maxW), 7)
            gs      = dict(
                height_ratios=[6]+[1]*(nrows-1),
                hspace=0.05, wspace=0.05,
                # eyeballed:
                left=0.15/(1+np.log(ncols)),
                right=0.97, bottom=0.06, top=0.9)
            # Create
            _, panels = freshfig(num=fignum, figsize=figsize,
                                 nrows=nrows, sharex=True,
                                 ncols=ncols, sharey=&#39;row&#39;,
                                 gridspec_kw=gs)
            panels = np.ravel(panels).reshape((-1, ncols))
        else:
            panels = np.atleast_2d(panels)

        # Title
        fig = panels[0, 0].figure
        fig_title = &#34;Average wrt. time&#34;
        if axes[&#34;mean&#34;] is not None:
            fig_title += f&#34; and {axes[&#39;mean&#39;]}&#34;
        if title2 is not None:
            fig_title += &#34;\n&#34; + str(title2)
        fig.suptitle(fig_title)

        # Loop outer
        label_register = set()  # mv inside loop to get legend on each panel
        for table_panels, (table_coord, table) in zip(panels.T, tables.items()):
            table.panels = table_panels
            title = &#39;&#39; if axes[&#34;outer&#34;] is None else repr(table_coord)

            # Plot
            for coord, row in table.items():
                style = get_style(coord)

                # Rm duplicate labels (contrary to coords, labels can
                # be &#34;tampered&#34; with, and so can be duplicate)
                if unique_labels:
                    if style.get(&#34;label&#34;, None) in label_register:
                        del style[&#34;label&#34;]
                    else:
                        label_register.add(style[&#34;label&#34;])

                plot1(table.panels, row, style)

            # Beautify
            panel0 = table.panels[0]
            panel0.set_title(title)
            if panel0.is_first_col():
                panel0.set_ylabel(statkey)
            with set_tmp(mpl_logger, &#39;level&#39;, 99):  # silence &#34;no label&#34; msg
                panel0.legend()
            table.panels[-1].set_xlabel(axes[&#34;inner&#34;][0])
            # Tuning panels:
            for a, panel in zip(axes[&#34;optim&#34;] or (), table.panels[1:]):
                if panel.is_first_col():
                    panel.set_ylabel(f&#34;Optim.\n{a}&#34;)

        tables.fig = fig
        tables.xp_dict = self
        tables.axes_roles = axes
        return tables


def default_fig_adjustments(tables):
    &#34;&#34;&#34;Beautify. These settings do not generalize well.&#34;&#34;&#34;
    # Get axs as 2d-array
    axs = np.array([table.panels for table in tables.values()]).T

    # Main panels (top row) only:
    sensible_f = ticker.FormatStrFormatter(&#39;%g&#39;)
    for ax in axs[0, :]:  # noqa
        for direction, nPanel in zip([&#39;y&#39;, &#39;x&#39;], axs.shape):
            if nPanel &lt; 6:
                eval(f&#34;ax.set_{direction}scale(&#39;log&#39;)&#34;)
                eval(f&#34;ax.{direction}axis&#34;).set_minor_formatter(sensible_f)
            eval(f&#34;ax.{direction}axis&#34;).set_major_formatter(sensible_f)

    # Tuning panels only
    table = tables[0]
    for a, panel in zip(tables.axes_roles[&#34;optim&#34;] or (), table.panels[1:]):
        yy = tables.xp_dict.tickz(a)
        axis_scale_by_array(panel, yy, &#34;y&#34;)
        # set_ymargin doesn&#39;t work for wonky scales. Do so manually:
        alpha = len(yy)/10
        y0, y1, y2, y3 = yy[0], yy[1], yy[-2], yy[-1]
        panel.set_ylim(y0-alpha*(y1-y0), y3+alpha*(y3-y2))

    # All panels
    for ax in axs.ravel():
        for direction, nPanel in zip([&#39;y&#39;, &#39;x&#39;], axs.shape):
            if nPanel &lt; 6:
                ax.grid(True, which=&#34;minor&#34;, axis=direction)

    # Not strictly compatible with gridspec height_ratios,
    # (throws warning), but still works ok.
    with warnings.catch_warnings():
        warnings.simplefilter(&#34;ignore&#34;, category=UserWarning)
        axs[0, 0].figure.tight_layout()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dapper.xp_process.make_label"><code class="name flex">
<span>def <span class="ident">make_label</span></span>(<span>coord, no_key=('da_method', 'Const', 'upd_a'), exclude=())</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L33-L42" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def make_label(coord, no_key=NO_KEY, exclude=()):
    dct = {a: v for a, v in coord._asdict().items() if v != None}
    lbl = &#39;&#39;
    for k, v in dct.items():
        if k not in exclude:
            if any(x in k for x in no_key):
                lbl = lbl + f&#39; {v}&#39;
            else:
                lbl = lbl + f&#39; {collapse_str(k,7)}:{v}&#39;
    return lbl[1:]</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.default_styles"><code class="name flex">
<span>def <span class="ident">default_styles</span></span>(<span>coord, baseline_legends=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Quick and dirty (but somewhat robust) styling.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L45-L85" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def default_styles(coord, baseline_legends=False):
    &#34;&#34;&#34;Quick and dirty (but somewhat robust) styling.&#34;&#34;&#34;
    style = struct_tools.DotDict(ms=8)
    style.label = make_label(coord)

    try:
        if coord.da_method == &#34;Climatology&#34;:
            style.ls = &#34;:&#34;
            style.c = &#34;k&#34;
            if not baseline_legends:
                style.label = None

        elif coord.da_method == &#34;OptInterp&#34;:
            style.ls = &#34;:&#34;
            style.c = .7*np.ones(3)
            style.label = &#34;Opt. Interp.&#34;
            if not baseline_legends:
                style.label = None

        elif coord.da_method == &#34;Var3D&#34;:
            style.ls = &#34;:&#34;
            style.c = .5*np.ones(3)
            style.label = &#34;3D-Var&#34;
            if not baseline_legends:
                style.label = None

        elif coord.da_method == &#34;EnKF&#34;:
            style.marker = &#34;*&#34;
            style.c = &#34;C1&#34;

        elif coord.da_method == &#34;PartFilt&#34;:
            style.marker = &#34;X&#34;
            style.c = &#34;C2&#34;

        else:
            style.marker = &#34;.&#34;

    except AttributeError:
        pass

    return style</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.rel_index"><code class="name flex">
<span>def <span class="ident">rel_index</span></span>(<span>elem, lst, default=None)</span>
</code></dt>
<dd>
<div class="desc"><p><code>lst.index(elem) / len(lst)</code> with fallback.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L88-L95" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def rel_index(elem, lst, default=None):
    &#34;&#34;&#34;`lst.index(elem) / len(lst)` with fallback.&#34;&#34;&#34;
    try:
        return lst.index(elem) / len(lst)
    except ValueError:
        if default == None:
            raise
        return default</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.discretize_cmap"><code class="name flex">
<span>def <span class="ident">discretize_cmap</span></span>(<span>cmap, N, val0=0, val1=1, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Discretize <code>cmap</code> so that it partitions <code>[0, 1]</code> into <code>N</code> segments.</p>
<p>I.e. <code>cmap(k/N) == cmap(k/N + eps)</code>.</p>
<p>Also provide the ScalarMappable <code>sm</code>
that maps range(N) to the segment centers,
as will be reflected by <code>cb = fig.colorbar(sm)</code>.
You can then re-label the ticks using
<code>cb.set_ticks(np.arange(N)); cb.set_ticklabels(["A","B","C",...])</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L98-L116" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def discretize_cmap(cmap, N, val0=0, val1=1, name=None):
    &#34;&#34;&#34;Discretize `cmap` so that it partitions `[0, 1]` into `N` segments.

    I.e. `cmap(k/N) == cmap(k/N + eps)`.

    Also provide the ScalarMappable `sm`
    that maps range(N) to the segment centers,
    as will be reflected by `cb = fig.colorbar(sm)`.
    You can then re-label the ticks using
    `cb.set_ticks(np.arange(N)); cb.set_ticklabels([&#34;A&#34;,&#34;B&#34;,&#34;C&#34;,...])`.
    &#34;&#34;&#34;
    # cmap(k/N)
    from_list = mpl.colors.LinearSegmentedColormap.from_list
    colors = cmap(np.linspace(val0, val1, N))
    cmap = from_list(name, colors, N)
    # sm
    cNorm = mpl.colors.Normalize(-.5, -.5+N)
    sm = mpl.cm.ScalarMappable(cNorm, cmap)
    return cmap, sm</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.cm_bond"><code class="name flex">
<span>def <span class="ident">cm_bond</span></span>(<span>cmap, xp_dict, axis, vmin=0, vmax=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Map cmap for <code>coord.axis ∈ [0, len(ticks)]</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L119-L131" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def cm_bond(cmap, xp_dict, axis, vmin=0, vmax=0):
    &#34;&#34;&#34;Map cmap for `coord.axis ∈ [0, len(ticks)]`.&#34;&#34;&#34;
    def link(coord):
        &#34;&#34;&#34;Essentially: `cmap(ticks.index(coord.axis))`&#34;&#34;&#34;
        if hasattr(coord, axis):
            ticks = xp_dict.ticks[axis]
            cNorm = mpl.colors.Normalize(vmin, vmax + len(ticks))
            ScMap = cm.ScalarMappable(cNorm, cmap).to_rgba
            index = ticks.index(getattr(coord, axis))
            return ScMap(index)
        else:
            return cmap(0.5)
    return link</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.in_idx"><code class="name flex">
<span>def <span class="ident">in_idx</span></span>(<span>coord, indices, xp_dict, axis)</span>
</code></dt>
<dd>
<div class="desc"><p>Essentially: <code>coord.axis in ticks[indices]</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L134-L140" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def in_idx(coord, indices, xp_dict, axis):
    &#34;&#34;&#34;Essentially: `coord.axis in ticks[indices]`.&#34;&#34;&#34;
    if hasattr(coord, axis):
        ticks = np.array(xp_dict.ticks[axis])[indices]
        return getattr(coord, axis) in ticks
    else:
        return True</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.load_HMM"><code class="name flex">
<span>def <span class="ident">load_HMM</span></span>(<span>save_as)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L143-L146" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def load_HMM(save_as):
    save_as = Path(save_as).expanduser()
    HMM = dill.load(open(save_as/&#34;xp.com&#34;, &#34;rb&#34;))[&#34;HMM&#34;]
    return HMM</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.load_xps"><code class="name flex">
<span>def <span class="ident">load_xps</span></span>(<span>save_as)</span>
</code></dt>
<dd>
<div class="desc"><p>Load <code>xps</code> (as a simple list) from dir.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L149-L176" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def load_xps(save_as):
    &#34;&#34;&#34;Load `xps` (as a simple list) from dir.&#34;&#34;&#34;
    save_as = Path(save_as).expanduser()
    files = [d/&#34;xp&#34; for d in uplink.list_job_dirs(save_as)]

    def load_any(filepath):
        &#34;&#34;&#34;Load any/all `xp&#39;s` from `filepath`.&#34;&#34;&#34;
        with open(filepath, &#34;rb&#34;) as F:
            # If experiment crashed, then xp will be empty
            try:
                data = dill.load(F)
            except EOFError:
                return []
            # Always return list
            try:
                return data[&#34;xps&#34;]
            except KeyError:
                return [data[&#34;xp&#34;]]

    print(&#34;Loading %d files from %s&#34; % (len(files), save_as))
    xps = []  # NB: progbar wont clean up properly w/ list compr.
    for f in tqdm(files, desc=&#34;Loading&#34;):
        xps.extend(load_any(f))

    if len(xps) &lt; len(files):
        print(f&#34;{len(files)-len(xps)} files could not be loaded.&#34;)

    return xps</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.save_xps"><code class="name flex">
<span>def <span class="ident">save_xps</span></span>(<span>xps, save_as, nDir=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Split xps and save in save_as/i for i in range(nDir).</p>
<h2 id="example">Example</h2>
<p>Rename attr n_iter to nIter:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; proj_name = &quot;Stein&quot;
&gt;&gt;&gt; dd = rc.dirs.data / proj_name
&gt;&gt;&gt; save_as = dd / &quot;run_2020-09-22__19:36:13&quot;
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; for save_as in dd.iterdir():  # doctest: +SKIP
...     save_as = dd / save_as
...
...     xps = load_xps(save_as)
...     HMM = load_HMM(save_as)
...
...     for xp in xps:
...         if hasattr(xp,&quot;n_iter&quot;):
...             xp.nIter = xp.n_iter
...             del xp.n_iter
...
...     overwrite_xps(xps, save_as)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L179-L211" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def save_xps(xps, save_as, nDir=100):
    &#34;&#34;&#34;Split xps and save in save_as/i for i in range(nDir).

    Example
    -------
    Rename attr n_iter to nIter:
    &gt;&gt;&gt; proj_name = &#34;Stein&#34;
    &gt;&gt;&gt; dd = rc.dirs.data / proj_name
    &gt;&gt;&gt; save_as = dd / &#34;run_2020-09-22__19:36:13&#34;

    &gt;&gt;&gt; for save_as in dd.iterdir():  # doctest: +SKIP
    ...     save_as = dd / save_as
    ...
    ...     xps = load_xps(save_as)
    ...     HMM = load_HMM(save_as)
    ...
    ...     for xp in xps:
    ...         if hasattr(xp,&#34;n_iter&#34;):
    ...             xp.nIter = xp.n_iter
    ...             del xp.n_iter
    ...
    ...     overwrite_xps(xps, save_as)
    &#34;&#34;&#34;
    save_as = Path(save_as).expanduser()
    save_as.mkdir(parents=False, exist_ok=False)

    splitting = np.array_split(xps, nDir)
    for i, sub_xps in enumerate(tqdm(splitting, desc=&#34;Saving&#34;)):
        if len(sub_xps):
            iDir = save_as / str(i)
            os.mkdir(iDir)
            with open(iDir/&#34;xp&#34;, &#34;wb&#34;) as F:
                dill.dump({&#39;xps&#39;: sub_xps}, F)</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.overwrite_xps"><code class="name flex">
<span>def <span class="ident">overwrite_xps</span></span>(<span>xps, save_as, nDir=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Save xps in save_as, but safely (by first saving to tmp).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L214-L227" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def overwrite_xps(xps, save_as, nDir=100):
    &#34;&#34;&#34;Save xps in save_as, but safely (by first saving to tmp).&#34;&#34;&#34;
    save_xps(xps, save_as/&#34;tmp&#34;, nDir)

    # Delete
    for d in tqdm(uplink.list_job_dirs(save_as),
                  desc=&#34;Deleting old&#34;):
        shutil.rmtree(d)

    # Mv up from tmp/ -- goes quick, coz there are not many.
    for d in os.listdir(save_as/&#34;tmp&#34;):
        shutil.move(save_as/&#34;tmp&#34;/d, save_as/d)

    shutil.rmtree(save_as/&#34;tmp&#34;)</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.reduce_inodes"><code class="name flex">
<span>def <span class="ident">reduce_inodes</span></span>(<span>save_as, nDir=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Reduce the number of <code>xp</code> dirs</p>
<p>by packing multiple <code>xp</code>s into lists (<code>xps</code>).</p>
<p>This reduces the <strong>number</strong> of files (inodes) on the system,
which limits storage capacity (along with <strong>size</strong>).</p>
<p>It also deletes files "xp.var" and "out"
(which tends to be relatively large coz of the progbar).
This is probably also the reason that the loading time is sometimes reduced.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L230-L242" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def reduce_inodes(save_as, nDir=100):
    &#34;&#34;&#34;Reduce the number of `xp` dirs

    by packing multiple `xp`s into lists (`xps`).

    This reduces the **number** of files (inodes) on the system,
    which limits storage capacity (along with **size**).

    It also deletes files &#34;xp.var&#34; and &#34;out&#34;
    (which tends to be relatively large coz of the progbar).
    This is probably also the reason that the loading time is sometimes reduced.
    &#34;&#34;&#34;
    overwrite_xps(load_xps(save_as), save_as, nDir)</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.default_fig_adjustments"><code class="name flex">
<span>def <span class="ident">default_fig_adjustments</span></span>(<span>tables)</span>
</code></dt>
<dd>
<div class="desc"><p>Beautify. These settings do not generalize well.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L1019-L1053" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def default_fig_adjustments(tables):
    &#34;&#34;&#34;Beautify. These settings do not generalize well.&#34;&#34;&#34;
    # Get axs as 2d-array
    axs = np.array([table.panels for table in tables.values()]).T

    # Main panels (top row) only:
    sensible_f = ticker.FormatStrFormatter(&#39;%g&#39;)
    for ax in axs[0, :]:  # noqa
        for direction, nPanel in zip([&#39;y&#39;, &#39;x&#39;], axs.shape):
            if nPanel &lt; 6:
                eval(f&#34;ax.set_{direction}scale(&#39;log&#39;)&#34;)
                eval(f&#34;ax.{direction}axis&#34;).set_minor_formatter(sensible_f)
            eval(f&#34;ax.{direction}axis&#34;).set_major_formatter(sensible_f)

    # Tuning panels only
    table = tables[0]
    for a, panel in zip(tables.axes_roles[&#34;optim&#34;] or (), table.panels[1:]):
        yy = tables.xp_dict.tickz(a)
        axis_scale_by_array(panel, yy, &#34;y&#34;)
        # set_ymargin doesn&#39;t work for wonky scales. Do so manually:
        alpha = len(yy)/10
        y0, y1, y2, y3 = yy[0], yy[1], yy[-2], yy[-1]
        panel.set_ylim(y0-alpha*(y1-y0), y3+alpha*(y3-y2))

    # All panels
    for ax in axs.ravel():
        for direction, nPanel in zip([&#39;y&#39;, &#39;x&#39;], axs.shape):
            if nPanel &lt; 6:
                ax.grid(True, which=&#34;minor&#34;, axis=direction)

    # Not strictly compatible with gridspec height_ratios,
    # (throws warning), but still works ok.
    with warnings.catch_warnings():
        warnings.simplefilter(&#34;ignore&#34;, category=UserWarning)
        axs[0, 0].figure.tight_layout()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dapper.xp_process.SparseSpace"><code class="flex name class">
<span>class <span class="ident">SparseSpace</span></span>
<span>(</span><span>axes, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Subclass of <code>dict</code> that enforces key conformity to a <code>namedtuple</code>.</p>
<p>Like a normal <code>dict</code>, it can hold any type of objects.
But, since keys must conform, this effectively defines a coordinate system,
i.e. vector <strong>space</strong>.</p>
<p>The coordinate system is specified by its "axes",
which is used to produce <code>self.Coord</code> (a <code>namedtuple</code> class).</p>
<p>In normal use, this space is highly sparse,
coz there are many coordinates with no matching experiment,
eg. <code>coord(da_method=Climatology, rot=True, ...)</code>.</p>
<p>Indeed, operations across (potentially multiple) axes,
such as optimization or averaging, should be carried out by iterating
&ndash; not over the axes &ndash; but over the the list of items.</p>
<p>The most important method is <code>nest</code>,
which is used (by <code><a title="dapper.xp_process.xpSpace.table_tree" href="#dapper.xp_process.xpSpace.table_tree">xpSpace.table_tree()</a></code>) to separate tables/columns,
and also to carry out the mean/optim operations.</p>
<p>In addition, <code>__getitem__</code> is very flexible, allowing accessing by:</p>
<ul>
<li>The actual key, a <code>self.Coord</code> object. Returns single item.</li>
<li>A <code>dict</code> to match against (part of) the coordinates. Returns subspace.</li>
<li>An <code>int</code>. Returns <code>list(self)[key]</code>.</li>
<li>A list of any of the above. Returns list.</li>
</ul>
<p>This flexibility can cause bugs, but it's probably still worth it.
Also see <code>__call__</code>, <code>get_for</code>, and <code>coords</code>,
for further convenience.</p>
<p>Inspired by</p>
<ul>
<li><a href="https://stackoverflow.com/a/7728830">https://stackoverflow.com/a/7728830</a></li>
<li><a href="https://stackoverflow.com/q/3387691">https://stackoverflow.com/q/3387691</a></li>
</ul>
<p>Usually initialized through <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>axes</code></strong> :&ensp;<code>list</code></dt>
<dd>The attributes defining the coordinate system.</dd>
<dt><strong><code>args</code></strong> :&ensp;<code>entries</code></dt>
<dd>Nothing, or a list of <code>xp</code>s.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L245-L505" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class SparseSpace(dict):
    &#34;&#34;&#34;Subclass of `dict` that enforces key conformity to a `namedtuple`.

    Like a normal `dict`, it can hold any type of objects.
    But, since keys must conform, this effectively defines a coordinate system,
    i.e. vector **space**.

    The coordinate system is specified by its &#34;axes&#34;,
    which is used to produce `self.Coord` (a `namedtuple` class).

    In normal use, this space is highly sparse,
    coz there are many coordinates with no matching experiment,
    eg. `coord(da_method=Climatology, rot=True, ...)`.

    Indeed, operations across (potentially multiple) axes,
    such as optimization or averaging, should be carried out by iterating
    -- not over the axes -- but over the the list of items.

    The most important method is `nest`,
    which is used (by `xpSpace.table_tree`) to separate tables/columns,
    and also to carry out the mean/optim operations.

    In addition, `__getitem__` is very flexible, allowing accessing by:

    - The actual key, a `self.Coord` object. Returns single item.
    - A `dict` to match against (part of) the coordinates. Returns subspace.
    - An `int`. Returns `list(self)[key]`.
    - A list of any of the above. Returns list.

    This flexibility can cause bugs, but it&#39;s probably still worth it.
    Also see `__call__`, `get_for`, and `coords`,
    for further convenience.

    Inspired by

    - https://stackoverflow.com/a/7728830
    - https://stackoverflow.com/q/3387691
    &#34;&#34;&#34;

    @property
    def axes(self):
        return self.Coord._fields

    def __init__(self, axes, *args, **kwargs):
        &#34;&#34;&#34;Usually initialized through `xpSpace`.

        Parameters
        ----------
        axes: list
            The attributes defining the coordinate system.

        args: entries
            Nothing, or a list of `xp`s.
        &#34;&#34;&#34;
        # Define coordinate system
        self.Coord = collections.namedtuple(&#39;Coord&#39;, axes)
        # Write dict
        self.update(*args, **kwargs)
        # Add repr/str
        self.Coord.__repr__ = lambda c: &#34;,&#34;.join(
            f&#34;{k}={v!r}&#34; for k, v in zip(c._fields, c))
        self.Coord.__str__  = lambda c: &#34;,&#34;.join(str(v) for v in c)

    def update(self, *args, **kwargs):
        &#34;&#34;&#34;Update using custom `__setitem__`.&#34;&#34;&#34;
        # See https://stackoverflow.com/a/2588648
        # and https://stackoverflow.com/a/2390997
        for k, v in dict(*args, **kwargs).items():
            self[k] = v

    def __setitem__(self, key, val):
        &#34;&#34;&#34;Setitem ensuring coordinate conforms.&#34;&#34;&#34;
        try:
            key = self.Coord(*key)
        except TypeError:
            raise TypeError(
                f&#34;The key {key!r} did not fit the coord. system &#34;
                f&#34;which has axes {self.axes}&#34;)
        super().__setitem__(key, val)

    def __getitem__(self, key):
        &#34;&#34;&#34;Flexible indexing.&#34;&#34;&#34;
        # List of items (by a list of indices).
        # Also see get_for().
        if isinstance(key, list):
            return [self[k] for k in key]

        # Single (by integer) or list (by Slice)
        # Note: NOT validating np.int64 here catches quite a few bugs.
        elif isinstance(key, int) or isinstance(key, slice):
            return [*self.values()][key]

        # Subspace (by dict, ie. an informal, partial coordinate)
        elif isinstance(key, dict):
            outer = self.nest(outer_axes=list(key))  # nest
            coord = outer.Coord(*key.values())      # create coord
            inner = outer[coord]                    # chose subspace
            return inner

        # Single item (by Coord object, coz an integer (eg)
        # gets interpreted (above) as a list index)
        else:
            # NB: Dont&#39;t use isinstance(key, self.Coord)
            # coz it fails when the namedtuple (Coord) has been
            # instantiated in different places (but with equal params).
            # Also see bugs.python.org/issue7796
            return super().__getitem__(key)

    def __getkey__(self, entry):
        &#34;&#34;&#34;Inverse of `dict.__getitem__`, but also works on coords.

        Note: This dunder method is not a &#34;builtin&#34; naming convention.
        &#34;&#34;&#34;
        coord = (getattr(entry, a, None) for a in self.axes)
        return self.Coord(*coord)

    def __call__(self, **kwargs):
        &#34;&#34;&#34;Convenience.

        Example
        -------
        &gt;&gt;&gt; xp_dict(da_method=&#34;EnKF&#34;, infl=1, seed=3)  # doctest: +SKIP
        &#34;&#34;&#34;
        return self.__getitem__(kwargs)

    def get_for(self, ticks, default=None):
        &#34;&#34;&#34;Almost `[self.get(Coord(x)) for x in ticks]`.

        NB: using the &#34;naive&#34; thing: `[self[x] for x in ticks]`
        would probably be a BUG coz x gets interpreted as indices
        for the internal list.
        &#34;&#34;&#34;
        singleton = not hasattr(ticks[0], &#34;__iter__&#34;)
        def coord(xyz): return self.Coord(xyz if singleton else xyz)
        return [self.get(coord(x), default) for x in ticks]

    def coords(self, **kwargs):
        &#34;&#34;&#34;Get all `coord`s matching kwargs.

        Unlike `__getitem__(kwargs)`,
        - A list is returned, not a subspace.
        - This list constains keys (coords), not values.
        - The coords refer to the original space, not the subspace.

        The last point is especially useful for
        `SparseSpace.label_xSection`.
        &#34;&#34;&#34;
        def embed(coord): return {**kwargs, **coord._asdict()}
        return [self.Coord(**embed(x)) for x in self[kwargs]]

        # Old implementation.
        # - I prefer the new version for its re-use of __getitem__&#39;s
        #   nesting, evidencing their mutual relationship)
        # - Note that unlike xpList.inds(): missingval shenanigans
        #   are here unnecessary coz each coordinate is complete.
        # match  = lambda x: all(getattr(x,k)==kwargs[k] for k in kwargs)
        # return [x for x in self if match(x)]

    def __repr__(self):
        # Note: print(xpList(self)) produces more human-readable key listing,
        # but we don&#39;t want to implement it here, coz it requires split_attrs(),
        # which we don&#39;t really want to call again.
        L = 2
        keys = [str(k) for k in self]
        if 2*L &lt; len(keys):
            keys = keys[:L] + [&#34;...&#34;] + keys[-L:]
        keys = &#34;[\n  &#34; + &#34;,\n  &#34;.join(keys) + &#34;\n]&#34;
        txt = f&#34;&lt;{self.__class__.__name__}&gt; with {len(self)} keys: {keys}&#34;
        # txt += &#34; befitting the coord. sys. with axes &#34;
        txt += &#34;\nplaced in a coord-sys with axes &#34;
        try:
            txt += &#34;(and ticks):&#34; + str(struct_tools.AlignedDict(self.ticks))
        except AttributeError:
            txt += &#34;:\n&#34; + str(self.axes)
        return txt

    def nest(self, inner_axes=None, outer_axes=None):
        &#34;&#34;&#34;Return a new xpSpace with axes `outer_axes`,

        obtained by projecting along the `inner_axes`.
        The entries of this `xpSpace` are themselves `xpSpace`s,
        with axes `inner_axes`,
        each one regrouping the entries with the same (projected) coordinate.

        Note: is also called by `__getitem__(key)` if `key` is dict.
        &#34;&#34;&#34;
        # Default: a singleton outer space,
        # with everything contained in the inner (projection) space.
        if inner_axes is None and outer_axes is None:
            outer_axes = ()

        # Validate axes
        if inner_axes is None:
            assert outer_axes is not None
            inner_axes = struct_tools.complement(self.axes, outer_axes)
        else:
            assert outer_axes is None
            outer_axes = struct_tools.complement(self.axes, inner_axes)

        # Fill spaces
        outer_space = self.__class__(outer_axes)
        for coord, entry in self.items():
            outer_coord = outer_space.__getkey__(coord)
            try:
                inner_space = outer_space[outer_coord]
            except KeyError:
                inner_space = self.__class__(inner_axes)
                outer_space[outer_coord] = inner_space
            inner_space[inner_space.__getkey__(coord)] = entry

        return outer_space

    def add_axis(self, axis):
        self.__init__(self.axes+(axis,))
        for coord in list(self):
            entry = self.pop(coord)
            self[coord + (None,)] = entry

    def intersect_axes(self, attrs):
        &#34;&#34;&#34;Rm those a in attrs that are not in self.axes.

        This allows errors in the axes allotment, for ease-of-use.
        &#34;&#34;&#34;
        absent = struct_tools.complement(attrs, self.axes)
        if absent:
            print(color_text(&#34;Warning:&#34;, colorama.Fore.RED),
                  &#34;The requested attributes&#34;,
                  color_text(str(absent), colorama.Fore.RED),
                  (&#34;were not found among the&#34;
                   &#34; xpSpace axes (attrs. used as coordinates&#34;
                   &#34; for the set of experiments).&#34;
                   &#34; This may be no problem if the attr. is redundant&#34;
                   &#34; for the coord-sys.&#34;
                   &#34; However, if it is caused by confusion or mis-spelling,&#34;
                   &#34; then it is likely to cause mis-interpretation&#34;
                   &#34; of the shown results.&#34;))
            attrs = struct_tools.complement(attrs, absent)
        return attrs

    def label_xSection(self, label, *NoneAttrs, **sub_coord):
        &#34;&#34;&#34;Insert duplicate entries for the cross section

        whose `coord`s match `sub_coord`,
        adding the attr `Const=label` to their `coord`,
        reflecting the &#34;constance/constraint/fixation&#34; this represents.

        This distinguishes the entries in this fixed-affine subspace,
        preventing them from being gobbled up in `nest`.

        If you wish, you can specify the `NoneAttrs`,
        which are consequently set to None for the duplicated entries,
        preventing them from getting plotted in tuning panels.
        &#34;&#34;&#34;
        if &#34;Const&#34; not in self.axes:
            self.add_axis(&#39;Const&#39;)

        for coord in self.coords(**self.intersect_axes(sub_coord)):
            entry = copy.deepcopy(self[coord])
            coord = coord._replace(Const=label)
            coord = coord._replace(**{a: None for a in NoneAttrs})
            self[coord] = entry</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="dapper.xp_process.SparseSpace.axes"><code class="name">var <span class="ident">axes</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L284-L286" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@property
def axes(self):
    return self.Coord._fields</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.xp_process.SparseSpace.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Update using custom <code>__setitem__</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L308-L313" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def update(self, *args, **kwargs):
    &#34;&#34;&#34;Update using custom `__setitem__`.&#34;&#34;&#34;
    # See https://stackoverflow.com/a/2588648
    # and https://stackoverflow.com/a/2390997
    for k, v in dict(*args, **kwargs).items():
        self[k] = v</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.get_for"><code class="name flex">
<span>def <span class="ident">get_for</span></span>(<span>self, ticks, default=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Almost <code>[self.get(Coord(x)) for x in ticks]</code>.</p>
<p>NB: using the "naive" thing: <code>[self[x] for x in ticks]</code>
would probably be a BUG coz x gets interpreted as indices
for the internal list.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L370-L379" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_for(self, ticks, default=None):
    &#34;&#34;&#34;Almost `[self.get(Coord(x)) for x in ticks]`.

    NB: using the &#34;naive&#34; thing: `[self[x] for x in ticks]`
    would probably be a BUG coz x gets interpreted as indices
    for the internal list.
    &#34;&#34;&#34;
    singleton = not hasattr(ticks[0], &#34;__iter__&#34;)
    def coord(xyz): return self.Coord(xyz if singleton else xyz)
    return [self.get(coord(x), default) for x in ticks]</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.coords"><code class="name flex">
<span>def <span class="ident">coords</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Get all <code>coord</code>s matching kwargs.</p>
<p>Unlike <code>__getitem__(kwargs)</code>,
- A list is returned, not a subspace.
- This list constains keys (coords), not values.
- The coords refer to the original space, not the subspace.</p>
<p>The last point is especially useful for
<code><a title="dapper.xp_process.SparseSpace.label_xSection" href="#dapper.xp_process.SparseSpace.label_xSection">SparseSpace.label_xSection()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L381-L393" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def coords(self, **kwargs):
    &#34;&#34;&#34;Get all `coord`s matching kwargs.

    Unlike `__getitem__(kwargs)`,
    - A list is returned, not a subspace.
    - This list constains keys (coords), not values.
    - The coords refer to the original space, not the subspace.

    The last point is especially useful for
    `SparseSpace.label_xSection`.
    &#34;&#34;&#34;
    def embed(coord): return {**kwargs, **coord._asdict()}
    return [self.Coord(**embed(x)) for x in self[kwargs]]</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.nest"><code class="name flex">
<span>def <span class="ident">nest</span></span>(<span>self, inner_axes=None, outer_axes=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a new xpSpace with axes <code>outer_axes</code>,</p>
<p>obtained by projecting along the <code>inner_axes</code>.
The entries of this <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code> are themselves <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code>s,
with axes <code>inner_axes</code>,
each one regrouping the entries with the same (projected) coordinate.</p>
<p>Note: is also called by <code>__getitem__(key)</code> if <code>key</code> is dict.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L421-L455" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def nest(self, inner_axes=None, outer_axes=None):
    &#34;&#34;&#34;Return a new xpSpace with axes `outer_axes`,

    obtained by projecting along the `inner_axes`.
    The entries of this `xpSpace` are themselves `xpSpace`s,
    with axes `inner_axes`,
    each one regrouping the entries with the same (projected) coordinate.

    Note: is also called by `__getitem__(key)` if `key` is dict.
    &#34;&#34;&#34;
    # Default: a singleton outer space,
    # with everything contained in the inner (projection) space.
    if inner_axes is None and outer_axes is None:
        outer_axes = ()

    # Validate axes
    if inner_axes is None:
        assert outer_axes is not None
        inner_axes = struct_tools.complement(self.axes, outer_axes)
    else:
        assert outer_axes is None
        outer_axes = struct_tools.complement(self.axes, inner_axes)

    # Fill spaces
    outer_space = self.__class__(outer_axes)
    for coord, entry in self.items():
        outer_coord = outer_space.__getkey__(coord)
        try:
            inner_space = outer_space[outer_coord]
        except KeyError:
            inner_space = self.__class__(inner_axes)
            outer_space[outer_coord] = inner_space
        inner_space[inner_space.__getkey__(coord)] = entry

    return outer_space</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.add_axis"><code class="name flex">
<span>def <span class="ident">add_axis</span></span>(<span>self, axis)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L457-L461" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def add_axis(self, axis):
    self.__init__(self.axes+(axis,))
    for coord in list(self):
        entry = self.pop(coord)
        self[coord + (None,)] = entry</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.intersect_axes"><code class="name flex">
<span>def <span class="ident">intersect_axes</span></span>(<span>self, attrs)</span>
</code></dt>
<dd>
<div class="desc"><p>Rm those a in attrs that are not in self.axes.</p>
<p>This allows errors in the axes allotment, for ease-of-use.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L463-L482" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def intersect_axes(self, attrs):
    &#34;&#34;&#34;Rm those a in attrs that are not in self.axes.

    This allows errors in the axes allotment, for ease-of-use.
    &#34;&#34;&#34;
    absent = struct_tools.complement(attrs, self.axes)
    if absent:
        print(color_text(&#34;Warning:&#34;, colorama.Fore.RED),
              &#34;The requested attributes&#34;,
              color_text(str(absent), colorama.Fore.RED),
              (&#34;were not found among the&#34;
               &#34; xpSpace axes (attrs. used as coordinates&#34;
               &#34; for the set of experiments).&#34;
               &#34; This may be no problem if the attr. is redundant&#34;
               &#34; for the coord-sys.&#34;
               &#34; However, if it is caused by confusion or mis-spelling,&#34;
               &#34; then it is likely to cause mis-interpretation&#34;
               &#34; of the shown results.&#34;))
        attrs = struct_tools.complement(attrs, absent)
    return attrs</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.label_xSection"><code class="name flex">
<span>def <span class="ident">label_xSection</span></span>(<span>self, label, *NoneAttrs, **sub_coord)</span>
</code></dt>
<dd>
<div class="desc"><p>Insert duplicate entries for the cross section</p>
<p>whose <code>coord</code>s match <code>sub_coord</code>,
adding the attr <code>Const=label</code> to their <code>coord</code>,
reflecting the "constance/constraint/fixation" this represents.</p>
<p>This distinguishes the entries in this fixed-affine subspace,
preventing them from being gobbled up in <code>nest</code>.</p>
<p>If you wish, you can specify the <code>NoneAttrs</code>,
which are consequently set to None for the duplicated entries,
preventing them from getting plotted in tuning panels.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L484-L505" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def label_xSection(self, label, *NoneAttrs, **sub_coord):
    &#34;&#34;&#34;Insert duplicate entries for the cross section

    whose `coord`s match `sub_coord`,
    adding the attr `Const=label` to their `coord`,
    reflecting the &#34;constance/constraint/fixation&#34; this represents.

    This distinguishes the entries in this fixed-affine subspace,
    preventing them from being gobbled up in `nest`.

    If you wish, you can specify the `NoneAttrs`,
    which are consequently set to None for the duplicated entries,
    preventing them from getting plotted in tuning panels.
    &#34;&#34;&#34;
    if &#34;Const&#34; not in self.axes:
        self.add_axis(&#39;Const&#39;)

    for coord in self.coords(**self.intersect_axes(sub_coord)):
        entry = copy.deepcopy(self[coord])
        coord = coord._replace(Const=label)
        coord = coord._replace(**{a: None for a in NoneAttrs})
        self[coord] = entry</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dapper.xp_process.xpSpace"><code class="flex name class">
<span>class <span class="ident">xpSpace</span></span>
<span>(</span><span>axes, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Functionality to facilitate working with <code>xps</code> and their results.</p>
<p><code><a title="dapper.xp_process.xpSpace.from_list" href="#dapper.xp_process.xpSpace.from_list">xpSpace.from_list()</a></code> initializes a <code><a title="dapper.xp_process.SparseSpace" href="#dapper.xp_process.SparseSpace">SparseSpace</a></code> from a list
of objects, typically experiments referred to as <code>xp</code>s, by
(1) computing the relevant axes from the attributes, and
(2) filling the dict by <code>xp</code>s.</p>
<p>Using <code><a title="dapper.xp_process.xpSpace.from_list" href="#dapper.xp_process.xpSpace.from_list">xpSpace.from_list()</a>(xps)</code> creates a SparseSpace holding <code>xp</code>s.
However, the nested <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code>s output by <code><a title="dapper.xp_process.xpSpace.table_tree" href="#dapper.xp_process.xpSpace.table_tree">xpSpace.table_tree()</a></code> will hold
objects of type <code>UncertainQtty</code>,
coz <code><a title="dapper.xp_process.xpSpace.table_tree" href="#dapper.xp_process.xpSpace.table_tree">xpSpace.table_tree()</a></code> calls <code>mean</code> calls <code>field(statkey)</code>.</p>
<p>The main use of <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code> is through <code><a title="dapper.xp_process.xpSpace.print" href="#dapper.xp_process.xpSpace.print">xpSpace.print()</a></code> &amp; <code><a title="dapper.xp_process.xpSpace.plot" href="#dapper.xp_process.xpSpace.plot">xpSpace.plot()</a></code>,
both of which call <code><a title="dapper.xp_process.xpSpace.table_tree" href="#dapper.xp_process.xpSpace.table_tree">xpSpace.table_tree()</a></code> to nest the axes of the <code><a title="dapper.xp_process.SparseSpace" href="#dapper.xp_process.SparseSpace">SparseSpace</a></code>.</p>
<p>Usually initialized through <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>axes</code></strong> :&ensp;<code>list</code></dt>
<dd>The attributes defining the coordinate system.</dd>
<dt><strong><code>args</code></strong> :&ensp;<code>entries</code></dt>
<dd>Nothing, or a list of <code>xp</code>s.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L511-L1016" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class xpSpace(SparseSpace):
    &#34;&#34;&#34;Functionality to facilitate working with `xps` and their results.

    `xpSpace.from_list` initializes a `SparseSpace` from a list
    of objects, typically experiments referred to as `xp`s, by
    (1) computing the relevant axes from the attributes, and
    (2) filling the dict by `xp`s.

    Using `xpSpace.from_list(xps)` creates a SparseSpace holding `xp`s.
    However, the nested `xpSpace`s output by `xpSpace.table_tree` will hold
    objects of type `UncertainQtty`,
    coz `xpSpace.table_tree` calls `mean` calls `field(statkey)`.

    The main use of `xpSpace` is through `xpSpace.print` &amp; `xpSpace.plot`,
    both of which call `xpSpace.table_tree` to nest the axes of the `SparseSpace`.
    &#34;&#34;&#34;

    @classmethod
    def from_list(cls, xps):
        &#34;&#34;&#34;Init xpSpace from xpList.&#34;&#34;&#34;
        def make_ticks(axes, ordering=dict(  # noqa TODO 5
                    N         = &#39;default&#39;,
                    seed      = &#39;default&#39;,
                    infl      = &#39;default&#39;,
                    loc_rad   = &#39;default&#39;,
                    rot       = &#39;as_found&#39;,
                    da_method = &#39;as_found&#39;,
                    )):
            &#34;&#34;&#34;Unique &amp; sort, for each axis (individually) in axes.&#34;&#34;&#34;
            for ax_name, arr in axes.items():
                ticks = set(arr)  # unique (jumbles order)

                # Sort
                order = ordering.get(ax_name, &#39;default&#39;).lower()
                if callable(order):  # eg. mylist.index
                    ticks = sorted(ticks, key=order)
                elif &#39;as_found&#39; in order:
                    ticks = sorted(ticks, key=arr.index)
                else:  # default sorting, with None placed at the end
                    ticks = sorted(ticks, key= lambda x: (x is None, x))
                if any(x in order for x in [&#39;rev&#39;, &#39;inv&#39;]):
                    ticks = ticks[::-1]
                axes[ax_name] = ticks

        # Define axes
        xp_list = xpList(xps)
        axes = xp_list.split_attrs(nomerge=[&#39;Const&#39;])[0]
        make_ticks(axes)
        self = cls(axes.keys())

        # Note: this attr (ticks) will not be propagated through nest().
        # That is fine. Otherwise we should have to prune the ticks
        # (if they are to be useful), which we don&#39;t want to do.
        self.ticks = axes

        # Fill
        self.update({self.__getkey__(xp): xp for xp in xps})

        return self

    def field(self, statkey=&#34;rmse.a&#34;):
        &#34;&#34;&#34;Extract `statkey` for each item in `self`.&#34;&#34;&#34;
        # Init a new xpDict to hold field
        avrgs = self.__class__(self.axes)

        found_anything = False
        for coord, xp in self.items():
            val = getattr(xp.avrgs, statkey, None)
            avrgs[coord] = val
            found_anything = found_anything or (val is not None)

        if not found_anything:
            raise AttributeError(
                f&#34;The stat. field &#39;{statkey}&#39; was not found&#34;
                &#34; among any of the xp&#39;s.&#34;)

        return avrgs

    def mean(self, axes=None):
        # Note: The case `axes=()` should work w/o special treatment.
        if axes is None:
            return self

        nested = self.nest(axes)
        for coord, space in nested.items():

            def getval(uq): return uq.val if isinstance(uq, UncertainQtty) else uq
            vals = [getval(uq) for uq in space.values()]

            # Don&#39;t use nanmean! It would give false impressions.
            mu = np.mean(vals)

            with warnings.catch_warnings():
                warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
                # Don&#39;t print warnings caused by N=1.
                # It already correctly yield nan&#39;s.
                var = np.var(vals, ddof=1)

            N = len(vals)
            uq = UncertainQtty(mu, np.sqrt(var/N))
            uq.nTotal   = N
            uq.nFail    = N - np.isfinite(vals).sum()
            uq.nSuccess = N - uq.nFail

            nested[coord] = uq
        return nested

    def tune(self, axes=None, costfun=None):
        &#34;&#34;&#34;Get (compile/tabulate) a stat field optimised wrt. tuning params.&#34;&#34;&#34;
        # Define cost-function
        costfun = (costfun or &#39;increasing&#39;).lower()
        if &#39;increas&#39; in costfun:
            costfun = (lambda x: +x)
        elif &#39;decreas&#39; in costfun:
            costfun = (lambda x: -x)
        else:
            assert callable(costfun)  # custom

        # Note: The case `axes=()` should work w/o special treatment.
        if axes is None:
            return self

        nested = self.nest(axes)
        for coord, space in nested.items():

            # Find optimal value and coord within space
            MIN = np.inf
            for inner_coord, uq in space.items():
                cost = costfun(uq.val)
                if cost &lt;= MIN:
                    MIN                = cost
                    uq_opt             = uq
                    uq_opt.tuned_coord = inner_coord

            nested[coord] = uq_opt

        return nested

    def validate_axes(self, axes):
        &#34;&#34;&#34;Validate axes.

        Note: This does not convert None to (),
              allowing None to remain special.
              Use `axis or ()` wherever tuples are required.
        &#34;&#34;&#34;
        roles = {}  # &#34;inv&#34;
        for role in set(axes) | set(AXES_ROLES):
            assert role in AXES_ROLES, f&#34;Invalid role {role!r}&#34;
            aa = axes.get(role, AXES_ROLES[role])

            if aa is None:
                pass  # Purposely special
            else:
                # Ensure iterable
                if isinstance(aa, str) or not hasattr(aa, &#34;__iter__&#34;):
                    aa = (aa,)

                aa = self.intersect_axes(aa)

                for axis in aa:

                    # Ensure unique
                    if axis in roles:
                        raise TypeError(
                            f&#34;An axis (here {axis!r}) cannot be assigned to 2&#34;
                            f&#34; roles (here {role!r} and {roles[axis]!r}).&#34;)
                    else:
                        roles[axis] = role
            axes[role] = aa
        return axes

    def table_tree(self, statkey, axes):
        &#34;&#34;&#34;Hierarchical nest(): xp_dict&gt;outer&gt;inner&gt;mean&gt;optim.

        as specified by `axes`. Returns this new xpSpace.

        - print_1d / plot_1d (respectively) separate
          tables / panel(row)s for `axes[&#39;outer&#39;]`, and
          columns/ x-axis      for `axes[&#39;inner&#39;]`.

        - The `axes[&#39;mean&#39;]` and `axes[&#39;optim&#39;]` get eliminated
          by the mean()/tune() operations.

        Note: cannot support multiple statkeys
              because it&#39;s not (obviously) meaningful
              when optimizing over tuning_axes.
        &#34;&#34;&#34;
        axes = self.validate_axes(axes)

        def mean_tune(xp_dict):
            &#34;&#34;&#34;Take mean, then tune.

            Note: the SparseDict implementation should be sufficiently
            &#34;uncluttered&#34; that mean_tune() (or a few of its code lines)
            could be called anywhere above/between/below
            the `nest()`ing of `outer` or `inner`.
            These possibile call locations are commented in the code.
            &#34;&#34;&#34;
            uq_dict = xp_dict.field(statkey)
            uq_dict = uq_dict.mean(axes[&#39;mean&#39;])
            uq_dict = uq_dict.tune(axes[&#39;optim&#39;])
            return uq_dict

        self = mean_tune(self)
        # Prefer calling mean_tune() [also see its docstring]
        # before doing outer/inner nesting. This is because then the axes of
        # a row (xpSpace) should not include mean&amp;optim, and thus:
        #  - Column header/coords may be had directly as row.keys(),
        #    without extraction by __getkey__() from (e.g.) row[0].
        #  - Don&#39;t need to propagate mean&amp;optim axes down to the row level.
        #    which would require defining rows by the nesting:
        #    rows = table.nest(outer_axes=struct_tools.complement(table.axes,
        #        *(axes[&#39;inner&#39;] or ()),
        #        *(axes[&#39;mean&#39;]  or ()),
        #        *(axes[&#39;optim&#39;] or ()) ))
        #  - Each level of the output from table_tree
        #    is a smaller (and more manageable) dict.

        tables = self.nest(outer_axes=axes[&#39;outer&#39;])
        for table_coord, table in tables.items():
            # table = mean_tune(table)

            # Should not be used (nesting as rows is more natural,
            # and is required for getting distinct/row_keys).
            # cols = table.nest(outer_axes=axes[&#39;inner&#39;])

            rows = table.nest(inner_axes=axes[&#39;inner&#39;] or ())

            # Overwrite table by its nesting as rows
            tables[table_coord] = rows

            # for row_coord, row in rows.items():
            # rows[row_coord] = mean_tune(row)

        return axes, tables

    def tickz(self, axis_name):
        &#34;&#34;&#34;Axis ticks without None&#34;&#34;&#34;
        return [x for x in self.ticks[axis_name] if x is not None]

    def print(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES,  # noqa
              subcols=True, decimals=None):
        &#34;&#34;&#34;Print tables of results.

        Parameters
        ----------
        statkey: str
            The statistical field from the experiments to report.
        subcols: bool
            If `True`, then subcolumns are added to indicate the
            1σ confidence interval, and potentially some other stuff.
        axes: dict
            Allots (maps) each role to a set of axis of the `xpSpace`.
            Example:

            &gt;&gt;&gt; dict(outer=&#39;da_method&#39;, inner=&#39;N&#39;, mean=&#39;seed&#39;,  # doctest: +SKIP
            ...      optim=(&#39;infl&#39;,&#39;loc_rad&#39;))

            - Herein, the &#34;role&#34; `outer` should list the axes/attributes
            used to define the splitting of the results into *separate tables*:
            one table for each distinct combination of attributes.
            - Similarly , the role `inner` determines which attributes
            split a table into its columns.
            - `mean` lists the attributes used over which the mean is taken.
            - `optim` lists the attributes used over which the optimum result
               is searched for.

            Example: If `mean` is assigned to:

            - `(&#34;seed&#34;,)`: Experiments are averaged accross seeds,
                           and the 1σ (sub)col is computed as sqrt(var(xps)/N),
                           where xps is a set of experiments.

            - `()`       : Experiments are averaged across nothing
                           (i.e. this is an edge case).

            - `None`     : Experiments are not averaged
                           (i.e. the values are the same as above),
                           and the 1σ (sub)col is computed from
                           the time series of that single experiment.
        decimals: int
            Number of decimals to print.
            If `None`, this is determined for each statistic by its uncertainty.
        &#34;&#34;&#34;
        def make_cols(rows, cc, subcols, h2):
            &#34;&#34;&#34;Subcolumns: align, justify, join.&#34;&#34;&#34;
            # Define subcol formats
            if subcols:
                templ = &#34;{val} ±{prec}&#34;
                templ += &#34;&#34; if axes[&#39;optim&#39;] is None else &#34; *{tuned_coord}&#34;
                templ += &#34;&#34; if  axes[&#39;mean&#39;] is None else &#34; {nFail} {nSuccess}&#34;  # noqa
                aligns = dict(prec=&#34;&lt;&#34;, tuned_coord=&#34;&lt;&#34;)
                labels = dict(val=statkey, prec=&#34;1σ&#34;,
                              tuned_coord=axes[&#34;optim&#34;],
                              nFail=&#34;☠&#34;, nSuccess=&#34;✓&#34;)

            def align(column):
                col = unpack_uqs(column, decimals)
                if subcols:
                    for key in list(col):
                        if key in templ:
                            subcolmn = [labels.get(key, key)] + col[key]
                            col[key] = align_col(subcolmn, just=aligns.get(key, &#34;&gt;&#34;))
                        else:
                            del col[key]
                    col = [templ.format(**row) for row in struct_tools.transps(col)]
                else:
                    col = align_col([statkey] + col[&#34;val&#34;])
                return col

            def super_header(col_coord, idx, col):
                header, matter = col[0], col[1:]
                if idx:
                    super_header = str(col_coord)
                else:
                    super_header = repr(col_coord)
                width = len(header)  # += 1 if using unicode chars like ✔️
                super_header = super_header.center(width, &#34;_&#34;)
                header = super_header + &#34;\n&#34; + header
                return [header] + matter

            # Transpose
            columns = [list(x) for x in zip(*rows)]

            # Format column
            for j, (col_coord, column) in enumerate(zip(cc, columns)):
                col = align(column)
                if h2:
                    col = super_header(col_coord, j, col)
                columns[j] = col

            # Un-transpose
            rows = [list(x) for x in zip(*columns)]

            return rows

        # Inform axes[&#34;mean&#34;]
        if axes.get(&#39;mean&#39;, None):
            print(f&#34;Averages (in time and) over {axes[&#39;mean&#39;]}.&#34;)
        else:
            print(&#34;Averages in time only&#34;
                  &#34; (=&gt; the 1σ estimates may be unreliable).&#34;)

        axes, tables = self.table_tree(statkey, axes)
        for table_coord, table in tables.items():

            # Get this table&#39;s column coords (cc). Use dict for sorted&amp;unique.
            # cc = xp_dict.ticks[axes[&#34;inner&#34;]] # May be larger than needed.
            # cc = table[0].keys()              # May be too small a set.
            cc = {c: None for row in table.values() for c in row}

            # Convert table (rows) into rows (lists) of equal length
            rows = [[row.get(c, None) for c in cc] for row in table.values()]

            if False:  # ****************** Simple (for debugging) table
                for i, (row_coord, row) in enumerate(zip(table, rows)):
                    row_key = &#34;, &#34;.join(str(v) for v in row_coord)
                    rows[i] = [row_key] + row
                rows.insert(0, [f&#34;{table.axes}&#34;] + [repr(c) for c in cc])
            else:  # ********************** Elegant table.
                h2 = &#34;\n&#34; if len(cc) &gt; 1 else &#34;&#34;  # do column-super-header
                rows = make_cols(rows, cc, subcols, h2)

                # Make and prepend left-side table
                # - It&#39;s prettier if row_keys don&#39;t have unnecessary cols.
                #   For example, the table of Climatology should not have an
                #   entire column repeatedly displaying &#34;infl=None&#34;.
                #   =&gt; split_attrs().
                # - Why didn&#39;t we do this for the column attrs?
                #   Coz there we have no ambition to split the attrs,
                #   which would also require excessive processing:
                #   nesting the table as cols, and then split_attrs() on cols.
                row_keys = xpList(table.keys()).split_attrs()[0]
                if len(row_keys):
                    # Header
                    rows[0] = [h2+k for k in row_keys] + [h2+&#39;⑊&#39;] + rows[0]
                    # Matter
                    for i, (row, key) in enumerate(zip(
                            rows[1:], struct_tools.transps(row_keys))):
                        rows[i+1] = [*key.values()] + [&#39;|&#39;] + row

            # Print
            print(&#34;\n&#34;, end=&#34;&#34;)
            if axes[&#39;outer&#39;]:
                table_title = &#34;Table for &#34; + repr(table_coord)
                print(color_text(table_title, colorama.Back.YELLOW))
            headers, *rows = rows
            t = tabulate(rows, headers).replace(&#39;␣&#39;, &#39; &#39;)
            print(t)

    def plot(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES, get_style=default_styles,
             fignum=None, figsize=None, panels=None,
             title2=None, costfun=None, unique_labels=True):
        &#34;&#34;&#34;Plot the avrgs of `statkey` as a function of `axis[&#34;inner&#34;]`.

        Optionally, the experiments can be grouped by `axis[&#34;outer&#34;]`,
        producing a figure with columns of panels.
        Firs of all, though, mean and optimum computations are done for
        `axis[&#34;mean&#34;]` and `axis[&#34;optim&#34;]`, where the optimization can
        be controlled through `costfun` (see `xpSpace.tune`)

        This is entirely analogous to the roles of `axis` in `xpSpace.print`.

        The optimal parameters are plotted in smaller panels below the main plot.
        This can be prevented by providing the figure axes through the `panels` arg.
        &#34;&#34;&#34;
        def plot1(panelcol, row, style):
            &#34;&#34;&#34;Plot a given line (row) in the main panel and the optim panels.

            Involves: Sort, insert None&#39;s, handle constant lines.
            &#34;&#34;&#34;
            # Make a full row (yy) of vals, whether is_constant or not.
            # row.is_constant = (len(row)==1 and next(iter(row))==row.Coord(None))
            row.is_constant = all(x == row.Coord(None) for x in row)
            yy = [row[0] if row.is_constant else y for y in row.get_for(xticks)]

            # Plot main
            row.vals = [getattr(y, &#39;val&#39;, None) for y in yy]
            row.handles = {}
            row.handles[&#34;main_panel&#34;] = panelcol[0].plot(xticks, row.vals, **style)[0]

            # Plot tuning params
            row.tuned_coords = {}  # Store ordered, &#34;transposed&#34; argmins
            argmins = [getattr(y, &#39;tuned_coord&#39;, None) for y in yy]
            for a, panel in zip(axes[&#34;optim&#34;], panelcol[1:]):
                yy = [getattr(coord, a, None) for coord in argmins]
                row.tuned_coords[a] = yy

                # Plotting all None&#39;s sets axes units (like any plotting call)
                # which can cause trouble if the axes units were actually supposed
                # to be categorical (eg upd_a), but this is only revealed later.
                if not all(y == None for y in yy):
                    row.handles[a] = panel.plot(xticks, yy, **style)

        # Nest axes through table_tree()
        assert len(axes[&#34;inner&#34;]) == 1, &#34;You must chose the abscissa.&#34;
        axes, tables = self.table_tree(statkey, axes)
        xticks = self.tickz(axes[&#34;inner&#34;][0])

        # Figure panels
        if panels is None:
            nrows   = len(axes[&#39;optim&#39;] or ()) + 1
            ncols   = len(tables)
            maxW    = 12.7  # my mac screen
            figsize = figsize or (min(5*ncols, maxW), 7)
            gs      = dict(
                height_ratios=[6]+[1]*(nrows-1),
                hspace=0.05, wspace=0.05,
                # eyeballed:
                left=0.15/(1+np.log(ncols)),
                right=0.97, bottom=0.06, top=0.9)
            # Create
            _, panels = freshfig(num=fignum, figsize=figsize,
                                 nrows=nrows, sharex=True,
                                 ncols=ncols, sharey=&#39;row&#39;,
                                 gridspec_kw=gs)
            panels = np.ravel(panels).reshape((-1, ncols))
        else:
            panels = np.atleast_2d(panels)

        # Title
        fig = panels[0, 0].figure
        fig_title = &#34;Average wrt. time&#34;
        if axes[&#34;mean&#34;] is not None:
            fig_title += f&#34; and {axes[&#39;mean&#39;]}&#34;
        if title2 is not None:
            fig_title += &#34;\n&#34; + str(title2)
        fig.suptitle(fig_title)

        # Loop outer
        label_register = set()  # mv inside loop to get legend on each panel
        for table_panels, (table_coord, table) in zip(panels.T, tables.items()):
            table.panels = table_panels
            title = &#39;&#39; if axes[&#34;outer&#34;] is None else repr(table_coord)

            # Plot
            for coord, row in table.items():
                style = get_style(coord)

                # Rm duplicate labels (contrary to coords, labels can
                # be &#34;tampered&#34; with, and so can be duplicate)
                if unique_labels:
                    if style.get(&#34;label&#34;, None) in label_register:
                        del style[&#34;label&#34;]
                    else:
                        label_register.add(style[&#34;label&#34;])

                plot1(table.panels, row, style)

            # Beautify
            panel0 = table.panels[0]
            panel0.set_title(title)
            if panel0.is_first_col():
                panel0.set_ylabel(statkey)
            with set_tmp(mpl_logger, &#39;level&#39;, 99):  # silence &#34;no label&#34; msg
                panel0.legend()
            table.panels[-1].set_xlabel(axes[&#34;inner&#34;][0])
            # Tuning panels:
            for a, panel in zip(axes[&#34;optim&#34;] or (), table.panels[1:]):
                if panel.is_first_col():
                    panel.set_ylabel(f&#34;Optim.\n{a}&#34;)

        tables.fig = fig
        tables.xp_dict = self
        tables.axes_roles = axes
        return tables</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dapper.xp_process.SparseSpace" href="#dapper.xp_process.SparseSpace">SparseSpace</a></li>
<li>builtins.dict</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="dapper.xp_process.xpSpace.from_list"><code class="name flex">
<span>def <span class="ident">from_list</span></span>(<span>xps)</span>
</code></dt>
<dd>
<div class="desc"><p>Init xpSpace from xpList.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L528-L569" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@classmethod
def from_list(cls, xps):
    &#34;&#34;&#34;Init xpSpace from xpList.&#34;&#34;&#34;
    def make_ticks(axes, ordering=dict(  # noqa TODO 5
                N         = &#39;default&#39;,
                seed      = &#39;default&#39;,
                infl      = &#39;default&#39;,
                loc_rad   = &#39;default&#39;,
                rot       = &#39;as_found&#39;,
                da_method = &#39;as_found&#39;,
                )):
        &#34;&#34;&#34;Unique &amp; sort, for each axis (individually) in axes.&#34;&#34;&#34;
        for ax_name, arr in axes.items():
            ticks = set(arr)  # unique (jumbles order)

            # Sort
            order = ordering.get(ax_name, &#39;default&#39;).lower()
            if callable(order):  # eg. mylist.index
                ticks = sorted(ticks, key=order)
            elif &#39;as_found&#39; in order:
                ticks = sorted(ticks, key=arr.index)
            else:  # default sorting, with None placed at the end
                ticks = sorted(ticks, key= lambda x: (x is None, x))
            if any(x in order for x in [&#39;rev&#39;, &#39;inv&#39;]):
                ticks = ticks[::-1]
            axes[ax_name] = ticks

    # Define axes
    xp_list = xpList(xps)
    axes = xp_list.split_attrs(nomerge=[&#39;Const&#39;])[0]
    make_ticks(axes)
    self = cls(axes.keys())

    # Note: this attr (ticks) will not be propagated through nest().
    # That is fine. Otherwise we should have to prune the ticks
    # (if they are to be useful), which we don&#39;t want to do.
    self.ticks = axes

    # Fill
    self.update({self.__getkey__(xp): xp for xp in xps})

    return self</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.xp_process.xpSpace.field"><code class="name flex">
<span>def <span class="ident">field</span></span>(<span>self, statkey='rmse.a')</span>
</code></dt>
<dd>
<div class="desc"><p>Extract <code>statkey</code> for each item in <code>self</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L571-L587" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def field(self, statkey=&#34;rmse.a&#34;):
    &#34;&#34;&#34;Extract `statkey` for each item in `self`.&#34;&#34;&#34;
    # Init a new xpDict to hold field
    avrgs = self.__class__(self.axes)

    found_anything = False
    for coord, xp in self.items():
        val = getattr(xp.avrgs, statkey, None)
        avrgs[coord] = val
        found_anything = found_anything or (val is not None)

    if not found_anything:
        raise AttributeError(
            f&#34;The stat. field &#39;{statkey}&#39; was not found&#34;
            &#34; among any of the xp&#39;s.&#34;)

    return avrgs</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self, axes=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L589-L616" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def mean(self, axes=None):
    # Note: The case `axes=()` should work w/o special treatment.
    if axes is None:
        return self

    nested = self.nest(axes)
    for coord, space in nested.items():

        def getval(uq): return uq.val if isinstance(uq, UncertainQtty) else uq
        vals = [getval(uq) for uq in space.values()]

        # Don&#39;t use nanmean! It would give false impressions.
        mu = np.mean(vals)

        with warnings.catch_warnings():
            warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
            # Don&#39;t print warnings caused by N=1.
            # It already correctly yield nan&#39;s.
            var = np.var(vals, ddof=1)

        N = len(vals)
        uq = UncertainQtty(mu, np.sqrt(var/N))
        uq.nTotal   = N
        uq.nFail    = N - np.isfinite(vals).sum()
        uq.nSuccess = N - uq.nFail

        nested[coord] = uq
    return nested</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.tune"><code class="name flex">
<span>def <span class="ident">tune</span></span>(<span>self, axes=None, costfun=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Get (compile/tabulate) a stat field optimised wrt. tuning params.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L618-L647" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tune(self, axes=None, costfun=None):
    &#34;&#34;&#34;Get (compile/tabulate) a stat field optimised wrt. tuning params.&#34;&#34;&#34;
    # Define cost-function
    costfun = (costfun or &#39;increasing&#39;).lower()
    if &#39;increas&#39; in costfun:
        costfun = (lambda x: +x)
    elif &#39;decreas&#39; in costfun:
        costfun = (lambda x: -x)
    else:
        assert callable(costfun)  # custom

    # Note: The case `axes=()` should work w/o special treatment.
    if axes is None:
        return self

    nested = self.nest(axes)
    for coord, space in nested.items():

        # Find optimal value and coord within space
        MIN = np.inf
        for inner_coord, uq in space.items():
            cost = costfun(uq.val)
            if cost &lt;= MIN:
                MIN                = cost
                uq_opt             = uq
                uq_opt.tuned_coord = inner_coord

        nested[coord] = uq_opt

    return nested</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.validate_axes"><code class="name flex">
<span>def <span class="ident">validate_axes</span></span>(<span>self, axes)</span>
</code></dt>
<dd>
<div class="desc"><p>Validate axes.</p>
<p>Note: This does not convert None to (),
allowing None to remain special.
Use <code>axis or ()</code> wherever tuples are required.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L649-L680" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def validate_axes(self, axes):
    &#34;&#34;&#34;Validate axes.

    Note: This does not convert None to (),
          allowing None to remain special.
          Use `axis or ()` wherever tuples are required.
    &#34;&#34;&#34;
    roles = {}  # &#34;inv&#34;
    for role in set(axes) | set(AXES_ROLES):
        assert role in AXES_ROLES, f&#34;Invalid role {role!r}&#34;
        aa = axes.get(role, AXES_ROLES[role])

        if aa is None:
            pass  # Purposely special
        else:
            # Ensure iterable
            if isinstance(aa, str) or not hasattr(aa, &#34;__iter__&#34;):
                aa = (aa,)

            aa = self.intersect_axes(aa)

            for axis in aa:

                # Ensure unique
                if axis in roles:
                    raise TypeError(
                        f&#34;An axis (here {axis!r}) cannot be assigned to 2&#34;
                        f&#34; roles (here {role!r} and {roles[axis]!r}).&#34;)
                else:
                    roles[axis] = role
        axes[role] = aa
    return axes</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.table_tree"><code class="name flex">
<span>def <span class="ident">table_tree</span></span>(<span>self, statkey, axes)</span>
</code></dt>
<dd>
<div class="desc"><p>Hierarchical nest(): xp_dict&gt;outer&gt;inner&gt;mean&gt;optim.</p>
<p>as specified by <code>axes</code>. Returns this new xpSpace.</p>
<ul>
<li>
<p>print_1d / plot_1d (respectively) separate
tables / panel(row)s for <code>axes['outer']</code>, and
columns/ x-axis
for <code>axes['inner']</code>.</p>
</li>
<li>
<p>The <code>axes['mean']</code> and <code>axes['optim']</code> get eliminated
by the mean()/tune() operations.</p>
</li>
</ul>
<p>Note: cannot support multiple statkeys
because it's not (obviously) meaningful
when optimizing over tuning_axes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L682-L745" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def table_tree(self, statkey, axes):
    &#34;&#34;&#34;Hierarchical nest(): xp_dict&gt;outer&gt;inner&gt;mean&gt;optim.

    as specified by `axes`. Returns this new xpSpace.

    - print_1d / plot_1d (respectively) separate
      tables / panel(row)s for `axes[&#39;outer&#39;]`, and
      columns/ x-axis      for `axes[&#39;inner&#39;]`.

    - The `axes[&#39;mean&#39;]` and `axes[&#39;optim&#39;]` get eliminated
      by the mean()/tune() operations.

    Note: cannot support multiple statkeys
          because it&#39;s not (obviously) meaningful
          when optimizing over tuning_axes.
    &#34;&#34;&#34;
    axes = self.validate_axes(axes)

    def mean_tune(xp_dict):
        &#34;&#34;&#34;Take mean, then tune.

        Note: the SparseDict implementation should be sufficiently
        &#34;uncluttered&#34; that mean_tune() (or a few of its code lines)
        could be called anywhere above/between/below
        the `nest()`ing of `outer` or `inner`.
        These possibile call locations are commented in the code.
        &#34;&#34;&#34;
        uq_dict = xp_dict.field(statkey)
        uq_dict = uq_dict.mean(axes[&#39;mean&#39;])
        uq_dict = uq_dict.tune(axes[&#39;optim&#39;])
        return uq_dict

    self = mean_tune(self)
    # Prefer calling mean_tune() [also see its docstring]
    # before doing outer/inner nesting. This is because then the axes of
    # a row (xpSpace) should not include mean&amp;optim, and thus:
    #  - Column header/coords may be had directly as row.keys(),
    #    without extraction by __getkey__() from (e.g.) row[0].
    #  - Don&#39;t need to propagate mean&amp;optim axes down to the row level.
    #    which would require defining rows by the nesting:
    #    rows = table.nest(outer_axes=struct_tools.complement(table.axes,
    #        *(axes[&#39;inner&#39;] or ()),
    #        *(axes[&#39;mean&#39;]  or ()),
    #        *(axes[&#39;optim&#39;] or ()) ))
    #  - Each level of the output from table_tree
    #    is a smaller (and more manageable) dict.

    tables = self.nest(outer_axes=axes[&#39;outer&#39;])
    for table_coord, table in tables.items():
        # table = mean_tune(table)

        # Should not be used (nesting as rows is more natural,
        # and is required for getting distinct/row_keys).
        # cols = table.nest(outer_axes=axes[&#39;inner&#39;])

        rows = table.nest(inner_axes=axes[&#39;inner&#39;] or ())

        # Overwrite table by its nesting as rows
        tables[table_coord] = rows

        # for row_coord, row in rows.items():
        # rows[row_coord] = mean_tune(row)

    return axes, tables</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.tickz"><code class="name flex">
<span>def <span class="ident">tickz</span></span>(<span>self, axis_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Axis ticks without None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L747-L749" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tickz(self, axis_name):
    &#34;&#34;&#34;Axis ticks without None&#34;&#34;&#34;
    return [x for x in self.ticks[axis_name] if x is not None]</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.print"><code class="name flex">
<span>def <span class="ident">print</span></span>(<span>self, statkey='rmse.a', axes={'outer': None, 'inner': None, 'mean': None, 'optim': None}, subcols=True, decimals=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Print tables of results.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>statkey</code></strong> :&ensp;<code>str</code></dt>
<dd>The statistical field from the experiments to report.</dd>
<dt><strong><code>subcols</code></strong> :&ensp;<code>bool</code></dt>
<dd>If <code>True</code>, then subcolumns are added to indicate the
1σ confidence interval, and potentially some other stuff.</dd>
<dt><strong><code>axes</code></strong> :&ensp;<code>dict</code></dt>
<dd>
<p>Allots (maps) each role to a set of axis of the <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code>.
Example:</p>
<blockquote>
<blockquote>
<blockquote>
<p>dict(outer='da_method', inner='N', mean='seed',
# doctest: +SKIP
&hellip;
optim=('infl','loc_rad'))</p>
</blockquote>
</blockquote>
</blockquote>
<ul>
<li>Herein, the "role" <code>outer</code> should list the axes/attributes
used to define the splitting of the results into <em>separate tables</em>:
one table for each distinct combination of attributes.</li>
<li>Similarly , the role <code>inner</code> determines which attributes
split a table into its columns.</li>
<li><code>mean</code> lists the attributes used over which the mean is taken.</li>
<li><code>optim</code> lists the attributes used over which the optimum result
is searched for.</li>
</ul>
<p>Example: If <code>mean</code> is assigned to:</p>
<ul>
<li>
<p><code>("seed",)</code>: Experiments are averaged accross seeds,
and the 1σ (sub)col is computed as sqrt(var(xps)/N),
where xps is a set of experiments.</p>
</li>
<li>
<p><code>()</code>
: Experiments are averaged across nothing
(i.e. this is an edge case).</p>
</li>
<li>
<p><code>None</code>
: Experiments are not averaged
(i.e. the values are the same as above),
and the 1σ (sub)col is computed from
the time series of that single experiment.</p>
</li>
</ul>
</dd>
<dt><strong><code>decimals</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of decimals to print.
If <code>None</code>, this is determined for each statistic by its uncertainty.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L751-L899" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def print(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES,  # noqa
          subcols=True, decimals=None):
    &#34;&#34;&#34;Print tables of results.

    Parameters
    ----------
    statkey: str
        The statistical field from the experiments to report.
    subcols: bool
        If `True`, then subcolumns are added to indicate the
        1σ confidence interval, and potentially some other stuff.
    axes: dict
        Allots (maps) each role to a set of axis of the `xpSpace`.
        Example:

        &gt;&gt;&gt; dict(outer=&#39;da_method&#39;, inner=&#39;N&#39;, mean=&#39;seed&#39;,  # doctest: +SKIP
        ...      optim=(&#39;infl&#39;,&#39;loc_rad&#39;))

        - Herein, the &#34;role&#34; `outer` should list the axes/attributes
        used to define the splitting of the results into *separate tables*:
        one table for each distinct combination of attributes.
        - Similarly , the role `inner` determines which attributes
        split a table into its columns.
        - `mean` lists the attributes used over which the mean is taken.
        - `optim` lists the attributes used over which the optimum result
           is searched for.

        Example: If `mean` is assigned to:

        - `(&#34;seed&#34;,)`: Experiments are averaged accross seeds,
                       and the 1σ (sub)col is computed as sqrt(var(xps)/N),
                       where xps is a set of experiments.

        - `()`       : Experiments are averaged across nothing
                       (i.e. this is an edge case).

        - `None`     : Experiments are not averaged
                       (i.e. the values are the same as above),
                       and the 1σ (sub)col is computed from
                       the time series of that single experiment.
    decimals: int
        Number of decimals to print.
        If `None`, this is determined for each statistic by its uncertainty.
    &#34;&#34;&#34;
    def make_cols(rows, cc, subcols, h2):
        &#34;&#34;&#34;Subcolumns: align, justify, join.&#34;&#34;&#34;
        # Define subcol formats
        if subcols:
            templ = &#34;{val} ±{prec}&#34;
            templ += &#34;&#34; if axes[&#39;optim&#39;] is None else &#34; *{tuned_coord}&#34;
            templ += &#34;&#34; if  axes[&#39;mean&#39;] is None else &#34; {nFail} {nSuccess}&#34;  # noqa
            aligns = dict(prec=&#34;&lt;&#34;, tuned_coord=&#34;&lt;&#34;)
            labels = dict(val=statkey, prec=&#34;1σ&#34;,
                          tuned_coord=axes[&#34;optim&#34;],
                          nFail=&#34;☠&#34;, nSuccess=&#34;✓&#34;)

        def align(column):
            col = unpack_uqs(column, decimals)
            if subcols:
                for key in list(col):
                    if key in templ:
                        subcolmn = [labels.get(key, key)] + col[key]
                        col[key] = align_col(subcolmn, just=aligns.get(key, &#34;&gt;&#34;))
                    else:
                        del col[key]
                col = [templ.format(**row) for row in struct_tools.transps(col)]
            else:
                col = align_col([statkey] + col[&#34;val&#34;])
            return col

        def super_header(col_coord, idx, col):
            header, matter = col[0], col[1:]
            if idx:
                super_header = str(col_coord)
            else:
                super_header = repr(col_coord)
            width = len(header)  # += 1 if using unicode chars like ✔️
            super_header = super_header.center(width, &#34;_&#34;)
            header = super_header + &#34;\n&#34; + header
            return [header] + matter

        # Transpose
        columns = [list(x) for x in zip(*rows)]

        # Format column
        for j, (col_coord, column) in enumerate(zip(cc, columns)):
            col = align(column)
            if h2:
                col = super_header(col_coord, j, col)
            columns[j] = col

        # Un-transpose
        rows = [list(x) for x in zip(*columns)]

        return rows

    # Inform axes[&#34;mean&#34;]
    if axes.get(&#39;mean&#39;, None):
        print(f&#34;Averages (in time and) over {axes[&#39;mean&#39;]}.&#34;)
    else:
        print(&#34;Averages in time only&#34;
              &#34; (=&gt; the 1σ estimates may be unreliable).&#34;)

    axes, tables = self.table_tree(statkey, axes)
    for table_coord, table in tables.items():

        # Get this table&#39;s column coords (cc). Use dict for sorted&amp;unique.
        # cc = xp_dict.ticks[axes[&#34;inner&#34;]] # May be larger than needed.
        # cc = table[0].keys()              # May be too small a set.
        cc = {c: None for row in table.values() for c in row}

        # Convert table (rows) into rows (lists) of equal length
        rows = [[row.get(c, None) for c in cc] for row in table.values()]

        if False:  # ****************** Simple (for debugging) table
            for i, (row_coord, row) in enumerate(zip(table, rows)):
                row_key = &#34;, &#34;.join(str(v) for v in row_coord)
                rows[i] = [row_key] + row
            rows.insert(0, [f&#34;{table.axes}&#34;] + [repr(c) for c in cc])
        else:  # ********************** Elegant table.
            h2 = &#34;\n&#34; if len(cc) &gt; 1 else &#34;&#34;  # do column-super-header
            rows = make_cols(rows, cc, subcols, h2)

            # Make and prepend left-side table
            # - It&#39;s prettier if row_keys don&#39;t have unnecessary cols.
            #   For example, the table of Climatology should not have an
            #   entire column repeatedly displaying &#34;infl=None&#34;.
            #   =&gt; split_attrs().
            # - Why didn&#39;t we do this for the column attrs?
            #   Coz there we have no ambition to split the attrs,
            #   which would also require excessive processing:
            #   nesting the table as cols, and then split_attrs() on cols.
            row_keys = xpList(table.keys()).split_attrs()[0]
            if len(row_keys):
                # Header
                rows[0] = [h2+k for k in row_keys] + [h2+&#39;⑊&#39;] + rows[0]
                # Matter
                for i, (row, key) in enumerate(zip(
                        rows[1:], struct_tools.transps(row_keys))):
                    rows[i+1] = [*key.values()] + [&#39;|&#39;] + row

        # Print
        print(&#34;\n&#34;, end=&#34;&#34;)
        if axes[&#39;outer&#39;]:
            table_title = &#34;Table for &#34; + repr(table_coord)
            print(color_text(table_title, colorama.Back.YELLOW))
        headers, *rows = rows
        t = tabulate(rows, headers).replace(&#39;␣&#39;, &#39; &#39;)
        print(t)</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, statkey='rmse.a', axes={'outer': None, 'inner': None, 'mean': None, 'optim': None}, get_style=&lt;function default_styles&gt;, fignum=None, figsize=None, panels=None, title2=None, costfun=None, unique_labels=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the avrgs of <code>statkey</code> as a function of <code>axis["inner"]</code>.</p>
<p>Optionally, the experiments can be grouped by <code>axis["outer"]</code>,
producing a figure with columns of panels.
Firs of all, though, mean and optimum computations are done for
<code>axis["mean"]</code> and <code>axis["optim"]</code>, where the optimization can
be controlled through <code>costfun</code> (see <code><a title="dapper.xp_process.xpSpace.tune" href="#dapper.xp_process.xpSpace.tune">xpSpace.tune()</a></code>)</p>
<p>This is entirely analogous to the roles of <code>axis</code> in <code><a title="dapper.xp_process.xpSpace.print" href="#dapper.xp_process.xpSpace.print">xpSpace.print()</a></code>.</p>
<p>The optimal parameters are plotted in smaller panels below the main plot.
This can be prevented by providing the figure axes through the <code>panels</code> arg.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L901-L1016" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def plot(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES, get_style=default_styles,
         fignum=None, figsize=None, panels=None,
         title2=None, costfun=None, unique_labels=True):
    &#34;&#34;&#34;Plot the avrgs of `statkey` as a function of `axis[&#34;inner&#34;]`.

    Optionally, the experiments can be grouped by `axis[&#34;outer&#34;]`,
    producing a figure with columns of panels.
    Firs of all, though, mean and optimum computations are done for
    `axis[&#34;mean&#34;]` and `axis[&#34;optim&#34;]`, where the optimization can
    be controlled through `costfun` (see `xpSpace.tune`)

    This is entirely analogous to the roles of `axis` in `xpSpace.print`.

    The optimal parameters are plotted in smaller panels below the main plot.
    This can be prevented by providing the figure axes through the `panels` arg.
    &#34;&#34;&#34;
    def plot1(panelcol, row, style):
        &#34;&#34;&#34;Plot a given line (row) in the main panel and the optim panels.

        Involves: Sort, insert None&#39;s, handle constant lines.
        &#34;&#34;&#34;
        # Make a full row (yy) of vals, whether is_constant or not.
        # row.is_constant = (len(row)==1 and next(iter(row))==row.Coord(None))
        row.is_constant = all(x == row.Coord(None) for x in row)
        yy = [row[0] if row.is_constant else y for y in row.get_for(xticks)]

        # Plot main
        row.vals = [getattr(y, &#39;val&#39;, None) for y in yy]
        row.handles = {}
        row.handles[&#34;main_panel&#34;] = panelcol[0].plot(xticks, row.vals, **style)[0]

        # Plot tuning params
        row.tuned_coords = {}  # Store ordered, &#34;transposed&#34; argmins
        argmins = [getattr(y, &#39;tuned_coord&#39;, None) for y in yy]
        for a, panel in zip(axes[&#34;optim&#34;], panelcol[1:]):
            yy = [getattr(coord, a, None) for coord in argmins]
            row.tuned_coords[a] = yy

            # Plotting all None&#39;s sets axes units (like any plotting call)
            # which can cause trouble if the axes units were actually supposed
            # to be categorical (eg upd_a), but this is only revealed later.
            if not all(y == None for y in yy):
                row.handles[a] = panel.plot(xticks, yy, **style)

    # Nest axes through table_tree()
    assert len(axes[&#34;inner&#34;]) == 1, &#34;You must chose the abscissa.&#34;
    axes, tables = self.table_tree(statkey, axes)
    xticks = self.tickz(axes[&#34;inner&#34;][0])

    # Figure panels
    if panels is None:
        nrows   = len(axes[&#39;optim&#39;] or ()) + 1
        ncols   = len(tables)
        maxW    = 12.7  # my mac screen
        figsize = figsize or (min(5*ncols, maxW), 7)
        gs      = dict(
            height_ratios=[6]+[1]*(nrows-1),
            hspace=0.05, wspace=0.05,
            # eyeballed:
            left=0.15/(1+np.log(ncols)),
            right=0.97, bottom=0.06, top=0.9)
        # Create
        _, panels = freshfig(num=fignum, figsize=figsize,
                             nrows=nrows, sharex=True,
                             ncols=ncols, sharey=&#39;row&#39;,
                             gridspec_kw=gs)
        panels = np.ravel(panels).reshape((-1, ncols))
    else:
        panels = np.atleast_2d(panels)

    # Title
    fig = panels[0, 0].figure
    fig_title = &#34;Average wrt. time&#34;
    if axes[&#34;mean&#34;] is not None:
        fig_title += f&#34; and {axes[&#39;mean&#39;]}&#34;
    if title2 is not None:
        fig_title += &#34;\n&#34; + str(title2)
    fig.suptitle(fig_title)

    # Loop outer
    label_register = set()  # mv inside loop to get legend on each panel
    for table_panels, (table_coord, table) in zip(panels.T, tables.items()):
        table.panels = table_panels
        title = &#39;&#39; if axes[&#34;outer&#34;] is None else repr(table_coord)

        # Plot
        for coord, row in table.items():
            style = get_style(coord)

            # Rm duplicate labels (contrary to coords, labels can
            # be &#34;tampered&#34; with, and so can be duplicate)
            if unique_labels:
                if style.get(&#34;label&#34;, None) in label_register:
                    del style[&#34;label&#34;]
                else:
                    label_register.add(style[&#34;label&#34;])

            plot1(table.panels, row, style)

        # Beautify
        panel0 = table.panels[0]
        panel0.set_title(title)
        if panel0.is_first_col():
            panel0.set_ylabel(statkey)
        with set_tmp(mpl_logger, &#39;level&#39;, 99):  # silence &#34;no label&#34; msg
            panel0.legend()
        table.panels[-1].set_xlabel(axes[&#34;inner&#34;][0])
        # Tuning panels:
        for a, panel in zip(axes[&#34;optim&#34;] or (), table.panels[1:]):
            if panel.is_first_col():
                panel.set_ylabel(f&#34;Optim.\n{a}&#34;)

    tables.fig = fig
    tables.xp_dict = self
    tables.axes_roles = axes
    return tables</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="dapper.xp_process.SparseSpace" href="#dapper.xp_process.SparseSpace">SparseSpace</a></b></code>:
<ul class="hlist">
<li><code><a title="dapper.xp_process.SparseSpace.coords" href="#dapper.xp_process.SparseSpace.coords">coords</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.get_for" href="#dapper.xp_process.SparseSpace.get_for">get_for</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.intersect_axes" href="#dapper.xp_process.SparseSpace.intersect_axes">intersect_axes</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.label_xSection" href="#dapper.xp_process.SparseSpace.label_xSection">label_xSection</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.nest" href="#dapper.xp_process.SparseSpace.nest">nest</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.update" href="#dapper.xp_process.SparseSpace.update">update</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="DAPPER" href="https://nansencenter.github.io/DAPPER">
<img src="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo_wtxt.png" alt="">
<!-- can add style="width:200px;" to img -->
</a>
</header>
<div class="gcse-search" style="height: 70px"
data-as_oq="inurl:github.com/nansencenter/DAPPER site:DAPPER.github.io"
data-gaCategoryParameter="dapper.xp_process">
</div>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dapper" href="index.html">dapper</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dapper.xp_process.make_label" href="#dapper.xp_process.make_label">make_label</a></code></li>
<li><code><a title="dapper.xp_process.default_styles" href="#dapper.xp_process.default_styles">default_styles</a></code></li>
<li><code><a title="dapper.xp_process.rel_index" href="#dapper.xp_process.rel_index">rel_index</a></code></li>
<li><code><a title="dapper.xp_process.discretize_cmap" href="#dapper.xp_process.discretize_cmap">discretize_cmap</a></code></li>
<li><code><a title="dapper.xp_process.cm_bond" href="#dapper.xp_process.cm_bond">cm_bond</a></code></li>
<li><code><a title="dapper.xp_process.in_idx" href="#dapper.xp_process.in_idx">in_idx</a></code></li>
<li><code><a title="dapper.xp_process.load_HMM" href="#dapper.xp_process.load_HMM">load_HMM</a></code></li>
<li><code><a title="dapper.xp_process.load_xps" href="#dapper.xp_process.load_xps">load_xps</a></code></li>
<li><code><a title="dapper.xp_process.save_xps" href="#dapper.xp_process.save_xps">save_xps</a></code></li>
<li><code><a title="dapper.xp_process.overwrite_xps" href="#dapper.xp_process.overwrite_xps">overwrite_xps</a></code></li>
<li><code><a title="dapper.xp_process.reduce_inodes" href="#dapper.xp_process.reduce_inodes">reduce_inodes</a></code></li>
<li><code><a title="dapper.xp_process.default_fig_adjustments" href="#dapper.xp_process.default_fig_adjustments">default_fig_adjustments</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dapper.xp_process.SparseSpace" href="#dapper.xp_process.SparseSpace">SparseSpace</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.xp_process.SparseSpace.update" href="#dapper.xp_process.SparseSpace.update">update</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.get_for" href="#dapper.xp_process.SparseSpace.get_for">get_for</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.coords" href="#dapper.xp_process.SparseSpace.coords">coords</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.nest" href="#dapper.xp_process.SparseSpace.nest">nest</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.add_axis" href="#dapper.xp_process.SparseSpace.add_axis">add_axis</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.intersect_axes" href="#dapper.xp_process.SparseSpace.intersect_axes">intersect_axes</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.label_xSection" href="#dapper.xp_process.SparseSpace.label_xSection">label_xSection</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.axes" href="#dapper.xp_process.SparseSpace.axes">axes</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.xp_process.xpSpace.from_list" href="#dapper.xp_process.xpSpace.from_list">from_list</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.field" href="#dapper.xp_process.xpSpace.field">field</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.mean" href="#dapper.xp_process.xpSpace.mean">mean</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.tune" href="#dapper.xp_process.xpSpace.tune">tune</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.validate_axes" href="#dapper.xp_process.xpSpace.validate_axes">validate_axes</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.table_tree" href="#dapper.xp_process.xpSpace.table_tree">table_tree</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.tickz" href="#dapper.xp_process.xpSpace.tickz">tickz</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.print" href="#dapper.xp_process.xpSpace.print">print</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.plot" href="#dapper.xp_process.xpSpace.plot">plot</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>